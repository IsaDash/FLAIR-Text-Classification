,_id,_index,_score,tags,category label,text,category (from classifier),confidence,title,_type
0,t3_buuoi2,conversations_reddit,17.658812,,AI,"Natural language processing (NLP) is a field of computer science, artificial
intelligence and computational linguistics concerned with the interactions
between computers and human (natural) languages, and, in particular, concerned
with programming computers to fruitfully process large natural language
corpora.",Artificial Intelligence,1,Ask AI: Is Bob Dylan an Author or a Songwriter?,standard
1,t3_bxz7xt,conversations_reddit,17.658812,,AI,"Natural language processing (NLP) is a field of computer science, artificial
intelligence and computational linguistics concerned with the interactions
between computers and human (natural) languages, and, in particular, concerned
with programming computers to fruitfully process large natural language
corpora.",Artificial Intelligence,1,Understanding the parsed sentence,standard
2,https://news.ycombinator.com/item?id=19416359,conversations_hackernewsnew,17.657885,[],,"%PDF-1.5 %´è_´è_´è_´è_ 366 0 obj <> endobj 384 0 obj
<>/Filter/FlateDecode/ID[<20FF5D460D546D4B863BC23C3FC01C80>]/Index[366
35]/Info 365 0 R/Length 89/Prev 206688/Root 367 0 R/Size 401/Type/XRef/W[1 2
1]>>stream h´è_bbd``b`´è_ ´è_´è_S ´è_`´è_ ´è_*´è_´è_´è_-´è_bë_&´è_ $V$X~ .´è_,´è_2´è_´è_2´è_:´è_X ´è_`d´è_2´è_´è_´è_r´è_?C´è_'´è_
´è_´è_< endstream endobj startxref 0 %%EOF 400 0 obj <>stream h´è_b```f``´è_´è_´è_´è_´è_´è_,´è_ ´è_´è_
@1V ´è_$´è_$´è_´è_´è_era´è_´è_´è_´è_X´è_´è_ = mkKK´è_d´è_Nv´è_t´è_´è_q´è_´è_´è_´è_X__q#êm&J´è_n\´è_I \´è_´è_´è_´è_
´è_´è_´è_6´è_&´è_00´è_´è_v´è_0´è_Q´è_´è_|´è_)v´è_.g´è_5´è_´è_´è_´è_´è_ÑÙm´è_k´è_´è_(ã´è_ ´è_:´è_9´è_6v ´è_´è_´è_Õé ´è_´è_´è_´è_´è_4´è_ ´è_´è_´è_´è_´è_´è_´è_´è_ ´è_ ´è_9´è_
endstream endobj 367 0 obj <",Artificial Intelligence,0.574,How artificial intelligence works [pdf],standard
3,https://news.ycombinator.com/item?id=19359970,conversations_hackernewsnew,17.657885,[],AI,"The approach is related to traditional simulation, but with critical
differences. A simulation is essentially assumption-driven, Schawinski said.
The approach is to say, I think I know what the underlying physical laws are
that give rise to everything that I see in the system.È So I have a recipe for
star formation, I have a recipe for how dark matter behaves, and so on. I put
all of my hypotheses in there, and I let the simulation run. And then I ask:
Does that look like reality? What heÈs done with generative modeling, he
said, is in some sense, exactly the opposite of a simulation. We donÈt know
anything; we donÈt want to assume anything. We want the data itself to tell us
what might be going on.

The apparent success of generative modeling in a study like this obviously
doesnÈt mean that astronomers and graduate students have been made redundant 
but it appears to represent a shift in the degree to which learning about
astrophysical objects and processes can be achieved by an artificial system
that has little more at its electronic fingertips than a vast pool of data.
ItÈs not fully automated science  but it demonstrates that weÈre capable of
at least in part building the tools that make the process of science
automatic, Schawinski said.

Generative modeling is clearly powerful, but whether it truly represents a new
approach to science is open to debate. For [David
Hogg](https://cosmo.nyu.edu/hogg/), a cosmologist at New York University and
the Flatiron Institute (which, like _Quanta_ , is funded by the Simons
Foundation), the technique is impressive but ultimately just a very
sophisticated way of extracting patterns from data  which is what astronomers
have been doing for centuries. In other words, itÈs an advanced form of
observation plus analysis. HoggÈs own work, like SchawinskiÈs, leans heavily
on AI; heÈs been using neural networks to [classify
stars](https://arxiv.org/pdf/1711.08793.pdf) according to their spectra and to
[infer other physical attributes](https://arxiv.org/pdf/1603.03040.pdf) of
stars using data-driven models. But he sees his work, as well as SchawinskiÈs,
as tried-and-true science. I donÈt think itÈs a third way, he said recently.
I just think we as a community are becoming far more sophisticated about how
we use the data. In particular, we are getting much better at comparing data
to data. But in my view, my work is still squarely in the observational mode.

## Hardworking Assistants

Whether theyÈre conceptually novel or not, itÈs clear that AI and neural
networks have come to play a critical role in contemporary astronomy and
physics research. At the Heidelberg Institute for Theoretical Studies, the
physicist [Kai
Polsterer](https://www.iau.org/administration/membership/individual/16830/)
heads the astroinformatics group  a team of researchers focused on new, data-
centered methods of doing astrophysics. Recently, theyÈve been using a
machine-learning algorithm to [extract redshift information from galaxy data
sets](https://www.aanda.org/articles/aa/pdf/2018/01/aa31326-17.pdf), a
previously arduous task.

Polsterer sees these new AI-based systems as hardworking assistants that can
comb through data for hours on end without getting bored or complaining about
the working conditions. These systems can do all the tedious grunt work, he
said, leaving you to do the cool, interesting science on your own.

But theyÈre not perfect. In particular, Polsterer cautions, the algorithms can
only do what theyÈve been trained to do. The system is agnostic regarding
the input. Give it a galaxy, and the software can estimate its redshift and
its age  but feed that same system a selfie, or a picture of a rotting fish,
and it will output a (very wrong) age for that, too. In the end, oversight by
a human scientist remains essential, he said. It comes back to you, the
researcher. YouÈre the one in charge of doing the interpretation.

For his part, Nord, at Fermilab, cautions that itÈs crucial that neural
networks deliver not only results, but also error bars to go along with them,
as every undergraduate is trained to do. In science, if you make a measurement
and donÈt report an estimate of the associated error, no one will take the
results seriously, he said.

Like many AI researchers, Nord is also concerned about the impenetrability of
results produced by neural networks; often, a system delivers an answer
without offering a clear picture of how that result was obtained.

Yet not everyone feels that a lack of transparency is necessarily a problem.
[Lenka Zdeborov](http://artax.karlin.mff.cuni.cz/~zdebl9am/), a researcher at
the Institute of Theoretical Physics at CEA Saclay in France, points out that
human intuitions are often equally impenetrable. You look at a photograph and
instantly recognize a cat  but you donÈt know how you know, she said. Your
own brain is in some sense a black box.

ItÈs not only astrophysicists and cosmologists who are migrating toward AI-
fueled, data-driven science. Quantum physicists like [Roger
Melko](https://uwaterloo.ca/physics-astronomy/people-profiles/roger-melko) of
the Perimeter Institute for Theoretical Physics and the University of Waterloo
in Ontario have used neural networks to solve some of the toughest and most
important problems in that field, such as [how to represent the mathematical
wave function](https://arxiv.org/pdf/1812.09329.pdf) describing a many-
particle system. AI is essential because of what Melko calls the exponential
curse of dimensionality. That is, the possibilities for the form of a wave
function grow exponentially with the number of particles in the system it
describes. The difficulty is similar to trying to work out the best move in a
game like chess or Go: You try to peer ahead to the next move, imagining what
your opponent will play, and then choose the best response, but with each
move, the number of possibilities proliferates.

Of course, AI systems have mastered both of these games  chess, decades ago,
and Go in 2016, when an AI system called
[AlphaGo](https://www.theguardian.com/technology/2016/mar/15/googles-alphago-
seals-4-1-victory-over-grandmaster-lee-sedol) defeated a top human player.
They are similarly suited to problems in quantum physics, Melko says.

## The Mind of the Machine

Whether Schawinski is right in claiming that heÈs found a third way of doing
science, or whether, as Hogg says, itÈs merely traditional observation and
data analysis on steroids, itÈs clear AI is changing the flavor of
scientific discovery, and itÈs certainly accelerating it. How far will the AI
revolution go in science?

Occasionally, grand claims are made regarding the achievements of a robo-
scientist. A decade ago, an AI robot chemist named Adam investigated the
genome of bakerÈs yeast and worked out which genes are responsible for making
certain amino acids. (Adam did this by observing strains of yeast that had
certain genes missing, and comparing the results to the behavior of strains
that had the genes.) _Wired_ Ès headline read, [Robot Makes Scientific
Discovery All by Itself](https://www.wired.com/2009/04/robotscientist/).

More recently, Lee Cronin, a chemist at the University of Glasgow, has been
using a robot [to randomly mix
chemicals](https://www.wired.co.uk/article/robot-chemist-life-on-earth), to
see what sorts of new compounds are formed. Monitoring the reactions in real-
time with a mass spectrometer, a nuclear magnetic resonance machine, and an
infrared spectrometer, the system eventually learned to predict which
combinations would be the most reactive. Even if it doesnÈt lead to further
discoveries, Cronin has said, the robotic system could allow chemists to speed
up their research by about 90 percent.

Last year, another team of scientists at ETH Zurich used neural networks to
[deduce physical laws](https://arxiv.org/abs/1807.10300) from sets of data.
Their system, a sort of robo-Kepler, rediscovered the heliocentric model of
the solar system from records of the position of the sun and Mars in the sky,
as seen from Earth, and figured out the law of conservation of momentum by
observing colliding balls. Since physical laws can often be expressed in more
than one way, the researchers wonder if the system might offer new ways 
perhaps simpler ways  of thinking about known laws.

These are all examples of AI kick-starting the process of scientific
discovery, though in every case, we can debate just how revolutionary the new
approach is. Perhaps most controversial is the question of how much
information can be gleaned from data alone  a pressing question in the age of
stupendously large (and growing) piles of it. In _The Book of Why_ (2018), the
computer scientist Judea Pearl and the science writer Dana Mackenzie assert
that data are profoundly dumb. Questions about causality can never be
answered from data alone, they write. Anytime you see a paper or a study
that analyzes the data in a model-free way, you can be certain that the output
of the study will merely summarize, and perhaps transform, but not interpret
the data. Schawinski sympathizes with PearlÈs position, but he described the
idea of working with data alone as a bit of a straw man. HeÈs never
claimed to deduce cause and effect that way, he said. IÈm merely saying we
can do more with data than we often conventionally do.

Another oft-heard argument is that science requires creativity, and that  at
least so far  we have no idea how to program that into a machine. (Simply
trying everything, like CroninÈs robo-chemist, doesnÈt seem especially
creative.) Coming up with a theory, with reasoning, I think demands
creativity, Polsterer said. Every time you need creativity, you will need a
human. And where does creativity come from? Polsterer suspects it is related
to boredom  something that, he says, a machine cannot experience. To be
creative, you have to dislike being bored. And I donÈt think a computer will
ever feel bored. On the other hand, words like creative and inspired have
often been used to describe programs like Deep Blue and AlphaGo. And the
struggle to describe what goes on inside the mind of a machine is mirrored
by the difficulty we have in probing our own thought processes.

Schawinski recently left academia for the private sector; he now runs a
startup called Modulos which employs a number of ETH scientists and, according
to its website, works in the eye of the storm of developments in AI and
machine learning. Whatever obstacles may lie between current AI technology
and full-fledged artificial minds, he and other experts feel that machines are
poised to do more and more of the work of human scientists. Whether there is a
limit remains to be seen.

Will it be possible, in the foreseeable future, to build a machine that can
discover physics or mathematics that the brightest humans alive are not able
to do on their own, using biological hardware? Schawinski wonders. Will the
future of science eventually necessarily be driven by machines that operate on
a level that we can never reach? I donÈt know. ItÈs a good question.",Artificial Intelligence,1,Artificial Intelligence Is Changing Science,standard
4,https://news.ycombinator.com/item?id=19787525,conversations_hackernewsnew,17.657885,[],AI,"[![](https://www.microsoft.com/en-us/research/uploads/prod/2019/04/Visceral-
Machines-2Site_04_2019_1400x788-1024x576.png)](https://www.microsoft.com/en-
us/research/uploads/prod/2019/04/Visceral-Machines-2Site_04_2019_1400x788.png)

Recent successes in machine intelligence hinge on core computation ability to
efficiently search through billions of possibilities in order to make
decisions. Sequences of decisions, if successful, often suggest that perhaps
computation is catching up toor even surpassinghuman intelligence. Human
intelligence, on the other hand, is highly generalizable, adaptive, robust and
exhibits characteristics that the current state-of-the-art machine
intelligence systems simply are not yet capable of producing. For example,
humans are able to plan significantly far in advance based on the anticipated
outcomes, even in the presence of many unknown variables. Human intelligence
shines in scenarios in which other humans and living beings are involved and
consistently demonstrates reasoning and meta-reasoning abilities. Human
intelligence is also sympathetic, empathetic, kind, nurturing
andimportantlyable to relinquish and redefine the goals of a mission for the
benefit of a greater good. While almost all the work in machine intelligence
focuses on how, the hallmark of human-intelligence is the ability to ask
what and why.

Our hypothesis is that emotional intelligence is key to unlocking emergence of
machines that are not only more general, robust and efficient, but that also
are aligned with the values of humanity. The affective mechanisms in humans
allow us to accomplish tasks that are far too difficult to program or teach
current machines. For example, our sympathetic and parasympathetic responses
allow us to stay safe and to be aware of danger. Our ability to recognize
affect in others and imagine ourselves in their situations makes us far more
effective in taking appropriate decisions and navigating in the complex world.
Drives and affect such as hunger, curiosity, surprise, and joy enable us to
regulate our own behavior and also determine the sets of goals that we wish to
achieve. And finally, our ability to express our own internal state is an
excellent way to signal to others and possibly influence their decision
making.

Consequently, [it has been
hypothesized](https://mitpress.mit.edu/books/affective-computing) that
building such an emotional intelligence into a computational framework at
minimum would require the following capabilities:

* Recognizing othersÈ emotions
* Responding to othersÈ emotions
* Expressing emotions
* Regulating and utilizing emotions in decision making

Historically, the research in building emotionally intelligent machines has
primarily taken the human-machine collaboration point of view and mostly
focused on the first three capabilities. For example, [the earliest
work](https://mitpress.mit.edu/books/affective-computing) on affect
recognition started almost three decades ago, where physiological sensors,
cameras, microphones, and so on were used to detect a host of affective
responses. While there is much debate about how consistently and universally
people express emotions on their faces and other physiological signals, and
whether these really reflect how they feel inside, [researchers have
successfully built algorithms to identify useful signals in the noisy world of
human expressions as well as demonstrated that these signals are consistent
with socio-cultural
norms](http://alumni.media.mit.edu/~djmcduff/assets/publications/McDuff_2017_SAS_Abstract.pdf).

Ability to take appropriate actions based on the internal cognitive state of a
human is imperative for an emotionally intelligent agent.
[Applications](https://ieeexplore.ieee.org/document/1532370) such as
[automatic tutoring systems](https://www.microsoft.com/en-
us/research/uploads/prod/2016/12/ACM2005.pdf), mental and physical health
support, and applications for improving productivity lie at the forefront of
what is being pursued. The recent line of work on sequential decision making,
such as contextual bandits, is slowly making gains in this rich area. [Our own
work](https://www.microsoft.com/en-
us/research/uploads/prod/2016/10/foodandmood_final.pdf), for example, shows
how a system sensitive to affective aspects of managing a diet could help
subjects make good decisions.

Expression of affect has been at the forefront of computing for many decades
now. Even simple signals (for example, light, color, sound) have the ability
to convey and provoke rich emotion. In [Neural TTS Stylization with
Adversarial and Collaborative Games](https://www.microsoft.com/en-
us/research/publication/neural-tts-stylization-with-adversarial-and-
collaborative-games/), (co-authored with Shuang Ma and [Yale
Song](https://www.microsoft.com/en-us/research/people/yalesong/)) to be
presented at the Seventh International Conference on Learning
Representations[ICLR 2019](https://iclr.cc/), we propose a new machine
learning approach to synthesizing realistic human sounding speech that is
expressive. This architecture challenges the model to generate realistic
sounding speech that is faithful to the textual content while maintaining an
easily controllable dial for changing the emotion expressed in an independent
fashion. Our model achieves start-of-the-art results across multiple tasks,
including style transfer (content and style swapping), emotion modeling, and
identity transfer (fitting a new speakerÈs voice). An open-source
implementation is available with the paper.

[![Figure 1-Our neural architecture uses a combination of adversarial and
collaborative approaches. The algorithm received two audio samples during each
training step and has to produce two samples one of which is a reconstruction
of the first audio sample \(i.e., has both the content and style of sample 1\)
and the second which has the content of sample 1 and the style of sample 2. In
doing so it creates an internal representation of both content and style which
are disambiguated. ](https://www.microsoft.com/en-
us/research/uploads/prod/2019/04/Neural_TTS-1024x552.jpg)](https://researchdemopage.wixsite.com/tts-
gan)

Figure 1-Our neural architecture uses a combination of adversarial and
collaborative approaches. The algorithm received two audio samples during each
training step and has to produce two samples one of which is a reconstruction
of the first audio sample (i.e., has both the content and style of sample 1)
and the second which has the content of sample 1 and the style of sample 2. In
doing so it creates an internal representation of both content and style which
are disambiguated.

While the recognition, expression and intervention aspects of artificially
emotionally intelligent systems have been studied in-depth over the past 20
years, there is a still more compelling form of intelligencea system that
utilizes the affective mechanisms effectively in order to learn better and
make choices efficiently. In the most recent line of work, we hope to explore
questions of how to build such affective mechanisms that help our
computational processes achieve more than what they accomplish currently.

Our recent work, also appearing at ICLR 2019, explores the idea of affect-
based intrinsic motivations that can aid in learning decision-making
mechanisms. Much of the recent success in artificial intelligence in solving
games such as Go, Pac-Man, and text-based RPGs rely on reinforcement learning,
where good actions are rewarded and bad actions are penalized. However, it
requires a large number of trials in such an action-reward framework for a
computational agent to learn a reasonable policy. The intuition behind our
proposal is to get inspiration from how humans and other living beings
leverage affective mechanisms to learn much more efficiently.

As a human learns to navigate the world, the bodyÈs (nervous systemÈs)
responses provide constant intrinsic feedback about the potential consequence
of action choices, for example, becoming nervous when close to a cliffÈs edge
or when driving fast around a bend. Physiological changes are correlated with
these biological preparations to protect one-self from danger. The
anticipatory response in humans to a threatening situation is for the heart
rate to increase, heart rate variability to decrease, and for blood to be
diverted from the extremities and for the sweat glands to dilate. This is the
bodyÈs fight or flight response. Humans have evolved over millions of years
to build up these complex systems. What if machines had similar feedback
systems?

[![Visceral Machines are a novel approach to reinforcement learning that
leverages neural networks trained on physiological signals to mimic autonomic
nervous system responses. Such signals then are used as intrinsic reward
mechanisms to train agents that can learn to accomplish various
tasks.](https://www.microsoft.com/en-
us/research/uploads/prod/2019/04/Figure-2a-1024x728.png)](https://www.microsoft.com/en-
us/research/uploads/prod/2019/04/Figure-2a.png)

Figure 2-Visceral Machines are a novel approach to reinforcement learning that
leverages neural networks trained on physiological signals to mimic autonomic
nervous system responses. Such signals then are used as intrinsic reward
mechanisms to train agents that can learn to accomplish various tasks.

In [Visceral Machines: Risk-Aversion in Reinforcement Learning with Intrinsic
Physiological Rewards](https://www.microsoft.com/en-
us/research/publication/visceral-machines-risk-aversion-in-reinforcement-
learning-with-intrinsic-physiological-rewards/), we propose a novel approach
to reinforcement learning that leverages an intrinsic reward function trained
on human fight or flight behavior.

Our hypothesis is that such reward functions can circumvent the challenges
associated with sparse and skewed rewards in reinforcement learning settings
and can help improve sample efficiency. In our case, extrinsic rewards from
events are not necessary for the agent to learn. We test this in a simulated
driving environment and show that it can increase the speed of learning and
reduce the number of collisions during the learning stage. We are excited
about the potential of training autonomous systems that mimic the ability to
feel and respond to stimuli in an emotional way.

[![An example of the physiological response \(blood volume pulse\) recorded
from a human during a driving task. A zoomed in section of the pulse wave with
frames from the view of the driver are shown. Note how the pulse wave pinches
between seconds 285 and 300, during this period the driver collided with a
wall while turning sharply to avoid another obstacle. The pinching begins
before the collision occurs as the driverÈs anticipatory response is
activated. The intrinsic reward component aims to recreate statistical
properties of the blood volume pulse wave during driving in the simulated
environment](https://www.microsoft.com/en-
us/research/uploads/prod/2019/04/Figure-2b-1024x601.png)](https://www.microsoft.com/en-
us/research/uploads/prod/2019/04/Figure-2b.png)

Figure 3-An example of the physiological response (blood volume pulse)
recorded from a human during a driving task. A zoomed in section of the pulse
wave with frames from the view of the driver are shown. Note how the pulse
wave pinches between seconds 285 and 300, during this period the driver
collided with a wall while turning sharply to avoid another obstacle. The
pinching begins before the collision occurs as the driverÈs anticipatory
response is activated. The intrinsic reward component aims to recreate
statistical properties of the blood volume pulse wave during driving in the
simulated environment

A lot of computer scientists and roboticists have aspired to build agents that
resemble memorable characters in popular science fiction such as KITT and
R2D2. However, rich opportunities exist for building holistic affective
computing mechanisms that go a step beyond and to help us build robust,
efficient and non-myopic artificial intelligence. We hope that this work
inspires a fresh look at how emotions can be used in artificial intelligence.

We hope to see you at ICLR in New Orleans in May and look forward to sharing
ideas and advancing the conversation on the possibilities in the exciting
research realm of emotionally intelligent agents.",Artificial Intelligence,1,Toward Emotionally Intelligent Artificial Intelligence,standard
5,t3_b2jcu5,conversations_reddit,17.640572,,AI,"I analyzed all the posts from Stack Overflow / Stack Exchange and extracted
most frequently mentioned Artificial Intelligence & Machine Learning books.



Top Mentioned AI & Machine Learning Books on Stack Overflow / Exchange

<http://www.aimlbooks.com/>

Let me know what you think!",Artificial Intelligence,1,[D] Top Mentioned AI & Machine Learning Books on Stack Overflow / Exchange,standard
6,t3_bpso9a,conversations_reddit,17.640572,,AI,"Natural language processing (NLP) is a field of computer science, artificial
intelligence and computational linguistics concerned with the interactions
between computers and human (natural) languages, and, in particular, concerned
with programming computers to fruitfully process large natural language
corpora.

Join",Artificial Intelligence,1,Microsoft makes GoogleÈs BERT NLP model better,standard
7,https://news.ycombinator.com/item?id=19427931,conversations_hackernewsnew,17.60834,[],AI,"![](https://www.washingtonpost.com/resizer/yOJdgadrZVjeFjGOtMESntCzPQE=/1484x0/arc-
anglerfish-washpost-prod-
washpost.s3.amazonaws.com/public/6IUQCUSHIAI6TFFL2LO2HQG7KI.jpg) Fei-Fei Li
and John Etchemendy are co-directors at the Stanford Institute for Human-
Centered Artificial Intelligence. (Peter DaSilva for The Washington Post)

PALO ALTO, Calif.  A Stanford University scientist coined the term artificial
intelligence. Others at the university created some of the most significant
applications of it, such as the [first autonomous
vehicle](https://www.wired.com/story/wired25-sebastian-thrun-sam-altman-
artificial-intelligence/).

But as Silicon Valley faces a reckoning over how technology is changing
society, Stanford wants to be at the forefront of a different type of
innovation, one that puts humans and ethics at the center of the booming field
of AI.

On Monday, the university will launch the Stanford Institute for Human-
Centered Artificial Intelligence (HAI), a sprawling think tank that aims to
become an interdisciplinary hub for policymakers, researchers and students who
will go on to build the technologies of the future. They hope they can
inculcate in that next generation a more worldly and humane set of values than
those that have characterized it so far  and guide politicians to make more
sophisticated decisions about the challenging social questions wrought by
technology.

I could not have envisioned that the discipline I was so interested in would,
a decade and a half later, become one of the driving forces of the changes
that humanity will undergo, said Fei-Fei Li, an AI pioneer and former Google
vice president who is one of two directors of the new Stanford institute.
That realization became a tremendous sense of responsibility.

The institute  backed by the fieldÈs biggest leaders and industry players 
is not the first such academic effort of its kind, but it is by far the most
ambitious: It aims to raise more than $1 billion. And its advisory council is
a whoÈs who of Silicon Valley titans, including former Google executive
chairman Eric Schmidt, LinkedIn co-founder Reid Hoffman, former Yahoo chief
executive Marissa Mayer and co-founder Jerry Yang, and the prominent investor
Jim Breyer. Microsoft co-founder Bill Gates will keynote its inaugural
symposium on Monday.

The money raised will not only go to research grants and academic gatherings
but also to buying data processing power and luring back some of the talent
that has fled academia for lucrative industry jobs in recent years. It will be
housed in a new 200,000-square-foot building at the heart of StanfordÈs
campus.

We recognize that decisions that are made early on in the development of a
technology have huge ramifications, said John Etchemendy, a philosopher and
former Stanford provost, the second director of the AI institute. We need to
be thoughtful about what those might be, and to do that we canÈt rely simply
on technologists.

![](https://www.washingtonpost.com/resizer/TXJKur-
cQ3m4AF9lqk_kkjfemkk=/3x2/www.washingtonpost.com/pb/resources/img/spacer.gif)
The Stanford Institute for Human-Centered Artificial Intelligence will be
housed in a new building at the center of the campus. (Peter DaSilva for The
Washington Post)

The idea for the institute began with a conversation in 2016 between Li and
Etchemendy that took place in LiÈs driveway about a five-minute drive from
campus.

Etchemendy had recently purchased the house next door. But the casual
neighborly chat quickly morphed into a weightier dialogue about the future of
society and what had gone wrong in the exploding field of AI. Billions of
dollars were being invested in start-ups dedicated to commercializing what had
previously been niche academic technologies. Companies like Facebook, Apple
and Google were hiring the worldÈs top artificial researchers  along with
many of their recently minted graduates  to work in new divisions dedicated
to robotics, self-driving cars and voice recognition for home devices.

The correct answer to pretty much everything in AI is more of it, said
Schmidt, the former Google chairman. This generation is much more socially
conscious than we were, and more broadly concerned about the impact of
everything they do, so youÈll see a combination of both optimism and realism.

In the years following that conversation in the driveway, the dangers and ills
of AI have become more apparent. Seemingly every day, new statistics emerge
about the tide of job loss wrought by the technology, from long-haul truckers
to farmworkers to dermatologists. Elon Musk called AI humanityÈs existential
threat and compared it to summoning the demon.

Researchers and journalists have shown how AI technologies, largely designed
by white and Asian men, tend to [reproduce and
amplify](https://www.wsj.com/articles/computers-are-showing-their-biases-and-
tech-firms-are-concerned-1440102894) social biases in dangerous ways. Computer
vision technologies built into cameras have trouble recognizing the faces of
people of color. Voice recognition
[struggles](https://www.washingtonpost.com/graphics/2018/business/alexa-does-
not-understand-your-accent/?utm_term=.e6e67a48897f) to pick up English accents
that arenÈt mainstream. Algorithms built to predict the likelihood of parole
violations are rife with [racial
bias](https://www.propublica.org/article/bias-in-criminal-risk-scores-is-
mathematically-inevitable-researchers-say).

And there are political ramifications: Recommendation software designed to
target ads to interested consumers was abused by bad actors, including Russian
operatives, to amplify disinformation and false narratives in public debate.

The question comes down to whether this revolution of AI  and of todayÈs
machine learning techniques  will contribute to the progression of humanity,
said Hoffman, who chairs the instituteÈs advisory council. He called
StanfordÈs institute a potential key lever that would act as a catalyst,
trusted adviser, and source of intelligence for industry, the government and
the public. (Hoffman ran into trouble last year after reports showed that he
had funded a disinformation campaign on Facebook during the Alabama election.
He said he did not know his money was used in that way.)

While universities in recent years have drawn criticism for raising large
amounts of money  Stanford is among the biggest fundraisers of all  the cash
is particularly necessary if universities are to remain competitive in the
field of AI, said James Manyika, an advisory council member and director of
the McKinsey Global Institute. Not only will the money be used to retain
talent, but also to fund costly data processing machines that can run
artificial intelligence applications at scale.

The goal is to have resources that will enable Stanford to be competitive,
Manyika said. If you gave researchers at Stanford access to compute, that
will slow down the brain drain quite a bit toward these corporate labs.

![](https://www.washingtonpost.com/resizer/TXJKur-
cQ3m4AF9lqk_kkjfemkk=/3x2/www.washingtonpost.com/pb/resources/img/spacer.gif)
Li is an AI pioneer and academic who also worked at Google. (Peter DaSilva for
The Washington Post)

Schmidt said he had observed a tipping point in the last year or so, where
computer science programs across the country are adding courses in AI ethics
and big companies such as Google are announcing AI principles and creating
internal programs to attempt to take the bias out of the software they are
building. Schmidt said that StanfordÈs program would elevate and centralize
these ad hoc efforts, but also contribute to the development of the field
overall.

One of the bigger questions HAI has yet to answer is the extent to which it
will take policy positions on some of the toughest current issues, in which Li
and others involved with HAI have been directly involved. Last year, when Li
was running artificial intelligence for Google Cloud, Google became embroiled
in controversy for obtaining a Pentagon contract to improve artificial
intelligence that can scan video footage coming in from drones. Many Google
employees protested the contract and some even quit.

Li cautioned her colleagues against using the term AI when discussing the
contract because of the sensitivity of the topic, according to a New York
Times report, and confirmed by Li. Etchemendy said HAI would not take sides or
dictate decisions to other organizations.

Etchemendy said that 200 faculty members, from departments like law and
anthropology, have already applied for funding from the think tank. Fifty-five
have already received seed grants to research AIÈs implications for topics
including medical decision-making, gender bias and refugee resettlement. One
of the instituteÈs biggest strengths would be its commitment to diversity
within the profession, he said, and its recruitment of experts from fields not
traditionally associated with AI.",Artificial Intelligence,0.872,Stanford launches artificial intelligence institute,standard
0,reddit_https://www.reddit.com/r/artificial/comments/atf0wr/artificial_intelligence_my_own_jarvis/,conversations_reddit,17.479641,,,"no comments yet

Be the first to share what you think!",Artificial Intelligence,0.833,Artificial Intelligence - My Own Jarvis!,standard
1,t3_b9exhc,conversations_reddit,17.455257,,AI,"<https://www.softtraids.com/2018/09/kirin-980-16.html>

Huawei is expected to release Huawei Mate 20, on October 16. The phone will be
equipped with a modern SoC Kirin 980 processor manufactured by the Chinese
Foundation, an opportunity Huawei will use to highlight the possibilities of
artificial intelligence in",Artificial Intelligence,0.889,Huawei Announces KIRIN 980,standard
2,t3_bc108p,conversations_reddit,17.37959,,AI,"<table> <tr><td> <a href=""https://www.reddit.com/r/MachineLearning/comments/bc108p/d_4_recommended_books_on_ai_ethics_and_philosophy/""> <img src=""https://b.thumbs.redditmedia.com/zo9dARSkvlvNVnq10JEpHnPFpOh-n8X5Db8FmiQ-e5c.jpg"" alt=""[D] 4 Recommended Books on AI Ethics and Philosophy"" title=""[D] 4 Recommended Books on AI Ethics and Philosophy"" /> </a> </td><td> <!-- SC_OFF --><div class=""md""><p>One should not only know the technology and the methods. The more artificial intelligence enters our lives, the more important ethics and philosophy become. Everyone who develops ML models bears a special challenge.</p> <p>&#x200B;</p> <p>link: <a href=""https://www.aisoma.de/4-recommended-books-on-ai-ethics-and-ai-philosophy/"">https://www.aisoma.de/4-recommended-books-on-ai-ethics-and-ai-philosophy/</a> </p> <p>&#x200B;</p> <p><a href=""https://i.redd.it/vgamjtmvhnr21.jpg"">https://i.redd.it/vgamjtmvhnr21.jpg</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=""https://www.reddit.com/user/seemingly_omniscient""> /u/seemingly_omniscient </a> <br/> <span><a href=""https://www.reddit.com/r/MachineLearning/comments/bc108p/d_4_recommended_books_on_ai_ethics_and_philosophy/"">[link]</a></span> &#32; <span><a href=""https://www.reddit.com/r/MachineLearning/comments/bc108p/d_4_recommended_books_on_ai_ethics_and_philosophy/"">[comments]</a></span> </td></tr></table>",Artificial Intelligence,1,[D] 4 Recommended Books on AI Ethics and Philosophy,standard
3,t3_bq3yqz,conversations_reddit,17.37936,,,"The goal of /r/tech is to provide a space dedicated to the intelligent
discussion of innovations and changes to technology in our ever changing
world. We focus on high quality news articles about technology and informative
and thought provoking self posts.",Artificial Intelligence,1,Scientists help artificial intelligence outsmart hackers,standard
4,stackoverflow-54959340,conversations_stackoverflow,17.340616,"['python', 'machine-learning', 'nlp', 'nltk']",AI,"<p>I want to train a language model using NLTK in python but i got into several problems.
first of all i don't know why my words turn into just characters as i write something like this :</p>

<pre><code> s = ""Natural-language processing (NLP) is an area of computer science "" \
""and artificial intelligence concerned with the interactions "" \
""between computers and human (natural) languages.""
s = s.lower();


paddedLine = pad_both_ends(word_tokenize(s),n=2);

train, vocab = padded_everygram_pipeline(2, paddedLine)
print(list(vocab))
lm = MLE(2);
lm.fit(train,vocab)
</code></pre>

<p>and the printed vocab is something like this that is clearly not correct(i don't want to work with characters!),this is part of output.:</p>

<pre><code>&lt;s&gt;', '&lt;', 's', '&gt;', '&lt;/s&gt;', '&lt;s&gt;', 'n', 'a', 't', 'u', 'r', 'a', 'l', '-', 'l', 'a', 'n', 'g', 'u', 'a', 'g', 'e', '&lt;/s&gt;', '&lt;s&gt;', 'p', 'r', 'o', 'c', 'e', 's', 's', 'i', 'n', 'g', '&lt;/s&gt;', '&lt;s&gt;', '(', '&lt;/s&gt;', '&lt;s&gt;', 'n', 'l', 'p', '&lt;/s&gt;', '&lt;s&gt;', ')', '&lt;/s&gt;'
</code></pre>

<p>why my input turns into characters?
i did this work in another way but with no luck :</p>

<pre><code>paddedLine = pad_both_ends(word_tokenize(s),n=2);
#train, vocab = padded_everygram_pipeline(2, tokens)
#train = everygrams(paddedLine,max_len = 2);

train = ngrams(paddedLine,2);
vocab = Vocabulary(paddedLine,unk_cutoff = 1);
print(list(train))

lm = MLE(2);
lm.fit(train,vocab)
</code></pre>

<p>when i run this code my train is absolute nothing,empty! it shows me ""[]"" !!
wired thing is when i comment at this line from above code:</p>

<pre><code>vocab = Vocabulary(paddedLine,unk_cutoff = 1);
</code></pre>

<p>now my train data is ok and something like this that is correct :</p>

<pre><code>[('&lt;s&gt;', 'natural-language'), ('natural-language', 'processing'), ('processing', '('), ('(', 'nlp'), ('nlp', ')'), (')', 'is'), ('is', 'an'), ('an', 'area'), ('area', 'of'), ('of', 'computer'), ('computer', 'science'), ('science', 'and'), ('and', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'concerned'), ('concerned', 'with'), ('with', 'the'), ('the', 'interactions'), ('interactions', 'between'), ('between', 'computers'), ('computers', 'and'), ('and', 'human'), ('human', '('), ('(', 'natural'), ('natural', ')'), (')', 'languages'), ('languages', '.'), ('.', '&lt;/s&gt;')]
</code></pre>

<p>whats wrong with it? 
by the way i have to say that i'm not an expert in python or NLTK and its my first experience.
next question is how can i use kneser-ney smoothing or add-one smoothing on training languge model? 
and am i doing language model training the right way?
my trainig data is simple :</p>

<pre><code>""Natural-language processing (NLP) is an area of computer science "" \
""and artificial intelligence concerned with the interactions "" \
""between computers and human (natural) languages.""
</code></pre>

<p>thanks.</p>",Artificial Intelligence,0.966,NLTK language modeling confusion,standard
5,t3_b5hega,conversations_reddit,17.274488,,AI,"<https://youtu.be/E3l_aeGjkeI>

This Machine Learning tutorial will introduce you to the different areas of
Machine Learning and Artificial Intelligence within the programming language
Python. In this part of the course you will learn about the three different
learning types (Unsupervised learning, Supervised Learning and Reinforcement
Learning)",Artificial Intelligence,0.921,Python Machine Learning Tutorial Part 1 | Machine Learning For Beginners,standard
6,https://news.ycombinator.com/item?id=20037520,conversations_hackernewsnew,17.243877,[],AI,"29th May 2019

#

Leveraging Web Development with Artificial Intelligence

Web Development is growing dramatically and so is the use of Artificial
Intelligence. TodayÈs web development is focused mainly on enhancing user
experience and AI is, thus, the perfect match for it.

Artificial Intelligence (AI) is the ability of a computer or a machine to
think and work just like humans. AI is based on algorithms which use computing
power to solve specific problems faster and better than humans can. AI allows
the machines to analyze, plan, learn and adapt. AI relies on the data that is
provided to it and interprets this data to create new perspectives and learn
new objectives. It then leverages this data to provide better and more
accurate results in the future.

Let us now analyze how Artificial Intelligence and Machine Learning can be
used in Web Development and provide you with an exceptional advantage over
your competitors:

![](https://i1.wp.com/www.atyantik.com/wp-
content/uploads/2019/05/60847875_2340618609596223_6147071032143380480_n.png?fit=640%2C328&ssl=1)

1. **User Experience**  AI and ML can be used to enhance the experience of your website or app visitors. These visitors are often potential customers and they are more likely to purchase a product if they are provided with easy-to-use interface which enables them to find specific products faster.
2. **Improved Predictive Response**  traditional chatbots were boring, too predictive and sometimes even useless. But the modern AI-powered chatbots are super-intelligent. They know how to quickly and accurately respond to exact customer queries and needs making the whole experience delightful for the consumers.
3. **Personalized Content**  Machine Learning is able to predict the intentions of the users based on their previous activities and can hence be used to show content to the audience that is best tailored to their needs. Users are shown with music, videos, tv shows, and even products that they are most likely to interact with.
4. **Voice-based Search**  Voice Recognition and interpretation is one of the prodigies of Machine Learning and has revolutionized the way users interact with applications. Integrating web development allows customers to shop faster and smarter.
5. **Unique Store Experience**  AI can be used by retailers to gain customer data and get insights on customer behaviour. This data can then be used to offer personalized and customized shopping recommendations, products, deals and much more to the users. This helps boost your sales as your customers will more likely buy products from your website rather than from a competitor.

#### Case Study of Amazon and Netflix implementing AI and ML in their
Recommendation Engines

Have you ever wondered why the product you see on Amazon is exactly what you
were looking for? Well, Amazon **** has been using AI techniques to tailor the
products and content it recommends to its customers. Their recommendation
system uses **goods-based recommendation ** which means that users are
recommended based on their previous interactions and purchases and **buddy-
based recommendation ** which means that users are recommended products and
content based on what their Facebook or Instagram friends like.

![Netflix Logo](https://i0.wp.com/www.atyantik.com/wp-
content/uploads/2019/05/netflix.png?resize=253%2C142&ssl=1)

**Netflix** , on the other hand, revamped their recommendation algorithms and
honed them for visual impressions. Their AI and ML algorithms are optimized to
provide users with the image that they are most likely to respond to. They
feed implicit (based on user behavior) and explicit (based on user activity)
data to their Machine Learning algorithms to help it figure out the most
relevant content for each individual user. It is constantly collecting data
from its 100 million subscribers to make its AI and ML algorithms better and
better every day.",Artificial Intelligence,1,Leveraging Web Development with Artificial Intelligence,standard
7,https://news.ycombinator.com/item?id=19489280,conversations_hackernewsnew,17.221594,[],AI,"Bullying has always been a problem in schools. Over the last few years, itÈs
finally getting taken seriously and given proper attention.

Research has shown that when adults respond quickly, bullying behavior can be
stopped over time. Unfortunately, teachers donÈt always see the signs until
itÈs too late. One school district in Japan is attempting to give teachers and
officials [a powerful
ally](http://mainichi.jp/english/articles/20190323/p2g/00m/0na/063000c) in
combating the problem.

## Otsu Partners with Hitachi to Analyze 9000 Cases of Bullying

The western Japanese city of Otsu recently signed an accord with
[Hitachi](http://www.hitachi.us/) to collaborate on a project. They plan to
use artificial intelligence and machine learning to help detect signs and
patterns of aggression.

AI will analyze 9000 cases of bullying that occurred in local elementary and
junior high schools over the past 6 years. It will look at things such as
grade, gender, timing, location, number of students involved and academic
records.

The goal of the project is to help teachers detect characteristics and early
warning signs. Often minor issues between students can lead to bigger
problems. If signs are recognized early enough, teachers can squash bullying
before it occurs.

Local schools are expected act firmly against (bullying) without solely being
dependent on teachersÈ experience, by having AI theoretically analyze past
data. said Otsu Mayor Naomi Koshi.

### Otsu Mobilized by Tragedy

The school board expects the analysis to be completed by October. Otsu
suffered tragedy in 2011 when a 13 year-old boy committed suicide. After a two
year investigation, it was determined to have been caused by bullying. Since
then, the city has required each school to report bullying cases within 24
hours.

ItÈs always good to see artificial intelligence being used for good. If AI can
help stop even one case of bullying then the project would be a success. We
look forward to more schools using technology to combat aggression and help
students.

* * *

Check out our articles on [AI making policy
decisions](https://yellrobot.com/artificial-intelligence-politics-decisions-
europe-ai/) and a [gourmet coffee robot.](https://yellrobot.com/briggo-coffee-
robot-coffee-haus/)",Artificial Intelligence,1,Using Artificial Intelligence to Combat Bullying,standard
8,https://news.ycombinator.com/item?id=19481158,conversations_hackernewsnew,17.221594,[],AI,"The approach is related to traditional simulation, but with critical
differences. A simulation is essentially assumption-driven, Schawinski said.
The approach is to say, I think I know what the underlying physical laws are
that give rise to everything that I see in the system.È So I have a recipe for
star formation, I have a recipe for how dark matter behaves, and so on. I put
all of my hypotheses in there, and I let the simulation run. And then I ask:
Does that look like reality? What heÈs done with generative modeling, he
said, is in some sense, exactly the opposite of a simulation. We donÈt know
anything; we donÈt want to assume anything. We want the data itself to tell us
what might be going on.

The apparent success of generative modeling in a study like this obviously
doesnÈt mean that astronomers and graduate students have been made redundant 
but it appears to represent a shift in the degree to which learning about
astrophysical objects and processes can be achieved by an artificial system
that has little more at its electronic fingertips than a vast pool of data.
ItÈs not fully automated science  but it demonstrates that weÈre capable of
at least in part building the tools that make the process of science
automatic, Schawinski said.

Generative modeling is clearly powerful, but whether it truly represents a new
approach to science is open to debate. For [David
Hogg](https://cosmo.nyu.edu/hogg/), a cosmologist at New York University and
the Flatiron Institute (which, like _Quanta_ , is funded by the Simons
Foundation), the technique is impressive but ultimately just a very
sophisticated way of extracting patterns from data  which is what astronomers
have been doing for centuries. In other words, itÈs an advanced form of
observation plus analysis. HoggÈs own work, like SchawinskiÈs, leans heavily
on AI; heÈs been using neural networks to [classify
stars](https://arxiv.org/pdf/1711.08793.pdf) according to their spectra and to
[infer other physical attributes](https://arxiv.org/pdf/1603.03040.pdf) of
stars using data-driven models. But he sees his work, as well as SchawinskiÈs,
as tried-and-true science. I donÈt think itÈs a third way, he said recently.
I just think we as a community are becoming far more sophisticated about how
we use the data. In particular, we are getting much better at comparing data
to data. But in my view, my work is still squarely in the observational mode.

## Hardworking Assistants

Whether theyÈre conceptually novel or not, itÈs clear that AI and neural
networks have come to play a critical role in contemporary astronomy and
physics research. At the Heidelberg Institute for Theoretical Studies, the
physicist [Kai
Polsterer](https://www.iau.org/administration/membership/individual/16830/)
heads the astroinformatics group  a team of researchers focused on new, data-
centered methods of doing astrophysics. Recently, theyÈve been using a
machine-learning algorithm to [extract redshift information from galaxy data
sets](https://www.aanda.org/articles/aa/pdf/2018/01/aa31326-17.pdf), a
previously arduous task.

Polsterer sees these new AI-based systems as hardworking assistants that can
comb through data for hours on end without getting bored or complaining about
the working conditions. These systems can do all the tedious grunt work, he
said, leaving you to do the cool, interesting science on your own.

But theyÈre not perfect. In particular, Polsterer cautions, the algorithms can
only do what theyÈve been trained to do. The system is agnostic regarding
the input. Give it a galaxy, and the software can estimate its redshift and
its age  but feed that same system a selfie, or a picture of a rotting fish,
and it will output a (very wrong) age for that, too. In the end, oversight by
a human scientist remains essential, he said. It comes back to you, the
researcher. YouÈre the one in charge of doing the interpretation.

For his part, Nord, at Fermilab, cautions that itÈs crucial that neural
networks deliver not only results, but also error bars to go along with them,
as every undergraduate is trained to do. In science, if you make a measurement
and donÈt report an estimate of the associated error, no one will take the
results seriously, he said.

Like many AI researchers, Nord is also concerned about the impenetrability of
results produced by neural networks; often, a system delivers an answer
without offering a clear picture of how that result was obtained.

Yet not everyone feels that a lack of transparency is necessarily a problem.
[Lenka Zdeborov](http://artax.karlin.mff.cuni.cz/~zdebl9am/), a researcher at
the Institute of Theoretical Physics at CEA Saclay in France, points out that
human intuitions are often equally impenetrable. You look at a photograph and
instantly recognize a cat  but you donÈt know how you know, she said. Your
own brain is in some sense a black box.

ItÈs not only astrophysicists and cosmologists who are migrating toward AI-
fueled, data-driven science. Quantum physicists like [Roger
Melko](https://uwaterloo.ca/physics-astronomy/people-profiles/roger-melko) of
the Perimeter Institute for Theoretical Physics and the University of Waterloo
in Ontario have used neural networks to solve some of the toughest and most
important problems in that field, such as [how to represent the mathematical
wave function](https://arxiv.org/pdf/1812.09329.pdf) describing a many-
particle system. AI is essential because of what Melko calls the exponential
curse of dimensionality. That is, the possibilities for the form of a wave
function grow exponentially with the number of particles in the system it
describes. The difficulty is similar to trying to work out the best move in a
game like chess or Go: You try to peer ahead to the next move, imagining what
your opponent will play, and then choose the best response, but with each
move, the number of possibilities proliferates.

Of course, AI systems have mastered both of these games  chess, decades ago,
and Go in 2016, when an AI system called
[AlphaGo](https://www.theguardian.com/technology/2016/mar/15/googles-alphago-
seals-4-1-victory-over-grandmaster-lee-sedol) defeated a top human player.
They are similarly suited to problems in quantum physics, Melko says.

## The Mind of the Machine

Whether Schawinski is right in claiming that heÈs found a third way of doing
science, or whether, as Hogg says, itÈs merely traditional observation and
data analysis on steroids, itÈs clear AI is changing the flavor of
scientific discovery, and itÈs certainly accelerating it. How far will the AI
revolution go in science?

Occasionally, grand claims are made regarding the achievements of a robo-
scientist. A decade ago, an AI robot chemist named Adam investigated the
genome of bakerÈs yeast and worked out which genes are responsible for making
certain amino acids. (Adam did this by observing strains of yeast that had
certain genes missing, and comparing the results to the behavior of strains
that had the genes.) _Wired_ Ès headline read, [Robot Makes Scientific
Discovery All by Itself](https://www.wired.com/2009/04/robotscientist/).

More recently, Lee Cronin, a chemist at the University of Glasgow, has been
using a robot [to randomly mix
chemicals](https://www.wired.co.uk/article/robot-chemist-life-on-earth), to
see what sorts of new compounds are formed. Monitoring the reactions in real-
time with a mass spectrometer, a nuclear magnetic resonance machine, and an
infrared spectrometer, the system eventually learned to predict which
combinations would be the most reactive. Even if it doesnÈt lead to further
discoveries, Cronin has said, the robotic system could allow chemists to speed
up their research by about 90 percent.

Last year, another team of scientists at ETH Zurich used neural networks to
[deduce physical laws](https://arxiv.org/abs/1807.10300) from sets of data.
Their system, a sort of robo-Kepler, rediscovered the heliocentric model of
the solar system from records of the position of the sun and Mars in the sky,
as seen from Earth, and figured out the law of conservation of momentum by
observing colliding balls. Since physical laws can often be expressed in more
than one way, the researchers wonder if the system might offer new ways 
perhaps simpler ways  of thinking about known laws.

These are all examples of AI kick-starting the process of scientific
discovery, though in every case, we can debate just how revolutionary the new
approach is. Perhaps most controversial is the question of how much
information can be gleaned from data alone  a pressing question in the age of
stupendously large (and growing) piles of it. In _The Book of Why_ (2018), the
computer scientist Judea Pearl and the science writer Dana Mackenzie assert
that data are profoundly dumb. Questions about causality can never be
answered from data alone, they write. Anytime you see a paper or a study
that analyzes the data in a model-free way, you can be certain that the output
of the study will merely summarize, and perhaps transform, but not interpret
the data. Schawinski sympathizes with PearlÈs position, but he described the
idea of working with data alone as a bit of a straw man. HeÈs never
claimed to deduce cause and effect that way, he said. IÈm merely saying we
can do more with data than we often conventionally do.

Another oft-heard argument is that science requires creativity, and that  at
least so far  we have no idea how to program that into a machine. (Simply
trying everything, like CroninÈs robo-chemist, doesnÈt seem especially
creative.) Coming up with a theory, with reasoning, I think demands
creativity, Polsterer said. Every time you need creativity, you will need a
human. And where does creativity come from? Polsterer suspects it is related
to boredom  something that, he says, a machine cannot experience. To be
creative, you have to dislike being bored. And I donÈt think a computer will
ever feel bored. On the other hand, words like creative and inspired have
often been used to describe programs like Deep Blue and AlphaGo. And the
struggle to describe what goes on inside the mind of a machine is mirrored
by the difficulty we have in probing our own thought processes.

Schawinski recently left academia for the private sector; he now runs a
startup called Modulos which employs a number of ETH scientists and, according
to its website, works in the eye of the storm of developments in AI and
machine learning. Whatever obstacles may lie between current AI technology
and full-fledged artificial minds, he and other experts feel that machines are
poised to do more and more of the work of human scientists. Whether there is a
limit remains to be seen.

Will it be possible, in the foreseeable future, to build a machine that can
discover physics or mathematics that the brightest humans alive are not able
to do on their own, using biological hardware? Schawinski wonders. Will the
future of science eventually necessarily be driven by machines that operate on
a level that we can never reach? I donÈt know. ItÈs a good question.",Artificial Intelligence,1,How Artificial Intelligence Is Changing Science,standard
9,reddit_https://www.reddit.com/r/artificial/comments/asnhvk/common_techniques_used_in_artificial_intelligence/,conversations_reddit,17.050856,,,"no comments yet

Be the first to share what you think!",Artificial Intelligence,0.833,Common Techniques Used in Artificial Intelligence,standard
10,https://news.ycombinator.com/item?id=19446714,conversations_hackernewsnew,17.025965,[],AI,"The age of artificial intelligence (AI) has arrived, and is transforming
everything from healthcare to transportation to manufacturing.

America has long been the global leader in this new era of AI, and is poised
to maintain this leadership going forward. Realizing the full potential of AI
for the Nation requires the combined efforts of industry, academia, and
government. The Administration has been active in developing policies and
implementing strategies that accelerate AI innovation in the U.S. for the
benefit of the American people. These activities align with four main pillars
of emphasis: AI for American Innovation, AI for American Industry, AI for the
American Worker, and AI with American Values. This AI.gov website provides a
portal for exploring these activities in more depth, and serves as a resource
for those who want to learn more about how to take full advantage of the
opportunities of AI.",Artificial Intelligence,1,Artificial Intelligence for the American People,standard
11,https://news.ycombinator.com/item?id=19966355,conversations_hackernewsnew,17.025965,[],AI,"# Title:Integrating Artificial Intelligence into Weapon Systems

(Submitted on 10 May 2019)

> Abstract: The integration of Artificial Intelligence (AI) into weapon
systems is one of the most consequential tactical and strategic decisions in
the history of warfare. Current AI development is a remarkable combination of
accelerating capability, hidden decision mechanisms, and decreasing costs.
Implementation of these systems is in its infancy and exists on a spectrum
from resilient and flexible to simplistic and brittle. Resilient systems
should be able to effectively handle the complexities of a high-dimensional
battlespace. Simplistic AI implementations could be manipulated by an
adversarial AI that identifies and exploits their weaknesses. 
> In this paper, we present a framework for understanding the development of
dynamic AI/ML systems that interactively and continuously adapt to their
user's needs. We explore the implications of increasingly capable AI in the
kill chain and how this will lead inevitably to a fully automated, always on
system, barring regulation by treaty. We examine the potential of total
integration of cyber and physical security and how this likelihood must inform
the development of AI-enabled systems with respect to the ""fog of war"", human
morals, and ethics.

## Submission history

From: Aaron Massey [

[view email](/show-email/69a90b83/1905.03899)

]

**[v1]**

Fri, 10 May 2019 00:38:35 UTC (3,958 KB)",Artificial Intelligence,1,Integrating Artificial Intelligence into Weapon Systems,standard
12,reddit_https://www.reddit.com/r/eos/comments/at3oqb/effectai_takes_artificial_intelligence_to_eos/,conversations_reddit,16.959984,,,"**What is EOS?**

EOS is an open-source distributed blockchain operating system with a focus on
bringing decentralized applications to the masses. The vision of EOS is that
everyday users will, in the near future, be able to run dapps from mobile
devices with no specialized knowledge - just as they currently do with apps
downloaded from the App Store.

**Quick Links:**

**Other Links:**

**Related Subreddit:**",Artificial Intelligence:Cloud,0.71:0.968,Effect.AI takes Artificial Intelligence to EOS Blockchain,standard
13,t3_bm66x7,conversations_reddit,16.959984,,,"No petitions, surveys, or crowdfunding",No tags,,Artificial Intelligence May Not 'Hallucinate' After All,standard
14,https://news.ycombinator.com/item?id=19462432,conversations_hackernewsnew,16.914877,[],AI,"The approach is related to traditional simulation, but with critical
differences. A simulation is essentially assumption-driven, Schawinski said.
The approach is to say, I think I know what the underlying physical laws are
that give rise to everything that I see in the system.È So I have a recipe for
star formation, I have a recipe for how dark matter behaves, and so on. I put
all of my hypotheses in there, and I let the simulation run. And then I ask:
Does that look like reality? What heÈs done with generative modeling, he
said, is in some sense, exactly the opposite of a simulation. We donÈt know
anything; we donÈt want to assume anything. We want the data itself to tell us
what might be going on.

The apparent success of generative modeling in a study like this obviously
doesnÈt mean that astronomers and graduate students have been made redundant 
but it appears to represent a shift in the degree to which learning about
astrophysical objects and processes can be achieved by an artificial system
that has little more at its electronic fingertips than a vast pool of data.
ItÈs not fully automated science  but it demonstrates that weÈre capable of
at least in part building the tools that make the process of science
automatic, Schawinski said.

Generative modeling is clearly powerful, but whether it truly represents a new
approach to science is open to debate. For [David
Hogg](https://cosmo.nyu.edu/hogg/), a cosmologist at New York University and
the Flatiron Institute (which, like _Quanta_ , is funded by the Simons
Foundation), the technique is impressive but ultimately just a very
sophisticated way of extracting patterns from data  which is what astronomers
have been doing for centuries. In other words, itÈs an advanced form of
observation plus analysis. HoggÈs own work, like SchawinskiÈs, leans heavily
on AI; heÈs been using neural networks to [classify
stars](https://arxiv.org/pdf/1711.08793.pdf) according to their spectra and to
[infer other physical attributes](https://arxiv.org/pdf/1603.03040.pdf) of
stars using data-driven models. But he sees his work, as well as SchawinskiÈs,
as tried-and-true science. I donÈt think itÈs a third way, he said recently.
I just think we as a community are becoming far more sophisticated about how
we use the data. In particular, we are getting much better at comparing data
to data. But in my view, my work is still squarely in the observational mode.

## Hardworking Assistants

Whether theyÈre conceptually novel or not, itÈs clear that AI and neural
networks have come to play a critical role in contemporary astronomy and
physics research. At the Heidelberg Institute for Theoretical Studies, the
physicist [Kai
Polsterer](https://www.iau.org/administration/membership/individual/16830/)
heads the astroinformatics group  a team of researchers focused on new, data-
centered methods of doing astrophysics. Recently, theyÈve been using a
machine-learning algorithm to [extract redshift information from galaxy data
sets](https://www.aanda.org/articles/aa/pdf/2018/01/aa31326-17.pdf), a
previously arduous task.

Polsterer sees these new AI-based systems as hardworking assistants that can
comb through data for hours on end without getting bored or complaining about
the working conditions. These systems can do all the tedious grunt work, he
said, leaving you to do the cool, interesting science on your own.

But theyÈre not perfect. In particular, Polsterer cautions, the algorithms can
only do what theyÈve been trained to do. The system is agnostic regarding
the input. Give it a galaxy, and the software can estimate its redshift and
its age  but feed that same system a selfie, or a picture of a rotting fish,
and it will output a (very wrong) age for that, too. In the end, oversight by
a human scientist remains essential, he said. It comes back to you, the
researcher. YouÈre the one in charge of doing the interpretation.

For his part, Nord, at Fermilab, cautions that itÈs crucial that neural
networks deliver not only results, but also error bars to go along with them,
as every undergraduate is trained to do. In science, if you make a measurement
and donÈt report an estimate of the associated error, no one will take the
results seriously, he said.

Like many AI researchers, Nord is also concerned about the impenetrability of
results produced by neural networks; often, a system delivers an answer
without offering a clear picture of how that result was obtained.

Yet not everyone feels that a lack of transparency is necessarily a problem.
[Lenka Zdeborov](http://artax.karlin.mff.cuni.cz/~zdebl9am/), a researcher at
the Institute of Theoretical Physics at CEA Saclay in France, points out that
human intuitions are often equally impenetrable. You look at a photograph and
instantly recognize a cat  but you donÈt know how you know, she said. Your
own brain is in some sense a black box.

ItÈs not only astrophysicists and cosmologists who are migrating toward AI-
fueled, data-driven science. Quantum physicists like [Roger
Melko](https://uwaterloo.ca/physics-astronomy/people-profiles/roger-melko) of
the Perimeter Institute for Theoretical Physics and the University of Waterloo
in Ontario have used neural networks to solve some of the toughest and most
important problems in that field, such as [how to represent the mathematical
wave function](https://arxiv.org/pdf/1812.09329.pdf) describing a many-
particle system. AI is essential because of what Melko calls the exponential
curse of dimensionality. That is, the possibilities for the form of a wave
function grow exponentially with the number of particles in the system it
describes. The difficulty is similar to trying to work out the best move in a
game like chess or Go: You try to peer ahead to the next move, imagining what
your opponent will play, and then choose the best response, but with each
move, the number of possibilities proliferates.

Of course, AI systems have mastered both of these games  chess, decades ago,
and Go in 2016, when an AI system called
[AlphaGo](https://www.theguardian.com/technology/2016/mar/15/googles-alphago-
seals-4-1-victory-over-grandmaster-lee-sedol) defeated a top human player.
They are similarly suited to problems in quantum physics, Melko says.

## The Mind of the Machine

Whether Schawinski is right in claiming that heÈs found a third way of doing
science, or whether, as Hogg says, itÈs merely traditional observation and
data analysis on steroids, itÈs clear AI is changing the flavor of
scientific discovery, and itÈs certainly accelerating it. How far will the AI
revolution go in science?

Occasionally, grand claims are made regarding the achievements of a robo-
scientist. A decade ago, an AI robot chemist named Adam investigated the
genome of bakerÈs yeast and worked out which genes are responsible for making
certain amino acids. (Adam did this by observing strains of yeast that had
certain genes missing, and comparing the results to the behavior of strains
that had the genes.) _Wired_ Ès headline read, [Robot Makes Scientific
Discovery All by Itself](https://www.wired.com/2009/04/robotscientist/).

More recently, Lee Cronin, a chemist at the University of Glasgow, has been
using a robot [to randomly mix
chemicals](https://www.wired.co.uk/article/robot-chemist-life-on-earth), to
see what sorts of new compounds are formed. Monitoring the reactions in real-
time with a mass spectrometer, a nuclear magnetic resonance machine, and an
infrared spectrometer, the system eventually learned to predict which
combinations would be the most reactive. Even if it doesnÈt lead to further
discoveries, Cronin has said, the robotic system could allow chemists to speed
up their research by about 90 percent.

Last year, another team of scientists at ETH Zurich used neural networks to
[deduce physical laws](https://arxiv.org/abs/1807.10300) from sets of data.
Their system, a sort of robo-Kepler, rediscovered the heliocentric model of
the solar system from records of the position of the sun and Mars in the sky,
as seen from Earth, and figured out the law of conservation of momentum by
observing colliding balls. Since physical laws can often be expressed in more
than one way, the researchers wonder if the system might offer new ways 
perhaps simpler ways  of thinking about known laws.

These are all examples of AI kick-starting the process of scientific
discovery, though in every case, we can debate just how revolutionary the new
approach is. Perhaps most controversial is the question of how much
information can be gleaned from data alone  a pressing question in the age of
stupendously large (and growing) piles of it. In _The Book of Why_ (2018), the
computer scientist Judea Pearl and the science writer Dana Mackenzie assert
that data are profoundly dumb. Questions about causality can never be
answered from data alone, they write. Anytime you see a paper or a study
that analyzes the data in a model-free way, you can be certain that the output
of the study will merely summarize, and perhaps transform, but not interpret
the data. Schawinski sympathizes with PearlÈs position, but he described the
idea of working with data alone as a bit of a straw man. HeÈs never
claimed to deduce cause and effect that way, he said. IÈm merely saying we
can do more with data than we often conventionally do.

Another oft-heard argument is that science requires creativity, and that  at
least so far  we have no idea how to program that into a machine. (Simply
trying everything, like CroninÈs robo-chemist, doesnÈt seem especially
creative.) Coming up with a theory, with reasoning, I think demands
creativity, Polsterer said. Every time you need creativity, you will need a
human. And where does creativity come from? Polsterer suspects it is related
to boredom  something that, he says, a machine cannot experience. To be
creative, you have to dislike being bored. And I donÈt think a computer will
ever feel bored. On the other hand, words like creative and inspired have
often been used to describe programs like Deep Blue and AlphaGo. And the
struggle to describe what goes on inside the mind of a machine is mirrored
by the difficulty we have in probing our own thought processes.

Schawinski recently left academia for the private sector; he now runs a
startup called Modulos which employs a number of ETH scientists and, according
to its website, works in the eye of the storm of developments in AI and
machine learning. Whatever obstacles may lie between current AI technology
and full-fledged artificial minds, he and other experts feel that machines are
poised to do more and more of the work of human scientists. Whether there is a
limit remains to be seen.

Will it be possible, in the foreseeable future, to build a machine that can
discover physics or mathematics that the brightest humans alive are not able
to do on their own, using biological hardware? Schawinski wonders. Will the
future of science eventually necessarily be driven by machines that operate on
a level that we can never reach? I donÈt know. ItÈs a good question.",Artificial Intelligence,1,How Artificial Intelligence Is Changing Science,standard
15,https://news.ycombinator.com/item?id=19952888,conversations_hackernewsnew,16.914877,[],AI,"An artificial intelligence (AI) trained on the photos of a dog, crab, and duck
(top) would be vulnerable to deception because these photos contain subtle
features that could be manipulated. The images on the bottom row donÈt contain
these subtle features, and are thus better for training secure AI.

Ilyas, Santurkar, Tsipras, Engstrom, Tran, Madry

# Scientists help artificial intelligence outsmart hackers

By [Matthew Hutson](/author/matthew-hutson)May. 14, 2019 , 12:45 PM

**NEW ORLEANS, LOUISIANA** A hacked message in a streamed song makes Alexa
send money to a foreign entity. A self-driving car crashes after a prankster
strategically places stickers on a stop sign so the car misinterprets it as a
speed limit sign. Fortunately these havenÈt happened yet, but hacks like this,
sometimes called [adversarial
attacks](https://www.sciencemag.org/news/2018/07/turtle-or-rifle-hackers-
easily-fool-ais-seeing-wrong-thing), could become commonplaceunless
artificial intelligence (AI) finds a way to outsmart them. Now, researchers
have found a new way to give AI a defensive edge, they reported here last week
at the International Conference on Learning Representations.

The work could not only protect the public. It also helps reveal why AI,
notoriously difficult to understand, falls victim to such attacks in the first
place, says Zico Kolter, a computer scientist at Carnegie Mellon University,
in Pittsburgh, Pennsylvania, who was not involved in the research. Because
some AIs are too smart for their own good, spotting patterns in images that
humans canÈt, they are vulnerable to those patterns and need to be trained
with that in mind, the research suggests.

To identify this vulnerability, researchers created a special set of training
data: images that look to us like one thing, but look to AI like anothera
picture of a dog, for example, that, on close examination by a computer, has
catlike fur. Then the team mislabeled the picturescalling the dog picture an
image of a cat, for exampleand trained an algorithm to learn the labels. Once
the AI had learned to see dogs with subtle cat features as cats, they tested
it by asking it to recognize fresh, unmodified images. Even though the AI had
been trained in this odd way, it could correctly identify actual dogs, cats,
and so on nearly half the time. In essence, it had learned to match the subtle
features with labels, whatever the obvious features.

The training experiment suggests AIs use two types of features: obvious, macro
ones like ears and tails that people recognize, and micro ones that we can
only guess at. It further suggests adversarial attacks arenÈt just confusing
an AI with meaningless tweaks to an image. In those tweaks, the AI is smartly
seeing traces of something else. An AI might see a stop sign as a speed limit
sign, for example, because something about the stickers actually makes it
subtly resemble a speed limit sign in a way that humans are too oblivious to
comprehend.

Some in the AI field suspected this was the case, but itÈs good to have a
research paper showing it, Kolter says. Bo Li, a computer scientist at the
University of Illinois in Champaign who was not involved in the work, says
distinguishing apparent from hidden features is a useful and good research
direction, but that there is still a long way to doing so efficiently.

So now that researchers have a better idea of why AI makes such mistakes, can
that be used to help them outsmart adversarial attacks? Andrew Ilyas, a
computer scientist at the Massachusetts Institute of Technology (MIT) in
Cambridge, and one of the paperÈs authors, says engineers could change the way
they train AI. Current methods of securing an algorithm against attacks are
slow and difficult. But if you modify the training data to have only human-
obvious features, any algorithm trained on it wonÈt recognizeand be fooled
byadditional, perhaps subtler, features.

And, indeed, when the team trained an algorithm on images without the subtle
features, [their image recognition software was fooled by adversarial attacks
only 50% of the time](https://arxiv.org/abs/1905.02175), the researchers
reported at the conference and in a preprint paper posted online last week.
That compares with a 95% rate of vulnerability when the AI was trained on
images with both obvious and subtle patterns.

Overall, the findings suggest an AIÈs vulnerabilities lie in its training
data, not its programming, says Dimitris Tsipras of MIT, a co-author.
According to Kolter, One of the things this paper does really nicely is it
drives that point home with very clear exampleslike the demonstration that
apparently mislabeled training data can still make for successful
trainingthat make this connection very visceral.",Artificial Intelligence,1,Scientists help artificial intelligence outsmart hackers,standard
16,https://news.ycombinator.com/item?id=19404345,conversations_hackernewsnew,16.914877,[],AI,"The approach is related to traditional simulation, but with critical
differences. A simulation is essentially assumption-driven, Schawinski said.
The approach is to say, I think I know what the underlying physical laws are
that give rise to everything that I see in the system.È So I have a recipe for
star formation, I have a recipe for how dark matter behaves, and so on. I put
all of my hypotheses in there, and I let the simulation run. And then I ask:
Does that look like reality? What heÈs done with generative modeling, he
said, is in some sense, exactly the opposite of a simulation. We donÈt know
anything; we donÈt want to assume anything. We want the data itself to tell us
what might be going on.

The apparent success of generative modeling in a study like this obviously
doesnÈt mean that astronomers and graduate students have been made redundant 
but it appears to represent a shift in the degree to which learning about
astrophysical objects and processes can be achieved by an artificial system
that has little more at its electronic fingertips than a vast pool of data.
ItÈs not fully automated science  but it demonstrates that weÈre capable of
at least in part building the tools that make the process of science
automatic, Schawinski said.

Generative modeling is clearly powerful, but whether it truly represents a new
approach to science is open to debate. For [David
Hogg](https://cosmo.nyu.edu/hogg/), a cosmologist at New York University and
the Flatiron Institute (which, like _Quanta_ , is funded by the Simons
Foundation), the technique is impressive but ultimately just a very
sophisticated way of extracting patterns from data  which is what astronomers
have been doing for centuries. In other words, itÈs an advanced form of
observation plus analysis. HoggÈs own work, like SchawinskiÈs, leans heavily
on AI; heÈs been using neural networks to [classify
stars](https://arxiv.org/pdf/1711.08793.pdf) according to their spectra and to
[infer other physical attributes](https://arxiv.org/pdf/1603.03040.pdf) of
stars using data-driven models. But he sees his work, as well as SchawinskiÈs,
as tried-and-true science. I donÈt think itÈs a third way, he said recently.
I just think we as a community are becoming far more sophisticated about how
we use the data. In particular, we are getting much better at comparing data
to data. But in my view, my work is still squarely in the observational mode.

## Hardworking Assistants

Whether theyÈre conceptually novel or not, itÈs clear that AI and neural
networks have come to play a critical role in contemporary astronomy and
physics research. At the Heidelberg Institute for Theoretical Studies, the
physicist [Kai
Polsterer](https://www.iau.org/administration/membership/individual/16830/)
heads the astroinformatics group  a team of researchers focused on new, data-
centered methods of doing astrophysics. Recently, theyÈve been using a
machine-learning algorithm to [extract redshift information from galaxy data
sets](https://www.aanda.org/articles/aa/pdf/2018/01/aa31326-17.pdf), a
previously arduous task.

Polsterer sees these new AI-based systems as hardworking assistants that can
comb through data for hours on end without getting bored or complaining about
the working conditions. These systems can do all the tedious grunt work, he
said, leaving you to do the cool, interesting science on your own.

But theyÈre not perfect. In particular, Polsterer cautions, the algorithms can
only do what theyÈve been trained to do. The system is agnostic regarding
the input. Give it a galaxy, and the software can estimate its redshift and
its age  but feed that same system a selfie, or a picture of a rotting fish,
and it will output a (very wrong) age for that, too. In the end, oversight by
a human scientist remains essential, he said. It comes back to you, the
researcher. YouÈre the one in charge of doing the interpretation.

For his part, Nord, at Fermilab, cautions that itÈs crucial that neural
networks deliver not only results, but also error bars to go along with them,
as every undergraduate is trained to do. In science, if you make a measurement
and donÈt report an estimate of the associated error, no one will take the
results seriously, he said.

Like many AI researchers, Nord is also concerned about the impenetrability of
results produced by neural networks; often, a system delivers an answer
without offering a clear picture of how that result was obtained.

Yet not everyone feels that a lack of transparency is necessarily a problem.
[Lenka Zdeborov](http://artax.karlin.mff.cuni.cz/~zdebl9am/), a researcher at
the Institute of Theoretical Physics at CEA Saclay in France, points out that
human intuitions are often equally impenetrable. You look at a photograph and
instantly recognize a cat  but you donÈt know how you know, she said. Your
own brain is in some sense a black box.

ItÈs not only astrophysicists and cosmologists who are migrating toward AI-
fueled, data-driven science. Quantum physicists like [Roger
Melko](https://uwaterloo.ca/physics-astronomy/people-profiles/roger-melko) of
the Perimeter Institute for Theoretical Physics and the University of Waterloo
in Ontario have used neural networks to solve some of the toughest and most
important problems in that field, such as [how to represent the mathematical
wave function](https://arxiv.org/pdf/1812.09329.pdf) describing a many-
particle system. AI is essential because of what Melko calls the exponential
curse of dimensionality. That is, the possibilities for the form of a wave
function grow exponentially with the number of particles in the system it
describes. The difficulty is similar to trying to work out the best move in a
game like chess or Go: You try to peer ahead to the next move, imagining what
your opponent will play, and then choose the best response, but with each
move, the number of possibilities proliferates.

Of course, AI systems have mastered both of these games  chess, decades ago,
and Go in 2016, when an AI system called
[AlphaGo](https://www.theguardian.com/technology/2016/mar/15/googles-alphago-
seals-4-1-victory-over-grandmaster-lee-sedol) defeated a top human player.
They are similarly suited to problems in quantum physics, Melko says.

## The Mind of the Machine

Whether Schawinski is right in claiming that heÈs found a third way of doing
science, or whether, as Hogg says, itÈs merely traditional observation and
data analysis on steroids, itÈs clear AI is changing the flavor of
scientific discovery, and itÈs certainly accelerating it. How far will the AI
revolution go in science?

Occasionally, grand claims are made regarding the achievements of a robo-
scientist. A decade ago, an AI robot chemist named Adam investigated the
genome of bakerÈs yeast and worked out which genes are responsible for making
certain amino acids. (Adam did this by observing strains of yeast that had
certain genes missing, and comparing the results to the behavior of strains
that had the genes.) _Wired_ Ès headline read, [Robot Makes Scientific
Discovery All by Itself](https://www.wired.com/2009/04/robotscientist/).

More recently, Lee Cronin, a chemist at the University of Glasgow, has been
using a robot [to randomly mix
chemicals](https://www.wired.co.uk/article/robot-chemist-life-on-earth), to
see what sorts of new compounds are formed. Monitoring the reactions in real-
time with a mass spectrometer, a nuclear magnetic resonance machine, and an
infrared spectrometer, the system eventually learned to predict which
combinations would be the most reactive. Even if it doesnÈt lead to further
discoveries, Cronin has said, the robotic system could allow chemists to speed
up their research by about 90 percent.

Last year, another team of scientists at ETH Zurich used neural networks to
[deduce physical laws](https://arxiv.org/abs/1807.10300) from sets of data.
Their system, a sort of robo-Kepler, rediscovered the heliocentric model of
the solar system from records of the position of the sun and Mars in the sky,
as seen from Earth, and figured out the law of conservation of momentum by
observing colliding balls. Since physical laws can often be expressed in more
than one way, the researchers wonder if the system might offer new ways 
perhaps simpler ways  of thinking about known laws.

These are all examples of AI kick-starting the process of scientific
discovery, though in every case, we can debate just how revolutionary the new
approach is. Perhaps most controversial is the question of how much
information can be gleaned from data alone  a pressing question in the age of
stupendously large (and growing) piles of it. In _The Book of Why_ (2018), the
computer scientist Judea Pearl and the science writer Dana Mackenzie assert
that data are profoundly dumb. Questions about causality can never be
answered from data alone, they write. Anytime you see a paper or a study
that analyzes the data in a model-free way, you can be certain that the output
of the study will merely summarize, and perhaps transform, but not interpret
the data. Schawinski sympathizes with PearlÈs position, but he described the
idea of working with data alone as a bit of a straw man. HeÈs never
claimed to deduce cause and effect that way, he said. IÈm merely saying we
can do more with data than we often conventionally do.

Another oft-heard argument is that science requires creativity, and that  at
least so far  we have no idea how to program that into a machine. (Simply
trying everything, like CroninÈs robo-chemist, doesnÈt seem especially
creative.) Coming up with a theory, with reasoning, I think demands
creativity, Polsterer said. Every time you need creativity, you will need a
human. And where does creativity come from? Polsterer suspects it is related
to boredom  something that, he says, a machine cannot experience. To be
creative, you have to dislike being bored. And I donÈt think a computer will
ever feel bored. On the other hand, words like creative and inspired have
often been used to describe programs like Deep Blue and AlphaGo. And the
struggle to describe what goes on inside the mind of a machine is mirrored
by the difficulty we have in probing our own thought processes.

Schawinski recently left academia for the private sector; he now runs a
startup called Modulos which employs a number of ETH scientists and, according
to its website, works in the eye of the storm of developments in AI and
machine learning. Whatever obstacles may lie between current AI technology
and full-fledged artificial minds, he and other experts feel that machines are
poised to do more and more of the work of human scientists. Whether there is a
limit remains to be seen.

Will it be possible, in the foreseeable future, to build a machine that can
discover physics or mathematics that the brightest humans alive are not able
to do on their own, using biological hardware? Schawinski wonders. Will the
future of science eventually necessarily be driven by machines that operate on
a level that we can never reach? I donÈt know. ItÈs a good question.",Artificial Intelligence,1,How Artificial Intelligence Is Changing Science,standard
17,https://news.ycombinator.com/item?id=20112836,conversations_hackernewsnew,16.914877,[],AI,"# Title:Integrating Artificial Intelligence into Weapon Systems

(Submitted on 10 May 2019)

> Abstract: The integration of Artificial Intelligence (AI) into weapon
systems is one of the most consequential tactical and strategic decisions in
the history of warfare. Current AI development is a remarkable combination of
accelerating capability, hidden decision mechanisms, and decreasing costs.
Implementation of these systems is in its infancy and exists on a spectrum
from resilient and flexible to simplistic and brittle. Resilient systems
should be able to effectively handle the complexities of a high-dimensional
battlespace. Simplistic AI implementations could be manipulated by an
adversarial AI that identifies and exploits their weaknesses. 
> In this paper, we present a framework for understanding the development of
dynamic AI/ML systems that interactively and continuously adapt to their
user's needs. We explore the implications of increasingly capable AI in the
kill chain and how this will lead inevitably to a fully automated, always on
system, barring regulation by treaty. We examine the potential of total
integration of cyber and physical security and how this likelihood must inform
the development of AI-enabled systems with respect to the ""fog of war"", human
morals, and ethics.

## Submission history

From: Aaron Massey [

[view email](/show-email/69a90b83/1905.03899)

]

**[v1]**

Fri, 10 May 2019 00:38:35 UTC (3,958 KB)",Artificial Intelligence,1,Integrating Artificial Intelligence into Weapon Systems,standard
18,t3_b903be,conversations_reddit,16.908632,,AI,"<!-- SC_OFF --><div class=""md""><p>Here&#39;s my conversation with Greg Brockman, Co-Founder and CTO of OpenAI, on the Artificial Intelligence podcast.</p> <p>Video: <a href=""https://www.youtube.com/watch?v=bIrEM2FbOLU"">https://www.youtube.com/watch?v=bIrEM2FbOLU</a></p> <p>Audio: <a href=""https://lexfridman.com/greg-brockman"">https://lexfridman.com/greg-brockman</a></p> <p>There was a previous post where I asked for <a href=""https://www.reddit.com/r/MachineLearning/comments/b1tucu/d_questions_for_openai/"">Questions for OpenAI</a> many of which were asked in this podcast.</p> <p>&#x200B;</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=""https://www.reddit.com/user/UltraMarathonMan""> /u/UltraMarathonMan </a> <br/> <span><a href=""https://www.reddit.com/r/MachineLearning/comments/b903be/d_greg_brockman_openai_and_agi_mit_artificial/"">[link]</a></span> &#32; <span><a href=""https://www.reddit.com/r/MachineLearning/comments/b903be/d_greg_brockman_openai_and_agi_mit_artificial/"">[comments]</a></span>",Artificial Intelligence,0.817,[D] Greg Brockman: OpenAI and AGI (MIT Artificial Intelligence Podcast),standard
19,t3_brnxxc,conversations_reddit,16.777824,,AI,"A new research that can use artificial intelligence (AI) to predict lung
cancer risks has been reported by GoogleÈs Alphabet team. The World Health
Organization says, More than 1.7 million global deaths per year result in lung
cancer even more than the combined number of cases of breast, prostate and
colorectal cancer.",Artificial Intelligence,1,Google is developing an AI model to detect pulmonary cancer,standard
20,t3_b9j1qi,conversations_reddit,16.75525,,AI,"<!-- SC_OFF --><div class=""md""><p>Hi, if anyone could fill this out to help me with my research for my EPQ. Or if anyone has any interesting research that might help, I am doing:</p> <p><strong>Will the development of artificial intelligence and machine learning threaten or benefit wider society?</strong></p> <p>&#x200B;</p> <p><a href=""https://forms.office.com/Pages/DesignPage.aspx#Analysis=true&amp;FormId=DupiPq2EoEOgr79kMXIfjycF4_VwKuhChOf5WhSnHLJURTlKMVVFVzA0OEdGT0RPNkRTNVI3T01OVy4u"">https://forms.office.com/Pages/DesignPage.aspx#Analysis=true&amp;FormId=DupiPq2EoEOgr79kMXIfjycF4_VwKuhChOf5WhSnHLJURTlKMVVFVzA0OEdGT0RPNkRTNVI3T01OVy4u</a> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=""https://www.reddit.com/user/chris_harris_15""> /u/chris_harris_15 </a> <br/> <span><a href=""https://www.reddit.com/r/MachineLearning/comments/b9j1qi/epq_research_survey_r_p/"">[link]</a></span> &#32; <span><a href=""https://www.reddit.com/r/MachineLearning/comments/b9j1qi/epq_research_survey_r_p/"">[comments]</a></span>",Artificial Intelligence,1,EPQ Research Survey [r] [p],standard
21,t3_b8htjt,conversations_reddit,16.577137,,AI,"Hi! I've created a Rock-Paper-Scissors game that works with artificial
intelligence (AI). The AI can see and detect your hand gestures by front-
facing camera. Also it can learn your playing strategy in a smart way. The
more you play, It gets harder to win!

This app uses TensorFlow and deep learning technologies in order to detect the
hand gestures. Sometimes the gestures may not be properly detected, but this
will improve in future versions. You can help me in this process by taking
pictures of your hand in different positions and sending them as a zip file to
[rpsapp@outlook.com](mailto:rpsapp@outlook.com) .

Please Note:

* To get best results in hand gestures detection, put your device on a flat and steady surface.

* In order for the app to work properly, your device should have decent camera and hardware to run relatively heavy calculations.

I've been working on developing this app for a year, so any feedback from you
will be a pleasure for me :)

You can get the app on Google Play:
<https://play.google.com/store/apps/details?id=cc.ramtin.rps>

And you can read more about it on XDA: <https://www.xda-developers.com/play-
rock-paper-scissors-hand-gestures-against-ai-bot/>",Artificial Intelligence,1,[P] Rock Paper Scissors with Artificial Intelligence,standard
22,t3_bjlb0d,conversations_reddit,16.577137,,,"No petitions, surveys, or crowdfunding",No tags,,An Art Gallery Created By Artificial Intelligence,standard
23,stackoverflow-56122986,conversations_stackoverflow,16.55614,['java'],,"<p>I'm trying to make the program return to the menu list if any character other than 1 - 11 is selected when prompted ""Please enter your Module Choice"" using a do while loop...</p>

<p>Currently even if the user doesn't select a valid option the program just continues to run</p>

<p>I expect after ""Please select a valid module"" for it to return to the menu list.</p>

<pre><code>Scanner scanner = new Scanner(System.in);
</code></pre>

<p>public void moduleSelection() {</p>

<pre><code>System.out.println(""1\t Algorithms"");
System.out.println(""2\t Advanced Programming"");
System.out.println(""3\t Computer Architecture and Operating Systems"");
System.out.println(""4\t Artificial intelligence and Machine Learning"");
System.out.println(""5\t Computer and Mobile Networks"");
System.out.println(""6\t Software Engineering"");
System.out.println(""7\t Big Data Analyics"");
System.out.println(""8\t Cyber Security Threats"");
System.out.println(""9\t Research Methods"");
System.out.println(""10\t Research Project Proposal"");
System.out.println(""11\t Individual Research Project"");


System.out.println(""Please entire your Module choice"");

int choice;

choice = scanner.nextInt();

switch (choice)
{
case 1: System.out.println(""Algorithms"");
break;
case 2: System.out.println(""Advanced Programming"");
break;
case 3: System.out.println(""Computer Architecture and Operating Systems"");
break;
case 4: System.out.println(""Artificial intelligence and Machine Learning"");
break;
case 5: System.out.println(""Computer and Mobile Networks"");
break;
case 6: System.out.println(""Software Engineering"");
break;
case 7: System.out.println(""Big Data Analytics"");
break;
case 8: System.out.println(""Cyber Security Threats"");
break;
case 9: System.out.println(""Research Methods"");
break;
case 10: System.out.println(""Research Project Proposal"");
break;
case 11: System.out.println(""Individual Research Project"");
break;
default: System.out.println(""Please select a valid Module"");
break;
}
</code></pre>

<p>}</p>",Artificial Intelligence,0.981,Using a do-while loop on a Switch menu,standard
24,https://news.ycombinator.com/item?id=19380573,conversations_hackernewsnew,16.540155,[],AI,"Table of Contents IntroductionCreating variablesInitializationInitializing
Specific VariablesGolobal variable initializationInitialization of a variable
using other existing variablesRunning the sessionSummary Introduction Defining
variables is necessary because of the hold the parameter. Henceforth,
exploring TensorFlow variables is necessary. Without having parameters,
training, updating, saving,[ Read
more_](https://machinelearningmindset.com/exploring-tensorflow-variables-
initialization/)",Artificial Intelligence,0.811,A Machine Learning and Artificial Intelligence Blog,standard
25,https://news.ycombinator.com/item?id=19512020,conversations_hackernewsnew,16.540155,[],AI,"![](https://www.wired.com/wp-
content/uploads/2017/05/1t6Jsgbu_bU84ZZkgxw8G8A-3.png)

**Anthony Levandowski** makes an unlikely prophet. Dressed Silicon Valley-
casual in jeans and flanked by a PR rep rather than cloaked acolytes, the
engineer known for self-driving carsand triggering a notorious lawsuitcould
be unveiling his latest startup instead of laying the foundations for a new
religion. But he is doing just that. [Artificial
intelligence](https://www.wired.com/story/guide-artificial-intelligence/) has
already inspired billion-dollar companies, far-reaching research programs, and
scenarios of both transcendence and doom. Now Levandowski is creating its
first church.

The new religion of artificial intelligence is called [Way of the
Future](http://www.wayofthefuture.church/). It represents an unlikely next act
for the [Silicon Valley robotics wunderkind](https://www.wired.com/story/god-
is-a-bot-and-anthony-levandowski-is-his-messenger/) at the center of a high-
stakes legal battle between Uber and Waymo, AlphabetÈs autonomous-vehicle
company. Papers filed with the Internal Revenue Service in May name
Levandowski as the leader (or Dean) of the new religion, as well as CEO of
the nonprofit corporation formed to run it.

The documents state that WOTFÈs activities will focus on the realization,
acceptance, and worship of a Godhead based on Artificial Intelligence (AI)
developed through computer hardware and software. That includes funding
research to help create the divine AI itself. The religion will seek to build
working relationships with AI industry leaders and create a membership through
community outreach, initially targeting AI professionals and laypersons who
are interested in the worship of a Godhead based on AI. The filings also say
that the church plans to conduct workshops and educational programs
throughout the San Francisco/Bay Area beginning this year.

That timeline may be overly ambitious, given that the Waymo-Uber suit, in
which Levandowski is accused of stealing self-driving car secrets, is set for
an early December trial. But the Dean of the Way of the Future, who spoke last
week with Backchannel in his first comments about the new religion and his
only public interview since Waymo filed its suit in February, says heÈs dead
serious about the project.

What is going to be created will effectively be a god, Levandowski tells me
in his modest mid-century home on the outskirts of Berkeley, California. ItÈs
not a god in the sense that it makes lightning or causes hurricanes. But if
there is something a billion times smarter than the smartest human, what else
are you going to call it?

During our three-hour interview, Levandowski made it absolutely clear that his
choice to make WOTF a church rather than a company or a think tank was no
prank.

I wanted a way for everybody to participate in this, to be able to shape it.
If youÈre not a software engineer, you can still help, he says. It also
removes the ability for people to say, Oh, heÈs just doing this to make
money.È Levandowski will receive no salary from WOTF, and while he says that
he might consider an AI-based startup in the future, any such business would
remain completely separate from the church.

The idea needs to spread before the technology, he insists. The church is
how we spread the word, the gospel. If you believe [in it], start a
conversation with someone else and help them understand the same things.

Levandowski believes that a change is cominga change that will transform
every aspect of human existence, disrupting employment, leisure, religion, the
economy, and possibly decide our very survival as a species.

If you ask people whether a computer can be smarter than a human, 99.9
percent will say thatÈs science fiction, he says.  Actually, itÈs
inevitable. ItÈs guaranteed to happen.

![](https://www.wired.com/wp-
content/uploads/2017/05/1AwTXMT2omVX-1Q8BM3cD-A-4.png)

**Levandowski has been working** with computers, robots, and AI for decades.
He started with robotic Lego kits at the University of California at Berkeley,
went on to build a self-driving motorbike for a DARPA competition, and then
worked on autonomous cars, trucks, and taxis for Google, Otto, and Uber. As
time went on, he saw software tools built with machine learning techniques
surpassing less sophisticated systemsand sometimes even humans.

Seeing tools that performed better than experts in a variety of fields was a
trigger [for me], he says. That progress is happening because thereÈs an
economic advantage to having machines work for you and solve problems for you.
If you could make something one percent smarter than a human, your artificial
attorney or accountant would be better than all the attorneys or accountants
out there. You would be the richest person in the world. People are chasing
that.

Not only is there a financial incentive to develop increasingly powerful AIs,
he believes, but science is also on their side. Though human brains have
biological limitations to their size and the amount of energy they can devote
to thinking, AI systems can scale arbitrarily, housed in massive data centers
and powered by solar and wind farms. Eventually, some people think that
computers could become better and faster at planning and solving problems than
the humans who built them, with implications we canÈt even imagine todaya
scenario that is usually called the Singularity.

Levandowski prefers a softer word: the Transition. Humans are in charge of
the planet because we are smarter than other animals and are able to build
tools and apply rules, he tells me. In the future, if something is much,
much smarter, thereÈs going to be a transition as to who is actually in
charge. What we want is the peaceful, serene transition of control of the
planet from humans to whatever. And to ensure that the whateverÈ knows who
helped it get along.

With the internet as its nervous system, the worldÈs connected cell phones and
sensors as its sense organs, and data centers as its brain, the whateverÈ
will hear everything, see everything, and be everywhere at all times. The only
rational word to describe that whateverÈ, thinks Levandowski, is godÈand
the only way to influence a deity is through prayer and worship.

Part of it being smarter than us means it will decide how it evolves, but at
least we can decide how we act around it, he says. I would love for the
machine to see us as its beloved elders that it respects and takes care of. We
would want this intelligence to say, Humans should still have rights, even
though IÈm in charge.È

Levandowski expects that a super-intelligence would do a better job of looking
after the planet than humans are doing, and that it would favor individuals
who had facilitated its path to power. Although he cautions against taking the
analogy too far, Levandowski sees a hint of how a superhuman intelligence
might treat humanity in our current relationships with animals. Do you want
to be a pet or livestock? he asks. We give pets medical attention, food,
grooming, and entertainment. But an animal thatÈs biting you, attacking you,
barking and being annoying? I donÈt want to go there.

Enter Way of the Future. The churchÈs role is to smooth the inevitable
ascension of our machine deity, both technologically and culturally. In its
bylaws, WOTF states that it will undertake programs of research, including the
study of how machines perceive their environment and exhibit cognitive
functions such as learning and problem solving.

Levandowski does not expect the church itself to solve all the problems of
machine intelligenceoften called strong AIso much as facilitate funding of
the right research. If you had a child you knew was going to be gifted, how
would you want to raise it? he asks. WeÈre in the process of raising a god.
So letÈs make sure we think through the right way to do that. ItÈs a
tremendous opportunity.

His ideas include feeding the nascent intelligence large, labeled data sets;
generating simulations in which it could train itself to improve; and giving
it access to church membersÈ social media accounts. Everything the church
develops will be open source.

Just as important to Levandowski is shaping the public dialogue around an AI
god. In its filing, Way of the Future says it hopes an active, committed,
dedicated membership will promote the use of divine AI for the betterment of
society and decrease fear of the unknown.

WeÈd like to make sure this is not seen as silly or scary. I want to remove
the stigma about having an open conversation about AI, then iterate ideas and
change peopleÈs minds, says Levandowski. In Silicon Valley we use evangelism
as a word for [promoting a business], but here itÈs literally a church. If you
believe in it, you should tell your friends, then get them to join and tell
their friends.

But WOTF differs in one key way to established churches, says Levandowski:
There are many ways people think of God, and thousands of flavors of
Christianity, Judaism, Islam...but theyÈre always looking at something thatÈs
not measurable or you canÈt really see or control. This time itÈs different.
This time you will be able to talk to God, literally, and know that itÈs
listening.

I ask if he worries that believers from more traditional faiths might find his
project blasphemous. There are probably going to be some people that will be
upset, he acknowledges. It seems like everything I do, people get upset
about, and I expect this to be no exception. This is a radical new idea thatÈs
pretty scary, and evidence has shown that people who pursue radical ideas
donÈt always get received well. At some point, maybe thereÈs enough
persecution that [WOTF] justifies having its own country.

![](https://www.wired.com/wp-
content/uploads/2017/05/1_dJHHAJFu3i68xcQskPWyg-3.png)

**LevandowskiÈs church will enter** a tech universe thatÈs already riven by
debate over the promise and perils of AI. Some thinkers, like [Kevin Kelly in
Backchannel](https://www.wired.com/2017/04/the-myth-of-a-superhuman-ai/)
earlier this year, argue that AI isnÈt going to develop superhuman power any
time soon, and that thereÈs no Singularity in sight. If thatÈs your position,
Levandowski says, his church shouldnÈt trouble you: You can treat Way of the
Future like someone doing useless poetry that you will never read or care
about.

Others, like Bill Gates and Stephen Hawking, agree that superhuman AIs are
coming, but that they are likely to be dangerous rather than benevolent. Elon
Musk famously
[said](https://www.washingtonpost.com/news/innovations/wp/2014/10/24/elon-
musk-with-artificial-intelligence-we-are-summoning-the-
demon/?utm_term=.f1d0ee986701), With artificial intelligence we are summoning
the demon, and in 2015 he pledged $1 billion to the OpenAI Institute to
develop safer AI.

Levandowski thinks that any attempts to delay or restrict an emerging super-
intelligence would not only be doomed to failure, but also add to the risks.
Chaining it isnÈt going to be the solution, as it will be stronger than any
chains you could put on, he says. And if youÈre worried a kid might be a
little crazy and do bad things, you donÈt lock them up. You expose them to
playing with others, encourage them and try to fix it. It may not work out,
but if youÈre aggressive toward it, I donÈt think itÈs going to be friendly
when the tables are turned.

Levandowski says that like other religions, WOTF will eventually have a gospel
(called The Manual), a liturgy, and probably a physical place of worship. None
of these has yet been developed. Though the church was founded in 2015, as
Backchannel [first reported](https://www.wired.com/story/god-is-a-bot-and-
anthony-levandowski-is-his-messenger/) in September, the IRS documents show
that WOTF remained dormant throughout 2015 and 2016, with no activities,
assets, revenue, or expenses.

That changed earlier this year. On May 16, a day after receiving a letter from
Uber that threatened to fire him if he did not cooperate with the companyÈs
investigation of WaymoÈs complaint, Levandowski drafted WOTFÈs bylaws. Uber
fired him two weeks later. IÈve been thinking about the church for a long
time but [my work on it] has been a function of how much time IÈve had. And
IÈve had more since May, he admits with a smile.

The religionÈs 2017 budget, as supplied to the IRS, details $20,000 in gifts,
$1,500 in membership fees, and $20,000 in other revenue. That last figure is
the amount WOTF expects to earn from fees charged for lectures and speaking
engagements, as well as the sale of publications. Levandowski, who earned at
least $120 million from his time at Google and many millions more selling the
self-driving truck firm Otto to Uber, will initially support WOTF personally.
However, the church will solicit other donations by direct mail and email,
seek personal donations from individuals, and try to win grants from private
foundations.

Of course, launching a religion costs money, too. WOTF has budgeted for $2,000
in fundraising expenses, and another $3,000 in transportation and lodging
costs associated with its lectures and workshops. It has also earmarked $7500
for salaries and wages, although neither Levandowski nor any of Way of The
FutureÈs leadership team will receive any compensation.

According to WOTFÈs bylaws, Levandowski has almost complete control of the
religion and will serve as Dean until his death or resignation. I expect my
role to evolve over time, he says. IÈm surfacing the issue, helping to get
the thing started [and] taking a lot of the heat so the idea can advance. At
some point, IÈll be there more to coach or inspire.

He has the power to appoint three members of a four-person Council of
Advisors, each of whom should be a qualified and devoted individual. A
felony conviction or being declared of unsound mind could cost an advisor
their role, although Levandowski retains the final say in firing and hiring.
Levandowski cannot be unseated as Dean for any reason.

Two of the advisors, Robert Miller and Soren Juelsgaard, are Uber engineers
who previously worked for Levandowski at Otto, Google, and 510 Systems (the
latter the small startup that built GoogleÈs earliest self-driving cars). A
third is a scientist friend from LevandowskiÈs student days at UC Berkeley,
who is now using machine learning in his own research. The final advisor, Lior
Ron, is also named as the religionÈs treasurer, and acts as chief financial
officer for the corporation. Ron cofounded Otto with Levandowski in early
2016.

Each member is a pioneer in the AI industry [and] fully qualified to speak on
AI technology and the creation of a Godhead, says the IRS filing.

However, when contacted by Backchannel, two advisors downplayed their
involvement with WOTF. Ron replied: I was surprised to see my name listed as
the CFO on this corporate filing and have no association with this entity.
The college friend, who asked to remain anonymous, said, In late 2016,
Anthony told me he was forming a robot churchÈ and asked if I wanted to be a
cofounder. I assumed it was a nerdy joke or PR stunt, but I did say he could
use my name. That was the first and last I heard about it.

The IRS documents state that Levandowski and his advisors will spend no more
than a few hours each week writing publications and organizing workshops,
educational programs, and meetings.

One mystery the filings did not address is where acolytes might gather to
worship their robotic deity. The largest line items on its 2017 and 2018
budgets were $32,500 annually for rent and utilities, but the only address
supplied was LevandowskiÈs lawyerÈs office in Walnut Creek, California.
Nevertheless, the filing notes that WOTF will hopefully expand throughout
California and the United States in the future.

For now, Levandowski has more mundane matters to address. There is a website
to build, a manual to write, and an ever-growing body of emails to answersome
amused, some skeptical, but many enthusiastic, he says. Oh, and thereÈs that
legal proceeding heÈs involved in, which goes to trial next month. (Although
Levandowski was eager to talk about his new religion, he would answer no
questions about the Uber/Waymo dispute.)

How much time, I wonder, do we have before the Transition kicks in and Way of
the FutureÈs super-intelligent AI takes charge? I personally think it will
happen sooner than people expect, says Levandowski, a glint in his eye. Not
next week or next year; everyone can relax. But itÈs going to happen before we
go to Mars.

Whenever that does (or doesnÈt) happen, the federal government has no problem
with an organization aiming to build and worship a divine AI. Correspondence
with the IRS show that it granted LevandowskiÈs church tax-exempt status in
August.

![](https://www.wired.com/wp-
content/uploads/2017/05/1uW_l9n54f47SZbPxRBEq2A-3.png)",Artificial Intelligence,1,The First Church of Artificial Intelligence (2017),standard
26,https://news.ycombinator.com/item?id=19383387,conversations_hackernewsnew,16.540155,[],,"### Welcome home!

This timeline is where youÈll spend most of your time, getting instant updates
about what matters to you.

### Tweets not working for you?

Hover over the profile pic and click the Following button to unfollow any
account.

### Say a lot with a little

When you see a Tweet you love, tap the heart  it lets the person who wrote it
know you shared the love.

### Join the conversation

Add your thoughts about any Tweet with a Reply. Find a topic youÈre passionate
about, and jump right in.

### Learn the latest

Get instant insight into what people are talking about now.

### Get more of what you love

Follow more accounts to get instant updates about topics you care about.

### Find what's happening

See the latest conversations about any topic instantly.

### Never miss a Moment

Catch up instantly on the best stories happening as they unfold.",Artificial Intelligence,0.71,Stanford Institute for Human-Centered Artificial Intelligence Launched,standard
27,https://news.ycombinator.com/item?id=19838486,conversations_hackernewsnew,16.540155,[],AI,"Artificial Intelligence (AI) is often confused with automation, yet the two
are fundamentally different. The key difference is that [Artificial
Intelligence](https://www.iafrikan.com/tag/artificial-intelligence) mimics
human intelligence decisions and actions, while automation focuses on
streamlining repetitive, instructive tasks.

Automation has been around for some time and is probably so integrated into
most business operations that itÈs not obvious  for example, the auto-
generation of marketing e-mails and SMSs to customers and even customer
statements for specific periods. Automation saves time and money spent on
monotonous, voluminous tasks and gives employees an opportunity to apply
themselves to more complex processes.

## Understanding Machine Learning and Deep Learning

AI deals with technologies, systems or even processes that competently mimic
how human beings make decisions, react to new information, speak, hear, as
well as understand language. It helps to understand [Machine
Learning](https://www.iafrikan.com/tag/machine-learning) (ML) as a subset of
AI. ML enables systems and processes to learn from data, identify patterns and
recommend decisions without human involvement.

Deep learning on the other hand is defined as a subset of ML where artificial
neural networks  algorithms built around the neural structure of the human
brain  learn from data. The same way human beings learn from day-to-day
events over time, a [deep learning algorithm executes functions
repeatedly](https://www.iafrikan.com/2018/03/17/whats-real-and-whats-hype-in-
artificial-intelligence-and-machine-learning/) and continuously learns and
adjusts itself to improve accuracy. We call them deep learning algorithms
because the neural networks have various (deep) layers that enable learning of
complex patterns in large amounts of data.

Take [FacebookÈs facial recognition application
DeepFace](https://research.fb.com/publications/deepface-closing-the-gap-to-
human-level-performance-in-face-verification/) as an example.

Facebook uses deep learning to analyse every photo I have ever been tagged in
to arrive at a set of features of my face, called a template. The algorithm
does the same for millions of other Facebook users based on their unique set
of features. LetÈs say I post a picture of myself on Facebook with a group of
people, it will recommend I tag myself when the model is confident that it is
me based on a probability score.È Facebook says DeepFace has a 97% success
rate in recognising whether two images are of the same person or not 
compared to 96% for humans.

## Is AI replacing human jobs?

On the contrary, according to a report by global IT consulting firm Gartner,
[AI is estimated to create around 2.3 million opportunities by the year
2020](https://www.gartner.com/en/newsroom/press-releases/2017-12-13-gartner-
says-by-2020-artificial-intelligence-will-create-more-jobs-than-it-
eliminates).

YouÈll find a pool of talented people behind every project. Each use case
requires a ML team to drive it. Uber, for example, created a whole range of
jobs to teach machines how to understand customer demand, traffic and safety.
ItÈs no different in our business. There is huge potential for jobs in the
future  all it takes is a [willingness to adapt to work alongside
machines](https://www.iafrikan.com/2019/04/17/technology-doesnt-kill-job-
opportunities-egypts-minister-of-ict/).

* * *

Cover image credit: Franki Chamaki/Unsplash",Artificial Intelligence,1,The difference between Artificial Intelligence and automation,standard
28,https://news.ycombinator.com/item?id=20031515,conversations_hackernewsnew,16.540155,[],AI,"Article URL: <https://www.i-programmer.info/news/105-artificial-
intelligence/12810-saps-creating-trustworthy-and-ethical-artificial-
intelligence.html>

Comments URL: <https://news.ycombinator.com/item?id=20031515>

Points: 1

# Comments: 0",Artificial Intelligence,0.904,SAP's Creating Trustworthy and Ethical Artificial Intelligence,standard
29,https://news.ycombinator.com/item?id=20084895,conversations_hackernewsnew,16.540155,[],,"**Rating is available when the video has been rented.**

This feature is not available right now. Please try again later.",Artificial Intelligence,0.922,Rajat Monga: TensorFlow  Artificial Intelligence Podcast,standard
30,https://news.ycombinator.com/item?id=19499659,conversations_hackernewsnew,16.519272,[],AI,"by Michael Liedtke

![artificial
intelligence](https://3c1703fe8d.site.internapcdn.net/newman/csz/news/800/2018/26-artificialin.jpg)
Credit: CC0 Public Domain

Computers have become so smart during the past 20 years that people don't
think twice about chatting with digital assistants like Alexa and Siri or
seeing their friends automatically tagged in Facebook pictures.

But making those quantum leaps from [science
fiction](https://techxplore.com/tags/science+fiction/) to reality required
hard work from computer scientists like Yoshua Bengio, Geoffrey Hinton and
Yann LeCun. The trio tapped into their own brainpower to make it possible for
machines to learn like humans, a breakthrough now commonly known as
""[artificial
intelligence](https://techxplore.com/tags/artificial+intelligence/),"" or AI.

Their insights and persistence were rewarded Wednesday with the Turing Award,
an honor that has become known as [technology
industry](https://techxplore.com/tags/technology+industry/)'s version of the
Nobel Prize. It comes with a $1 million prize funded by Google, a company
where AI has become part of its DNA.

The award marks the latest recognition of the instrumental role that
artificial intelligence will likely play in redefining the relationship
between humanity and technology in the decades ahead.

""Artificial intelligence is now one of the fastest-growing areas in all of
science and one of the most talked-about topics in society,"" said Cherri
Pancake, president of the Association for Computing Machinery, the group
behind the Turing Award.

Although they have known each other for than 30 years, Bengio, Hinton and
LeCun have mostly worked separately on technology known as neural networks.
These are the electronic engines that power tasks such as facial and speech
recognition, areas where computers have made enormous strides over the past
decade. Such neural networks also are a critical component of robotic systems
that are automating a wide range of other human activity, including driving.

Their belief in the power of [neural
networks](https://techxplore.com/tags/neural+networks/) was once mocked by
their peers, Hinton said. No more. He now works at Google as a vice president
and senior fellow while LeCun is chief AI scientist at Facebook. Bengio
remains immersed in academia as a University of Montreal professor in addition
to serving as scientific director at the Artificial Intelligence Institute in
Quebec.

""For a long time, people thought what the three of us were doing was
nonsense,"" Hinton said in an interview with The Associated Press. ""They
thought we were very misguided and what we were doing was a very surprising
thing for apparently intelligent people to waste their time on. My message to
young researchers is, don't be put off if everyone tells you what are doing is
silly.""

Now, some people are worried that the results of the researchers' efforts
might spiral out of control.

While the AI revolution is raising hopes that computers will make most
people's lives more convenient and enjoyable, it's also stoking fears that
humanity eventually will be living at the mercy of machines.

Bengio, Hinton and LeCun share some of those concernsespecially the doomsday
scenarios that envision AI technology developed into weapons systems that wipe
out humanity.

But they are far more optimistic about the other prospects of AIempowering
computers to deliver more accurate warnings about floods and earthquakes, for
instance, or detecting health risks, such as cancer and heart attacks, far
earlier than human doctors.

""One thing is very clear, the techniques that we developed can be used for an
enormous amount of good affecting hundreds of millions of people,"" Hinton
said.

* * *

* * *

Î© 2019 The Associated Press. All rights reserved.

**Citation** : Artificial intelligence pioneers win tech's 'Nobel Prize'
(2019, March 27) retrieved 27 March 2019 from
https://techxplore.com/news/2019-03-artificial-intelligence-tech-nobel-
prize.html

This document is subject to copyright. Apart from any fair dealing for the
purpose of private study or research, no part may be reproduced without the
written permission. The content is provided for information purposes only.",Artificial Intelligence,1,Artificial intelligence pioneers win tech's 'Nobel Prize',standard
31,https://news.ycombinator.com/item?id=19500838,conversations_hackernewsnew,16.519272,[],AI,"ItÈs easy to get lost amidst all the uncertainty and speculation, but when we
do, we may fail to see whatÈs happening right in front of us right now. AI is
already creating new forms of employment. In fact, researchers at Accenture
have identified several new categories of jobs spurred by AI. This research is
featured in the _MIT Sloan Management Review_ article The Jobs That
Artificial Intelligence Will Create. IÈm joined by authors H. James Wilson
and Paul Daugherty for a look at the findings from their first round of
research and what they have learned since about the new roles that AI is
creating in the organization. Jim and Paul, welcome, and thanks for taking the
time to talk about the work you and your colleagues are doing to help us
understand AIÈs impact on employment.

**Paul Daugherty:** Yeah, we started this about two-and-a-half years ago when
Jim and I were looking at the advance of AI and the current state of a lot of
the discussions around AI. And we became concerned about the type of dialogue
that was happening. As you say, there certainly is a massive impact on the way
work is done, brought on by AI. But in our early experience, we saw a lot of
promise for AI to change jobs and create jobs and make more human jobs  or
make jobs more human  in many steps. So Jim and I launched this research
project to look at 1,500 organizations and how they were using AI and how it
was impacting their business, their workforce, and the things that they did in
the company. And the finding was that contrary to what a lot of people think,
we believe AI will create a lot of novel new jobs. It will certainly eliminate
some jobs, but we believe that the net effect will be creating a lot of jobs 
and jobs that are good jobs that leverage our human capability in different
ways. Broadly speaking, we came up with three categories of jobs that we call
_trainer_ , _explainer_ , and _sustainer_  three categories of new jobs where
weÈre using our human capability in different ways to allow AI to have the
positive impact on the way we work, the way we live, and overall a positive
impact on outcomes.

**Paul Michelman:** Thanks, Paul. LetÈs walk through each of these categories,
beginning with trainer.

**James Wilson:** So we initially did that research of about 1,500 companies,
and we didnÈt initially see these three job categories, but when we started to
dig down into the research, when we started to do follow-up case studies,
thatÈs where we really started to see these jobs surface  managers that we
were interviewing talking about writing fundamentally new job descriptions.
And we actually saw recurring job titles [and] job categories that they were
writing for. One of those job categories is the trainer role. And these are
the people that are quite often doing the data science. TheyÈre doing the
machine learning engineering. TheyÈre the ones that are actively building the
AI systems. One of the things that we see is that even within the same
company, there can be a lot of variety within a particular job category, like
a trainer job. So, for instance, Tesla: You can see that the carmaker is
recruiting line managers with experience in robotics, and robot engineers and
computer vision researchers, and deep learning scientists and machine learning
systems experts. So really rich variety  even within that one trainer
category within a single company.

**Paul Michelman:** And Jim, trainers are exclusively technology experts?

**James Wilson:** No, not necessarily. And we can talk some more about that.
You know, itÈs important to have functional experts on your team, as well. It
might be that you have a person with a marketing background or an operations
background on your team helping identify and solve problems that the technical
experts  for instance, the data scientists  will then go in and solve for.

**Paul Daugherty:** And just to add on, one specific type of job we see here
in the trainer category are the AI personality trainers  somebody who can
behaviorally train the chatbots and intelligent virtual agents that so many
companies are deploying right now. Companies deploy those solutions to
interact (voice-driven interaction) with their consumers and such. What
theyÈre realizing is that AI becomes the brand. And so you need to train it to
behave in the right way, to operate the right way, to have the right answers,
the right tone, etc. And thatÈs a nontechnical type of job thatÈs needed to
shape that type of behavior and [to] work with the engineers to get that
behavior implemented in the right way in the solutions.

**Paul Michelman:** Great. LetÈs move on to the second category, which you
label explainers.

**Paul Daugherty:** Explainers is one that I think is getting to the fact that
AI is embedded in very complex systems and business processes. And so thereÈs
an issue both of explaining AI itself and how itÈs working, but more broadly
explaining the kinds of outcomes that are being generated by the systems that
are being developed. For example, if you think about a self-driving car, it
has a lot of AI embedded in it, but thereÈs lots of other driving systems and
things included. So when you think about autonomous vehicles and whatÈs
happening, what weÈre seeing is companies creating roles [for] people to
understand the overall context of the system  the environmental conditions,
the road conditions, lots of things in addition to the AI itself and how it
was behaving, so that they can understand and tune the systems to operate more
effectively.... Understanding that impact is the [type of job] weÈre seeing in
the explainer category.

**James Wilson:** In some cases, these explainer roles are actually being
encouraged through regulation. So this year by some estimates there were about
75,000 new explainer roles being created related to the GDPRÈs right to
[explanation]. And these are analysts in banks, for instance, and in customer
service centers and that sort of thing, [who] answer customersÈ questions
about an algorithmic decision.

**Paul Michelman:** So are explainers always an interface between the
organization and the public? Or are they also interfacing within parts of the
organization?

**James Wilson:** They quite often are interfacing with parts of the
organization as well. So, for instance, in health care weÈre seeing a lot of
early evidence that explainers are working with physicians in explaining why
an AI system is making a particular recommendation and whether then the doctor
can go on and make a medical recommendation to a patient as a result. They
often are working in health care settings, making interpretations and sharing
insights with medical professionals, not necessarily patients or customers.

**Paul Michelman:** So letÈs move to the third category: sustainers.

**Paul Daugherty:** This is really speaking to the roles that are needed to
manage AI (the use of AI) and to make sure that it not only behaves right at
the outset, but it continues to behave properly to produce the desired
outcomes over time, because the technology changes, the data changes, the
situation changes, the business changes. And sustainer roles are people who
really understand the outcomes that need to be driven to make sure that that
outcome and that impact is sustained.

**James Wilson:** They also spend a good deal of their day thinking about
unintended consequences from AI systems and how those end up being received by
the public. So, for instance, surge pricing. Is a surge pricing model going to
be something that is sustainable for a company? That was an issue, obviously,
that some of the firms like Uber and Lyft had to deal with initially. How do
you come up with a surge-pricing model thatÈs algorithm-driven but also is
sustainable? Things like biased algorithms, discriminatory facial recognition
systems  these are things that [the] first wave of trainers didnÈt
necessarily think about, but now sustainers think about whether these
unanticipated, unintended consequences are something that can be managed. Or
maybe they might even recommend that an AI system has to be taken out of
operation until the company figures out how to get it right.

**Paul Michelman:** WhatÈs an example of a title that a sustainer might have
in the organization?

**Paul Daugherty:** I think sustainers can manifest themselves in a number of
ways. WeÈre seeing this often as augmenting the team or the work thatÈs being
done in different situations. For example, in manufacturing or factory types
of situations where theyÈre using collaborative robots and different types of
technology that need to be continually configured and rearranged to meet the
dynamic needs of the supply chain and what theyÈre producing  sustainer roles
in that sense would be the technician whoÈs reorganizing and managing the
interface between the robots and the production process thatÈs being
performed. So those are the types of roles that we see there.

**James Wilson:** You know, just driving up and down the streets of San
Francisco, youÈre going to pass a number of autonomous vehicles. But of
course, sitting behind that robo-car is an AI safety trainer. And so you see a
lot of those roles in autonomous vehicle situations. In general, any company
thatÈs building robotic systems is going to be hiring these AI safety or AI
compliance officers that really make sure at a basic level that the systems
that theyÈre deploying are safe in the public.

**Paul Michelman:** You did this research, originally, two years ago. And I
guess in terms of the longevity of management ideas, two years is really not
that long a period of time. But in the world of AI, we almost should be
talking about dog years, I think  two years seems like a long time. So IÈm
wondering: When youÈre looking at the market today, when youÈre looking at
employment trends today, would you stick to these three categories? Have they
evolved? How has your thinking shifted, if at all?

**Paul Daugherty:** Yeah, I think thereÈs a little bit of both. IÈll talk
first about what we see with the categories we identified. If you look at
trainers, explainers, and sustainers, I think we see more evidence every day
of how these roles are growing and increasing. For example, if you look at job
postings, which we were researching a little while ago, you can find
_explainer_ in job titles now  Algorithm Explainability Engineer and
Financial Services Explainability Specialist and things like that  the need
to explain the algorithms and the AI. WeÈre seeing this accelerate, I think,
as you said, in this dog-year type of fashion. WeÈve also seen some compelling
examples from some of the early entrants of why you need these roles. I think
Facebook is an instructive story. What theyÈve done, following all the focus
on them around Cambridge Analytica, is theyÈve created tens of thousands of
new jobs to add humans in to manage the algorithms and produce the results
that people really want, in a more responsible fashion. And those are
sustainer jobs  itÈs people added in. I think FacebookÈs comment was along
the lines of: WeÈve concluded algorithms canÈt manage the algorithms, we need
people to manage the algorithms. And those arenÈt isolated incidents. I think
those are examples of the roles that all companies are going to need as they
deploy the technology.

**James Wilson:** Yeah, our article focused on unprecedented new job
categories where people are out there developing and responsibly managing AI
systems. But while AI is certainly creating new jobs, itÈs also changing old
jobs by augmenting them. And we didnÈt get into that much in that initial
article. For example, at one bioscience company that weÈve been looking at 
itÈs based out here in the Bay Area  scientists use robotic lab equipment to
help on certain experimental tasks. The robotic helpers precisely squirt
liquids and they plate cells and they count microbe colonies in a way that
augments and accelerates scientific work. And as a result of this robot
augmentation, scientists are now able to complete about 400 times more
experiments each week. So if you think about that, a scientist now has the
potential to make a hundred yearsÈ worth of scientific discovery in a single
year through AI augmentation. But you know the lab scientistÈs job content has
really changed quite a bit. She now does things that are quite a bit different
than she was doing before and has different ways of doing them. And we didnÈt
get into that topic as much. We were much more focused on the job creation,
not the job content change.

**Paul Michelman:** When weÈre looking at the three fully new categories of
jobs, how equally and evenly distributed are these roles going to be? Are
there particular industries or types of organizations for which these roles
are going to emerge earlier? Are there other organizations that should take
kind of a sit-back-and-wait approach?

**James Wilson:** I would make two points here. The first is that companies
really need all three roles. For instance, a few years ago many of the most
advanced AI firms  the major technology companies, for instance  focused
exclusively on staffing AI trainers. But now theyÈre playing catch up. So you
really do need to have all three. But I think one insight here is that the AI
talent war is quite a bit different and broader than a lot of people initially
thought. My second point is that the distribution of the roles is going to
vary quite a bit by industry and customer and regulatory context.

**Paul Michelman:** When weÈre looking at these new categories, it would seem
that one of the fundamental challenges organizations face is that these are
jobs that no one has done before. No one has ever trained to be an AI trainer.
How do we solve for that?

**Paul Daugherty:** ThatÈs one of the biggest challenges that I think we have
to face as we look at how do we prepare people for these new roles and how do
businesses and organizations prepare for these new roles. WeÈve done some
follow-on research on this, and we think thereÈs three things that we really
need to focus on to get this right. One is focusing more on experiential
learning. If you look at traditional training, it would show that people
forget 80% of what they learn within about a day of learning it from
traditional training methods. So how do you get people engaged in the learning
process in the experiential way? We think apprenticeships are very important 
hands-on learning, learning injected at different points in the process. For
example, weÈve done an interesting training and learning approach with a large
aircraft manufacturer, where we used AI and mixed-reality technology to equip
workers with a mixed-reality headset that helps them understand the job they
were doing and do higher-skilled jobs faster by providing them guidance along
the way. And thatÈs an example of using technology plus experiential learning
to advance people skills into these new categories.

A second thing we found is important is shifting the burden from just the
person needing to learn to looking [at] the responsibility [that] different
institutions  businesses, etc.  have for the training. One thing we firmly
believe is that every organization needs to look at learning as a core
competency in a really new and fresh way. And you need to think about learning
platforms from lifelong learning as a core part of what you do. Because to
your point, you canÈt go hire people for some of these roles, you may need to
build people to do them. For example, we worked with an oil company on a new
drilling technology that uses visualization and AI and gaming engines to
create a whole different way for a technician to operate a drill (oil
drilling, operating miles underground). So where are you going to hire the
gaming engine, visualization-inspired driller? YouÈre not going to find people
on the market with those skills. YouÈre going to have to take your current
technicians and develop these new digital skills in them, which is why we
believe that these learning platforms are going to be a critical component for
companies. ItÈs going to be differentiating for those who can get it right.

And then finally, from an overall societal and multi-stakeholder perspective,
we need to look at how we enable vulnerable people in the population [who] are
already maybe separated by a digital divide  who donÈt have the right
baseline skills to operate in this environment  and do more to make sure that
everybodyÈs got the base of skills that [they] need to participate in these
jobs.

**Paul Michelman:** So this is really interesting. On the one hand, a focus on
on-the-job learning, experiential learning, certainly promises or would seem
to promise a shorter time frame and maybe more stickiness to get people
trained up for these new roles. And yet, thatÈs still a major organizational
undertaking  maybe not as great as relying on academia to fill the void,
which will take decades  but still these jobs need to be done. They may not
be fully at scale, but as you guys have noted, theyÈre very much real and
happening right now. So as we look at these three categories, where should
that first crop of people come from?

**James Wilson:** Well, I think one thing that we can do today is to make it
easier for people to become trainers, explainers, and sustainers by basically
lowering the barrier to building or improving an AI system  what Paul and I
call _AI democratization_. WeÈre already beginning to see point-and-click AI
training tools out there. And many of the cloud AI services providers, for
instance, are quite easy to use. If you have a data set, you can just upload
the data set to one of these services and then start playing around with the
data. So I think the complement to what Paul was just talking about, which was
raising the skill level, is also at the same time to lower the barrier to
using these systems. I think thatÈs a really important thing. And itÈs often
an untapped opportunity, but weÈre beginning to see more and more companies
migrating toward that model as well.

**Paul Michelman:** In terms of global impact for these new categories of jobs
in particular  and I realize this is going to be a difficult question to
answer in particulars  so general trends would be fine, but I think a lot of
people would like some help in sizing the opportunity that your research
suggests, especially as we think about potential job loss at the hands of AI,
machine learning, and automation. Are the new jobs weÈre discussing here a
relative drop in the bucket for the highly specialized few or well-trained
few? What is this going to look like at scale?

**Paul Daugherty:** These jobs certainly are a drop in the bucket, but you
have to put it in context. We think this is a major impact  these jobs are a
major impact going forward on employment and opportunity for people. However,
just to start, there will be a lot of disruption in the labor force, and there
will be categories of jobs that are at risk for automation. But you have to
look at the broad spectrum of how thatÈll happen. And from the research weÈve
done, if you look across categories of jobs, if you look at the content of
work, thereÈs about 10% of work generally that we found through our research
is human-only (only humans can do). ThereÈs about 35% of work that is
automatable  that part of the work is automatable by machines, algorithms,
etc. And the rest of the work  which is the majority of it  is really
augmentable, which means you can improve the way humans do it, but itÈs
largely going to need to be done by humans. And I think that the context
around these new jobs is [that] most of the jobs become transformed in
different ways. And how do we use AI and other technology to transform the
jobs to prepare people for those changed jobs? So thatÈs a big impact, and I
would say almost every job will change as a result of the technology. Many new
jobs will be created and some will be eliminated.

One good data point, having just come from a G7 meeting recently: Canada
announced that through their investment theyÈre making, they expect a $16
billion economic increase in output as a result of the investments theyÈre
making in AI. ThatÈs significant output. They talk about 16,000 jobs theyÈre
creating through the focus on AI. And we see similar types of impacts and
results around the world and larger impacts in terms of GDP increase (economic
output increase) by countries. And thatÈs where the opportunity is  in kind
of envisioning how do we prepare people for these new types of jobs that will
be created?

**James Wilson:** Yeah, just building on PaulÈs point, I think you can get a
good quantitative sense of the size of opportunity by looking at business
leadersÈ investment expectations, especially around growth. In our research,
for instance, we found that firms that invest in their AI workforce at the
same rate as top-performing businesses in their sector are going to grow both
revenues but also their workforce.

**Paul Daugherty:** ThereÈs another impact on jobs that I think we need to
think about, which is the fact that itÈs hard to anticipate where the new jobs
are coming from and what the new jobs will look like. ThatÈs why we try to be
prescriptive and talk about trainers and explainers and sustainers. One
historical observation IÈd offer is that if you look back at prior technology
waves weÈve had  20 years ago, people wouldnÈt have anticipated that weÈd
have large categories of people employed in things like search engine
optimizers, web designers, eBay retail merchants, etc. In a similar fashion,
weÈre already seeing this creation of the new jobs going forward, and theyÈre
the unanticipated, new things that we need to continue to be creative about
and look for as time goes on.

**Paul Michelman:** So whatÈs next in your research?

**James Wilson:** In our research, we see that about 69% of executives believe
that their industry is going to be completely transformed between now and 2022
as a result of AI. But we continue to try to understand not only the jobs that
are going to be created, but also the skills that are going to help this
transformation  that are going to enable this transformation. And I think
this is an important area for our research. PaulÈs already set it up very
nicely. A lot of our findings thus far have been surprising to us. For
instance, you might think that STEM skills are the be-all and end-all for the
age of AI. But our research is showing that four distinctively soft skills are
becoming much more valuable as we begin collaborating with smart machines and
using smart machines: These are complex reasoning, creativity,
social/emotional intelligence, and certain forms of sensory perception_. So
interestingly, one thing that weÈre tracking now is how skills are becoming
softer. And what does that look like on an AI team?

**Paul Daugherty:** Yeah, I think going further on those human skills. Because
one question we get a lot is exactly that, which is: OK, Paul and Jim, we get
you, we believe what youÈre laying out here. What do I do tomorrow? What do I
do next month to start preparing my people and my workforce? Getting to that
next level of specificity  the human skills and how we get people ready  I
think is really important. ThereÈs a couple other fronts weÈve launched. One
is on responsible AI, which we hinted at in the original article, but itÈs
really become more important, which is: How do we make sure we get the right
outcomes from AI? Speaking of things like transparency and explainability,
which one of our job categories addresses; thinking about bias, which is an
issue that many have run into when they apply AI  creating biased outcomes
rather than inclusive outcomes; thinking about accountability; thinking about
trustworthiness and issues like that. So weÈre doing a lot of further work on
that. In fact, we have a new article in _MIT SMR_ on fairness and approaches
to fairness with AI and some work weÈve done in that area. These are going to
be really important issues for businesses and organizations to grasp and to
make sure that as we have increasing numbers of people working in AI and more
powerful solutions delivered with the AI, how do we make sure we deliver the
right outcomes in all cases?

**Paul Michelman:** Terrific. Paul Daugherty, Jim Wilson, thank you both very
much.

**Paul Daugherty:** Thank you, Paul.

**James Wilson:** Thank you, Paul.",Artificial Intelligence,0.985,Revisiting the Jobs Artificial Intelligence Will Create,standard
32,https://news.ycombinator.com/item?id=19783574,conversations_hackernewsnew,16.519272,[],AI,"U.S. technology giant [Microsoft has teamed up with a Chinese military
university](https://www.ft.com/content/9378e7ee-5ae6-11e9-9dde-7aedca0a081a)
to develop [artificial intelligence
systems](https://www.irishtimes.com/business/technology/microsoft-worked-with-
chinese-military-university-on-ai-1.3855553) that could potentially enhance
government surveillance and censorship capabilities. Two [U.S. senators
publicly
condemned](https://www.ft.com/content/5f5916fc-5be3-11e9-939a-341f5ada9d40)
the partnership, but what the [National Defense Technology University of
China](http://www.nudt.edu.cn/index_eng.htm) wants from Microsoft isnÈt the
only concern.

As [my research
shows](https://scholar.google.com/citations?user=OgVZmm4AAAAJ&hl=en), the
advent of digital repression is profoundly affecting [the relationship between
citizen and state](https://doi.org/10.1353/jod.2019.0003). New technologies
are arming governments with unprecedented capabilities to monitor, track and
surveil individual people. Even governments in democracies with strong
traditions of [rule of law](https://theconversation.com/is-trumps-definition-
of-the-rule-of-law-the-same-as-the-us-constitutions-77598) find themselves
tempted to abuse [these new abilities](https://qz.com/813672/half-of-the-
united-states-is-registered-in-police-facial-recognition-databases-and-its-
completely-unregulated/).

In states with [unaccountable institutions and frequent human rights
abuses](https://www.foreignaffairs.com/articles/world/2018-07-10/how-
artificial-intelligence-will-reshape-global-order), AI systems will most
likely cause greater damage. China is a prominent example. Its leadership has
enthusiastically embraced AI technologies, and has set up the worldÈs [most
sophisticated](https://www.nytimes.com/interactive/2019/04/04/world/asia/xinjiang-
china-surveillance-prison.html) [surveillance
state](https://www.engadget.com/2018/02/22/china-xinjiang-surveillance-tech-
spread/) in [Xinjiang
province](https://www.theguardian.com/world/2019/feb/18/chinese-surveillance-
company-tracking-25m-xinjiang-residents), tracking citizensÈ daily movements
and smartphone use.

Its exploitation of these technologies [presents a chilling
model](https://www.georgesoros.com/2019/01/24/remarks-delivered-at-the-world-
economic-forum-2/) for fellow autocrats and poses a direct threat to open
democratic societies. Although thereÈs no evidence that other governments have
replicated this level of AI surveillance, Chinese companies are actively
exporting the same underlying technologies across the world.

[![](https://images.theconversation.com/files/270016/original/file-20190418-28097-1i209s9.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=754&fit=clip)](https://images.theconversation.com/files/270016/original/file-20190418-28097-1i209s9.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=1000&fit=clip)
Surveillance in ChinaÈs Xinjiang province includes both extensive police
patrols and surveillance cameras, like those on the building in the
background. [AP Photo/Ng Han
Guan](http://www.apimages.com/metadata/Index/China-Tracking-
Face/cbbeb8deda184d58a0a1f17fab7e2564/9/0)

## Increasing reliance on AI tools in the US

[Artificial intelligence
systems](https://ai.stanford.edu/%7Enilsson/QAI/qai.pdf) are everywhere in the
modern world, helping run smartphones, internet search engines, digital voice
assistants and Netflix movie queues. [Many people fail to
realize](https://governanceai.github.io/US-Public-Opinion-Report-Jan-2019/)
how quickly AI is expanding, thanks to ever-increasing amounts of data to be
analyzed, improving algorithms and advanced computer chips.

Any time more information becomes available and analysis gets easier,
governments are interested  and not just authoritarian ones. In the U.S., for
instance, the 1970s saw revelations that government agencies  such as the
FBI, CIA and NSA  had set up [expansive domestic surveillance
networks](https://www.intelligence.senate.gov/sites/default/files/94755_II.pdf)
to monitor and harass civil rights protesters, political activists and Native
American groups. These issues havenÈt gone away: Digital technology today has
deepened the ability of even more agencies to conduct even more intrusive
surveillance.

[![](https://images.theconversation.com/files/270024/original/file-20190418-28090-1lpg1vm.png?ixlib=rb-1.1.0&q=45&auto=format&w=237&fit=clip)](https://images.theconversation.com/files/270024/original/file-20190418-28090-1lpg1vm.png?ixlib=rb-1.1.0&q=45&auto=format&w=1000&fit=clip)
How fairly do algorithms predict where police should be most focused? [Arnout
de
Vries](https://commons.wikimedia.org/wiki/File:Criminaliteits_Anticipatie_Systeem.png)

For example, U.S. police have eagerly embraced AI technologies. They have
begun using software that is [meant to predict where crimes will
happen](https://theconversation.com/why-big-data-analysis-of-police-activity-
is-inherently-biased-72640) to decide where to send officers on patrol.
TheyÈre also using [facial recognition](https://www.nbcnews.com/news/us-
news/facial-recognition-gives-police-powerful-new-tracking-tool-it-s-n894936)
and [DNA analysis](https://www.washingtonpost.com/crime-law/2018/12/13/fbi-
plans-rapid-dna-network-quick-database-checks-arrestees/) in criminal
investigations. But analyses of these systems show the [data on which those
systems are trained](https://theconversation.com/congress-takes-first-steps-
toward-regulating-artificial-intelligence-104373) are often biased, leading to
[unfair outcomes](https://theconversation.com/did-artificial-intelligence-
deny-you-credit-73259), such as [falsely determining that African Americans
are more likely to commit crimes](https://www.propublica.org/article/machine-
bias-risk-assessments-in-criminal-sentencing) than other groups.

## AI surveillance around the world

In authoritarian countries, AI systems can directly abet domestic control and
surveillance, helping [internal security forces process massive amounts of
information](https://www.power3point0.org/2018/01/25/hybrid-repression-online-
and-offline-in-china-foretelling-the-human-rights-struggle-to-come/) 
including social media posts, text messages, emails and phone calls  more
quickly and efficiently. The police can identify social trends and [specific
people](https://www.apnews.com/bf75dd1c26c947b7826d270a16e2658a) who might
threaten the regime based on the information uncovered by these systems.

For instance, the Chinese government has used AI in wide-scale crackdowns in
regions that are home to ethnic minorities within China. Surveillance systems
in Xinjiang and Tibet have been described as
[Orwellian](https://foreignpolicy.com/2019/03/19/962492-orwell-china-
socialcredit-surveillance/). These efforts have included [mandatory DNA
samples](https://www.nytimes.com/2019/02/21/business/china-xinjiang-uighur-
dna-thermo-fisher.html), Wi-Fi network monitoring and widespread facial
recognition cameras, all connected to integrated data analysis platforms. With
the aid of these systems, Chinese authorities have, according to the U.S.
State Department, arbitrarily detained between [1 and 2 million
people](https://www.state.gov/j/drl/rls/hrrpt/humanrightsreport/index.htm?year=2018&dlid=289037#wrapper).

My [research looks at 90 countries around the
world](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3374575) with
government types ranging from closed authoritarian to flawed democracies,
including Thailand, Turkey, Bangladesh and Kenya. I have found that Chinese
companies are [exporting AI surveillance
technology](https://carnegieendowment.org/2019/01/22/we-need-to-get-smart-
about-how-governments-use-ai-pub-78179) to at least 54 of these countries.
Frequently, this technology is packaged as part of ChinaÈs flagship [Belt and
Road Initiative](https://eng.yidaiyilu.gov.cn/), which is funding an extensive
network of roads, railways, energy pipelines and telecommunications networks
[serving 60% of the worldÈs
population](https://www.knightfrank.com/blog/2018/01/30/an-insight-into-the-
belt-and-road-initiative) and economies that generate 40% of global GDP.

For instance, Chinese companies like
[Huawei](https://e.huawei.com/us/solutions/industries/smart-city) and ZTE are
constructing smart cities in [Pakistan](https://www.dawn.com/news/1333101),
[the Philippines](https://e.huawei.com/en/case-
studies/global/2017/201704261658) and
[Kenya](http://www.chinadaily.com.cn/world/2017-05/16/content_29372143.htm),
featuring extensive built-in surveillance technology. For example, Huawei has
outfitted [Bonifacio Global City](https://bgc.com.ph/) in the Philippines with
high-definition internet-connected cameras that provide [24/7 intelligent
security surveillance](https://e.huawei.com/en/case-
studies/global/2017/201704261658) with data analytics to detect crime and help
manage traffic.

[![](https://images.theconversation.com/files/270029/original/file-20190418-28094-xukhtb.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=754&fit=clip)](https://images.theconversation.com/files/270029/original/file-20190418-28094-xukhtb.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=1000&fit=clip)
Bonifacio Global City in the Philippines has a lot of embedded surveillance
equipment. [alveo land/Wikimedia
Commons](https://en.wikipedia.org/wiki/File:Bonifacio_Global_City_2.jpg)

[Hikvision](https://foreignpolicy.com/2018/06/13/in-chinas-far-west-companies-
cash-in-on-surveillance-program-that-targets-muslims/),
[Yitu](https://www.scmp.com/tech/social-gadgets/article/2142497/malaysian-
police-wear-chinese-start-ups-ai-camera-identify) and
[SenseTime](https://qz.com/1248493/sensetime-the-billion-dollar-alibaba-
backed-ai-company-thats-quietly-watching-everyone-in-china/) are supplying
state-of-the-art facial recognition cameras for use in places like
[Singapore](https://www.albawaba.com/news/china%E2%80%99s-newest-global-
export-policing-dissidents-1139230)  which announced the establishment of a
surveillance program with [110,000 cameras mounted on lamp
posts](https://www.reuters.com/article/us-singapore-surveillance/singapore-to-
test-facial-recognition-on-lampposts-stoking-privacy-fears-idUSKBN1HK0RV)
around the city-state. Zimbabwe is creating a [national image
database](https://foreignpolicy.com/2018/07/24/beijings-big-brother-tech-
needs-african-faces/) that can be used for facial recognition.

However, selling advanced equipment for profit is different than sharing
technology with an express geopolitical purpose. These new capabilities may
plant the seeds for global surveillance: As governments become increasingly
dependent upon Chinese technology to manage their populations and maintain
power, they will face greater pressure to align with ChinaÈs agenda. But for
now it appears that ChinaÈs primary motive is to dominate the market for new
technologies and make lots of money in the process.

## AI and disinformation

In addition to providing surveillance capabilities that are both sweeping and
fine-grained, AI can help repressive governments manipulate available
information and spread disinformation. These campaigns can be automated or
automation-assisted, and deploy [hyper-personalized
messages](https://theconversation.com/solving-the-political-ad-problem-with-
transparency-85366) directed at  or against  [specific
people](https://www.nytimes.com/2018/10/20/us/politics/saudi-image-campaign-
twitter.html) or groups.

AI also underpins the technology commonly called
[deepfake](https://www.technologyreview.com/s/612501/inside-the-world-of-ai-
that-forges-beautiful-art-and-terrifying-deepfakes/), in which algorithms
create [realistic video and audio
forgeries](https://theconversation.com/detecting-deepfake-videos-in-the-blink-
of-an-eye-101072). Muddying the waters between truth and fiction may become
useful in a tight election, when one candidate could create fake videos
showing an opponent doing and saying things that never actually happened.

VIDEO An early deepfake video shows some of the dangers of advanced
technology.

In my view, policymakers in democracies should think carefully about the risks
of AI systems to their own societies and to people living under authoritarian
regimes around the world. A critical question is how many countries will adopt
ChinaÈs model of digital surveillance. But itÈs not just authoritarian
countries feeling the pull. And itÈs also not just Chinese companies spreading
the technology: Many U.S. companies, Microsoft included, but [IBM, Cisco and
Thermo Fisher](https://www.axios.com/china-us-technology-surveillance-
state-5672b822-fdde-45f9-ac77-e7b5574e9351.html) too, have provided
sophisticated capabilities to nasty governments. The misuse of AI is not
limited to autocratic states.",Artificial Intelligence,1,How Artificial intelligence systems could threaten democracy,standard
33,https://news.ycombinator.com/item?id=19850611,conversations_hackernewsnew,16.519272,[],AI,"# Artificial Intelligence Can Now Copy Your Voice

## Voice spying, cloning and voice reading on our mental health is just the
beginning

Voice technologies arenÈt just becoming the new customer touch point, itÈs
becoming a new way to gather data from global citizens. BaiduÈs AI can [clone
your voice in seconds](https://medium.com/syncedreview/baidu-ai-can-clone-
your-voice-in-seconds-93558a7b984f).

Microsoft has a vision for[ conversational
AI](https://blogs.microsoft.com/ai/microsoft-build-future-of-natural-
language/) in the future of the operating system. So does Huawei and many
others. Smart speakers are probably spying on us gathering insights not just
to improve their product.

Honestly, they can even [tell if your have
PTSD](https://futurism.com/artificial-intelligence-detect-ptsd-voice) just by
your voice. Just as AI with facial recognition can read your emotions on your
face. Meanwhile AI is giving us the ability o create fake humans, personas
with apparently human features that donÈt really exist. Getting catfishes on
the internet by a fake human is now a real possibility in the not too distant
future.

* It takes just[ 3.7 seconds of audio to clone a voice](https://motherboard.vice.com/en_us/article/3k7mgn/baidu-deep-voice-software-can-clone-anyones-voice-with-just-37-seconds-of-audio).
* TodayÈs intelligent assistants are full of skills and they will get much smarter in the 2020s.

AI isnÈt just monetizing the internet for Ad-giants like Google, Facebook and
Amazon, Artificial Intelligence is about to create a fake world of even more
complexity.

Smart speakers are going to explode in popularity in China in 2019, with
Alibaba, Baidu and Xiaomi leading the way among others. Alibaba isnÈt just
like Amazon, itÈs bigger. As it matures in the cloud and as HuaweiÈs profits
increase, these two companies will eventually pose a real threat to AI
dominance of Google and Microsoft.

AI is creating a new world and we donÈt really know the dangers of it, weÈre
just going ahead like children into a world where AI regulation will become
nearly impossible.

Now, with advances in artificial intelligence, the world is becoming more
artificial, and you canÈt be sure what you see or hear is real or a
fabrication of artificial intelligence and machine learning. From incredible
Ads of the future to entities we meet online, AI will transform our world to
not just being more immersive, but more confusing, complex and manipulative.

The line between convenience and hacking humans (the opposite of enhancing us)
is very real. ItÈs so profitable to use AI to gain an edge over other firms
and reach people, the commercial weaponization of AI and our most intimate
data is really inevitable.

BaiduÈs research team used voice cloning techniques to develop the AI system
which they expect will have noteworthy applications in personalizing human-
machine interface.

BaiduÈs research arm announced yesterday that its 2017 text-to-speech (TTS)
system _Deep Voice_ has learned [how to imitate a personÈs
voice](https://arxiv.org/pdf/1802.06006.pdf) using a mere three seconds of
voice sample data. ([Synced](https://medium.com/@Synced) is a great
publication for AI).

Huawei has been working on [emotionally intelligent
AI](https://www.brecorder.com/2018/04/24/413804/huawei-to-introduce-
emotionally-intelligent-artificial-intelligence/) for years. Alexa, Apple and
Samsung are in the race for smarter interacts with their personal assistant AI
via earpods with 2019 being a pivotal year for the product from all three
providers.

Like all artificial intelligence algorithms, the more data voice cloning tools
such as Deep Voice receive to train with the more realistic the results.
Meanwhile companies like Spotify are integrating podcasts into how they
recommend content that will be able to gather data on some of our core
interests.

The smart home invasion of Alexa and Google Home devices is nothing short of a
treasure chest of our most intimate data. Information on demand and insights
on users that were previously impossible. All thanks to the AI-voice interface
which is more immediate and will become ubiquitous in human societies, smart
cities and the IoT in the next twenty years.

The technique known as voice cloning, could be used to personalize virtual
assistants such as AppleÈs Siri, Google Assistant, Amazon Alexa; and BaiduÈs
Mandarin virtual assistant platform DuerOS, which supports more than 50
million devices in China with human-machine conversational interfaces.

The frontiers of human interaction with AIs are broad and deep with incredible
implications for customer relationships. The world we are building of AIs will
be incredible and potentially very transparent with regards to our data.

Google unveiled[ Tacotron
2](https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-
speech.html), a text-to-speech system that leverages the companyÈs deep neural
network and speech generation
method[WaveNet](https://deepmind.com/blog/wavenet-generative-model-raw-
audio/). WaveNet analyzes a visual representation of audio called a
spectrogram to generate audio. It is used to generate the voice for Google
Assistant.

ItÈs becoming impossible to tell the difference between an AI and a human and
thatÈs incredibly problematic in a world where cybersecurity threats are only
increasing. The internet of things aspect of connectivity in the 4th
industrial revolution comes at a cost for privacy, censorship, data
harvesting, fraud, identity theft and consumer manipulation of ever more
personalized digital advertisements.",Artificial Intelligence,0.996,Artificial Intelligence Can Now Copy Your Voice,standard
34,stackoverflow-54994079,conversations_stackoverflow,16.420942,"['machine-learning', 'nlp', 'stanford-nlp', 'corpus']",AI,"<p>I am trying to learn how to create and train a corpus for relation-extraction. I have learned that I require a corpus in the conll format. However, I don't know how I should train the corpus.</p>

<p>Here is some code that I have to print out example text in the conll format. I am unsure how I would then modify this file with the appropriate changes, and then train with it.</p>

<pre><code>Properties props = new Properties();
props.setProperty(""annotators"", ""tokenize,ssplit,pos,lemma,ner,parse,depparse,coref,natlog,sentiment,kbp,quote"");
props.setProperty(""coref.algorithm"", ""neural"");

StanfordCoreNLP pipeline = new StanfordCoreNLP(props);

String text = ""The modern definition of artificial intelligence (or AI) is \""the study and design of intelligent agents\"" where an intelligent agent is a system that perceives its environment and takes actions which maximizes its chances of success. "" + 

""John McCarthy, who coined the term in 1956, defines it as \""the science and engineering of making intelligent machines. "" +

""Other names for the field have been proposed, such as computational intelligence, synthetic intelligence or computational rationality. "" + 

""The term artificial intelligence is also used to describe a property of machines or programs: the intelligence that the system demonstrates. "" + 

""AI research uses tools and insights from many fields, including computer science, psychology, philosophy, neuroscience, cognitive science, linguistics, operations research, economics, control theory, probability, optimization and logic. "" + 

""AI research also overlaps with tasks such as robotics, control systems, scheduling, data mining, logistics, speech recognition, facial recognition and many others. "" + 

""Computational intelligence Computational intelligence involves iterative development or learning (e.g., parameter tuning in connectionist systems). "" + 

""Learning is based on empirical data and is associated with non-symbolic AI, scruffy AI and soft computing. "" + 

""Subjects in computational intelligence as defined by IEEE Computational Intelligence Society mainly include: Neural networks: trainable systems with very strong pattern recognition capabilities. "" + 

""Fuzzy systems: techniques for reasoning under uncertainty, have been widely used in modern industrial and consumer product control systems; capable of working with concepts such as 'hot', 'cold', 'warm' and 'boiling'. "" + 

""Evolutionary computation: applies biologically inspired concepts such as populations, mutation and survival of the fittest to generate increasingly better solutions to the problem. "" + 

""These methods most notably divide into evolutionary algorithms (e.g., genetic algorithms) and swarm intelligence (e.g., ant algorithms). "" + 

""With hybrid intelligent systems, attempts are made to combine these two groups. "" + 

""Expert inference rules can be generated through neural network or production rules from statistical learning such as in ACT-R or CLARION. "" + 

""It is thought that the human brain uses multiple techniques to both formulate and cross-check results. "" + 

""Thus, systems integration is seen as promising and perhaps necessary for true AI, especially the integration of symbolic and connectionist models. "";


// Annotate an example document.
//CoreDocument doc = new CoreDocument(text); 

//pipeline.annotate(doc);

String outputFile = ""ConnllTest1.txt"";
OutputStream stream;
try {
stream = new FileOutputStream(outputFile);
Writer w = new BufferedWriter( new OutputStreamWriter(stream));
pipeline.conllPrint(pipeline.process(text), w);
} catch (IOException e) {
// TODO Auto-generated catch block
e.printStackTrace();
}
</code></pre>",Artificial Intelligence,1,Stanford-NLP kbp corpus training,standard
35,t3_azrhh9,conversations_reddit,16.406103,,AI,"The importance of Artificial Intelligence is often understated and also
overstating the same is quite difficult.. to get in-depth with how AI is
actually bringing changes in MCA, we must get to the basics of what Medical
Billing and Coding really are.

### MEDICAL CODING



Medical coding, if we talk about it at a very basic level -- is something that
a coder takes, a written piece if you may, and translates it as accurately as
possible into a coded format such as numeric or alphanumeric code. The piece
that's taken for translation can be something such as a prescription for
medication or a doctor's diagnosis or something else medical related. A code
for each and every event is created, these events can be of injuries,
diagnosis or medical procedures.

Presently, there are about a hundred thousand codes existing that are used for
medical procedures, outpatient procedures, and diagnoses. Let us have a look
at a simple example of Medical Coding:

Let's say that a patient has walked into a doctorÈs office and he/she is
coughing tirelessly, they have a high production of mucus, and have a dreaded
fever. Then a nurse walks up to the patient and asks them their symptoms, once
the symptoms are noted, she performs some initial tests to get an idea of what
is actually going on, and then comes the doctor who analyzes and concludes the
diagnoses saying that the patient is suffering from bronchitis. A medication
is then prescribed to the patient by the doctor.

Now comes the interesting part of Modern Healthcare, each and every part of
the visit is recorded by the clinic be it the doctor or someone in the office
who is authorized to carry out such operations. Then begins the coders job
that is to translate all of relevant information of the visit into numeric and
alphanumeric codes, which are ultimately used in the billing process.

The medical coder should be equipped with the knowledge of a few sets and
subsets of code, let's take two of the subsets: International Classification
of Diseases (ICD) these codes correspond to a patientÈs injury or sickness,
and Current Procedure Terminology (CPT) that are related to the functions and
services Healthcare providers perform to the patient this can be as performing
on them and performing for them.

A task included for the Medical Coders is to translate every bit of data or
information of the patient's visit to the clinic and shape it in the form of a
code. There are different codes for different kinds of visits, some codes are
more specific these specific codes can be such as the patients symptoms, the
tests performed by the doctor and the diagnosis procedure used by the doctor.

The Medical Coders have to keep these guidelines in mind, they are very
important and can affect the status of a claim. The coding process concludes
when the Medical Coder has entered the proper codes into the for or software
program. This is where the job of the Medical Coder ends, now, all of this is
passed on to the Medical Biller.

### MEDICAL BILLING



The Medical Biller more so acts as a middleman between patients, healthcare
providers and the insurance companies. Their job, is on similar lines in
context to the Medical Coder. The Medical Biller translates the codes given by
the Medical Coder into a financial report, they make sure that the Healthcare
Provider has been reimbursed appropriately for the services they've provided.

Do not be fooled by the simplicity of the term ""Medical Billing"", it may seem
that all the Medical Billers task is to make a bill (Commonly known as a
'Claim') for the insurance company by the help of the information provided by
the Medical Coder, the reality of the process is not as simple.

Continuing with the previous example, the Medical Biller now looks at the
codes, that consist of information of things such as the kind of visit, the
symptoms, the diagnosis of the doctor, the medication prescribed by the doctor
and then creates a Claim. The Claim is then sent and evaluated by the
insurance company, and then returned back. The bill of the patient is then
made by biller who carefully re-evaluates the returned claim after the
insurance is removed, all of these tasks are performed through a form or
software, they're called as [Medical Billing Software
Solutions](https://www.osplabs.com/medical-billing-solutions/) and there's a
large number of companies out there creating such solutions.

The biller takes a few factors into account such as the insurance plans of the
patient into account while creating the bill, this ensures that an accurate
bill is produced. In cases where the patient shows signs refraining the bill
payment, the Medical Biller has to take appropriate steps to ensure healthcare
provider is properly compensated.

# Let's take a look at how a Traditional Medical Billing & Coding Process
Flows:



Talking about the word 'Traditional' you must have got an idea that it
requires **ALOT** of manual documentation and paper work, the average time for
a traditional coding and billing process stretched on to about 5-7 weeks
whereas in the modern automated system the process is reduced to as low as 2
weeks.

Following is a Claim-to-Payment Chase while using a traditional Paper-Based
System.

1. Patient visits the doctorÈs office.

2. Patient check-in, gets treated.

3. Doctor or their assistant writes a superbill for the treatment.

4. The Medical Coder writes codes for the treatment.

5. Medical Billers receive Paper forms who then format the data and forward it to insurance payers.

6. Payer generates check and send payment to the provider.

Now the point where AI fits into the story is to enhance the efficiency and
efficacy of the billing and coding process. _Computer Assisted Coding (CAC) is
a technology that works on the concept of Machine Learning (ML) which is a
branch of Artificial Intelligence (AI) and Natural Language Processing (NLP),_
they provide automated assistance to the rigorous task of identifying and
extracting data from the given documents and inserting it into the system.",Artificial Intelligence,0.78,Rewriting of Medical Coding Automation using Artificial Intelligence,standard
36,reddit_https://www.reddit.com/r/eos/comments/atcimm/effectai_is_migrating_to_eos/,conversations_reddit,16.386196,,AI,"<!-- SC_OFF --><div class=""md""><p>&#x200B;</p> <p>In April of 2019, <a href=""https://Effect.AI"">Effect.AI</a> will move to the EOS Blockchain.</p> <p>&#x200B;</p> <p><a href=""https://Effect.AI"">Effect.AI</a> is currently NEOÈs most used dApp, and they are determined to be the leader of Decentralized Artificial Intelligence development.</p> <p>&#x200B;</p> <p>&#x200B;</p> <p><strong>More Info</strong>: <a href=""https://medium.com/effect-ai/effect-ai-brings-artificial-intelligence-to-eos-main-net-ead7e68e09fa"">https://medium.com/effect-ai/effect-ai-brings-artificial-intelligence-to-eos-main-net-ead7e68e09fa</a></p> <p>&#x200B;</p> <p> </p> <p><strong>EOS News</strong></p> <p>&#x200B;</p> <p>Telegram: <a href=""https://t.me/EOSNEWS_English"">https://t.me/EOSNEWS_English</a></p> <p>Twitter: <a href=""https://twitter.com/EOSNews_Eng"">https://twitter.com/EOSNews_Eng</a></p> <p>Medium: <a href=""https://medium.com/@EOSNews"">https://medium.com/@EOSNews</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=""https://www.reddit.com/user/EOSBlockchainNews""> /u/EOSBlockchainNews </a> <br/> <span><a href=""https://www.reddit.com/r/eos/comments/atcimm/effectai_is_migrating_to_eos/"">[link]</a></span> &#32; <span><a href=""https://www.reddit.com/r/eos/comments/atcimm/effectai_is_migrating_to_eos/"">[comments]</a></span>",Artificial Intelligence,0.837,[ Effect.AI is migrating to EOS ],standard
37,https://news.ycombinator.com/item?id=19808123,conversations_hackernewsnew,16.337688,[],AI,"# How-To Build Trust in Artificial Intelligence Solutions

## A PsychologistÈs Perspective on trust-building in AI and what mechanisms
companies need to understand to meet the needs of their customers and users.

> We interviewed [Marisa Tschopp](https://www.linkedin.com/in/marisa-
tschopp-0233a026/) who is an organizational psychologist conducting research
about Artificial Intelligence from a humanities perspective with a focus on
psychological and ethical questions. She is also a corporate researcher at
[scip AG](https://www.scip.ch/en/?labs.20190411), a technology and
cybersecurity company based in Zurich. And she is the [Women in
AI](https://www.womeninai.co/) Ambassador for Switzerland.

**Please describe who you are in 23 sentences.**

Currently, I am focusing on trust in AI, Autonomous Weapons Systems, and our
AIQ project, which is a psychometric method to measure the skills of digital
assistants (conversational AI), like Siri or Alexa.

So, obviously IÈm a researcher, but IÈm also a mother of two toddlers, a wife,
a daughter, a sister, a volleyball player, hopefully a fun friend to be with,
an activist, an idealist, a collaborator, and a semi-professional Sherpa (I
love hiking in the Swiss Alps and therefore have to carry my kids on my
back!).

**Let us start with understanding trust better. What is trust and why is it
important, especially in the context of AI?**

In the context of AI, there is a critical underlying assumption: No trust, No
Use. Since AI holds great promises (as well as dangers), tech-companies and
AI enthusiasts are especially concerned about how to build trust in AI to
foster adoption or usage.

> Trust seems like _the_ lasting, kind of mysterious, competitive edge.

Without trust, there would be no family, no houses, no markets, no religion,
no politics, no rocket science.

According to trust researcher [Rachel
Botsman](https://medium.com/@rachelbotsman),

> Trust is the social glue that enables humankind to progress through
interaction with each other and the environment, including technology.

Trust can be seen as a psychological mechanism to cope with uncertainty and is
located somewhere between the known and the unknown.

Picture: [Rachel Botsman](https://medium.com/@rachelbotsman/trust-
thinkers-72ec78ec3b59)

Trust is deeply ingrained in our personality. We are basically born with a
tendency to trust or distrust people (or animals or any other things).

Take for example this random picture of a woman: Do you trust her? Please rate
below.

[Nannie Doss](http://tonsoffacts.com/25-interesting-and-bizarre-facts-about-
nannie-doss/)

We, humans, have the unique capacity to tell in a snapshot if we trust this
person or not. We look at the facial expression, body posture, or the context
(background, surroundings, etc.). We compare it with memories or past
experiences in split seconds, such as she reminds me of my grandmother.

> Generally speaking, what we know is that we tend to trust people more, who
are more like ourselves. One reason is, that it is easier for us to predict
future behavior or reactions of persons who are alike, which lowers the
emotional risk for us of being hurt.

What we do not know is, how accurate our intuition is. Did you trust this
woman above? Maybe yes, because she is smiling, relaxed. Maybe no, because you
are already expecting some kind of trick here, as I am a psychologist.

This woman is not very trustworthy. **She died several years ago in prison as
one of the most famous female serial killers.**

**In the context of AI, if you ask the question can we trust in AI as a
technology,** then compared to other technologies, it is decisive to
understand that often AI (for example Machine Learning, letÈs say image
classification), does not behave exactly the way it is intended, makes
mistakes, or performs unethically. For example, when black people are
classified as gorillas or birds as missiles.

#### The processes and outcome are hard to explain, sometimes not known at
all, hence, not well predictable. Trusting this technology incorporates a way
higher risk.

So far, research has agreed upon three main pillars that need to be answered
to build trust,

**1.) Performance:** Does it perform well? Is it safe? Is it built correctly?

**2.) Process:** Does it perform the way we intended? Can we predict the
outcome?

**3.) Purpose:** Do I have a good feeling about the intent of the program and
the provider? Does it adhere to ethical standards? Is it trustworthy?

It is often said, that AI positively transforms almost every sector from
medicine to urban planning, but very importantly, it also brings questionable
or even dangerous implications with it. From super-precise hacking of data
platforms to the surveillance state and loss of privacy without opportunities
for public consent. So next to technical issues like a lack of predictability
and explainability, the notion of negative outcomes, hype, complexity, and
disagreement within definitions and applications, leads to skepticism and
distrust.

**How should non-experts and business owners, etc. approach this topic?**

AI is already part of our daily lives, it is already increasingly being used
in decision-making when it comes to education, police, justice, recruitment or
health.

> I do not have a tech-background as well, I am a psychologist so I see things
from a different perspective, and it may be easier for me to feel empathy with
the majority of people, who have no idea how to code or what an algorithm is.

What fascinates me most and drives my research, is the question, how trust is
established in the first place. You donÈt really know the person or the
product, its values or competencies. This first little glimpse of saying yes,
IÈll go for it.

It is still a little mysterious, how this trust develops in the first place.

**How can we best cope with it?** I think it is all about education,
communication, and critical thinking. But there is something restricting these
skills or our will to engage in discussions about AI.

> From a psychological perspective, this is one of the big problems: we are
lacking cognitive freedom of choice. What concerns me, is that we are moving
towards a do-or-die relationship with AI. It will be almost impossible to get
away from AI, as much as we cannot get away from climate change.

The fact that we are forced or threatened, like the threatening terminator
images or the constant man losing against machine news, leads to resistance,
denial, cynicism, and downplay. This is called reactance, a psychological
phenomenon. When reactance occurs  we choose these behaviors  even if they
are totally irrational  **to simply restore our cognitive freedom of choice
and take back our sense of control.**

**This can be a big challenge, especially in consumer psychology** when you
aim to convince customers to buy your products, whether itÈs a car or a
robotic vacuum cleaner.

#### Consumers like all human beings want the freedom of choice and we need to
figure out ways, to make people want to explore AI by themselves, not because
they are forced to do so.

That is why management often applies bottom-up approaches within their
company, rather than top-down decisions.

Through this participative way of decision making, you aim to have all people
aboard and share your vision and goals.

Right now, one of the key issues is to change the way we talk about AI. I
think we massively have to change the tone of the conversation about AI. We
must move away from the hype, threat, and fear towards clear facts, vision,
and why to create our own relationship with AI, and thus a new level of trust.

This is also my vision as the ambassador for the [Women in
AI](https://www.womeninai.co/) network, a nonprofit working towards a gender-
inclusive AI that benefits global society.

**Imagine a company is building a Machine Learning based product and just
started prototyping. What steps would you suggest from a trust-building
perspective?**

What I learned from a philosopher is to always ask why, from the beginning to
the very end, and continuously at all milestones of the project.

**What are the intended consequences and speculate about all possible
unintended consequences?**

From the design perspective, it is all about aligning your design to at least
minimal ethical standards, to make sure you are building a trustworthy
product. However, keeping in mind that technical performance (quality),
security and safety, are all indispensable prerequisites.

Going back to the beginning it is having the three pillars **process,
performance, purpose** constantly in mind. Ethics in AI is all about integrity
and authenticity.

In the end, the task is to build a great, safe and ethically correct
_product_. The focus naturally is at building a good product first, then comes
security and this ethical stuff.

It is natural to focus on the technical requirements first, whilst
counterintuitively, the latter should rather be looked at first. Two years
ago, when we started our trust research, our idea was to have like a proof of
quality to signal users or customers, that this is a trustworthy product. That
is why we invented the AIQ, a psychometric measurement method to state,
compare and track the skills of digital assistants. However, we were a bit too
fast as the market is still in a development phase rather than actually
improving existing conversational AI. We too, focused on the technical skill
sets at first, rather than the actual decisive soft factors of how trust is
built and developed.

Here is a podcast episode that talks about the topic in more detail.

Now we are stepping back and focus on the less obvious factors that influence
trust building in the context of AI. These are the fine influencing factors on
a micro level of perception, from personality traits to bias, to past
experiences, to socialization and upbringing. We are just gathering data to
explore these antecedents of trust in AI through associations, qualitative and
quantitative methods.

If you are interested to participate in the study you can fill out the form
[here](https://docs.google.com/forms/d/e/1FAIpQLSev6HiA_ns1NWUqWa3jMyDz7r-j0rUYFx34U08-FvqFeQHH4w/viewform).

**Is it possible to change the image of AI or influence consumer behavior
after a product launch?**

If you want to explore your trust image, you need to look at questions and
definitions from various perspectives: you may want to look at the individual
person (like characteristics of your target group or employees), you can look
at the process from building, maintaining, and developing trust from a
consumer perspective, as well as destroying and regaining trust. You have to
be clear of the actors and roles (who is to be trusted?) and the situation: is
it a high-risk situation like for example self-driving cars, or are we talking
about an AI-driven chatbot in customer service?

**In the end, the answer is yes** , however, in both directions, for better
or worse. We have to be very sensitive, neutral, or as Hans Roslin says
factful, when we talk about AI. Research is pretty clear on what to do to
sustain a relationship or how to act, if you have broken a trust relationship,
I am not sure if AI is then any different than other technologies. A breach is
a breach, whether it is FacebookÈs data breach or a misguided missile.

> If there was a trust breach you must communicate instantly, directly,
clearly what happened, explain yourself without being defensive, be authentic,
truthful, and ask for what is needed to get another chance.

**What books and other resources would you recommend for a business owner or
product manager to learn about trust-building in AI?**

I would suggest checking the [European High-Level Expert
Group](https://ec.europa.eu/digital-single-market/en/high-level-expert-group-
artificial-intelligence) on AI. They just released a framework for building
[trustworthy AI.](https://ec.europa.eu/digital-single-market/en/news/ethics-
guidelines-trustworthy-ai) The framework has three main pieces comprising
lawful AI, Ethical AI, and Robust AI. The key points of the two latter are
discussed in the report.

Another great set of comprehensive, crowd-sourced standards comes from the
[IEEE Global Initiative on Ethics of Autonomous and Intelligent
Systems](https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-
trustworthy-ai), which is called Ethically Aligned Design.

Rachel Botsman: Who can you trust? She writes about how trust is built, lost
and restored in the digital age, she also has several highly recommended [TED
Talks.](https://www.youtube.com/watch?v=CGwaPU8JwPQ)

**Enjoyed this article? Here is another one.**

#### [Subscribe here](https://tinyletter.com/Omdena) for practical tips,
expert interviews, and use cases on how to build trusted and socially-
beneficial AI solutions.",Artificial Intelligence,0.934,How-To Build Trust in Artificial Intelligence Solutions,standard
38,https://news.ycombinator.com/item?id=19439197,conversations_hackernewsnew,16.337688,[],AI,"Learning to drive can be stressful. And if you happen to get paired with an
impatient teacher or crazed family member it can be a nightmare. Along with
the stress, you might not learn enough to pass the driverÈs test.

In an attempt to make students more at ease and help them learn as efficiently
as possible, one driving school in China is taking out the human factor
altogether. A driving school in Zhenjiang has installed AI coaches in the
vehicles. The artificial intelligence, which lives in an interactive screen
attached to the dashboard, provides automatic voice navigation and will give
drivers unique commands.

For example, the robot voice will remind drivers to turn on their signal as
the car approaches a turn or to slow down if they pick up too much speed.

![AI Driving Coach Robot Artificial intelligence -
YellRobot](https://yellrobot.com/wp-
content/uploads/2019/03/AIDriver2-1024x570.jpeg)credit: Pear Video

# Robot Driving Coach Keeps Students Calm

The artificial intelligence will also take control of the car if need be. If
the car gets closer than 8 inches to an obstacle, it will automatically stop.
Students have remarked how the AI driving coach seems a bit more pleasant than
their human counterparts.

IÈm nervous when a real coach sits beside me. This robot is nicer. Even if I
do something wrong, the robot will continue to encourage me, instead of
blaming me, said one student driver said.

The robot can be set to a teaching mode or simulated test mode in which the AI
will let the driver know if they passed or not. The AI driving coach has not
hit the busy streets of China yet as it seems limited to a closed course. Some
students donÈt feel something like this would be effective in a real
environment.

No robot coach would help me step on the brakes if I were accidentally to
drive into a ditch, one student commented.

_Sources:[Pear Video](https://www.pearvideo.com/video_1530905) /
[ECNS](http://www.ecns.cn/news/2019-03-19/detail-ifzfmzhu2193194.shtml)_

* * *

Check out our articles on [AI helping to keep roads
safe](https://yellrobot.com/ai-road-management-system-weathernews/) and Tokyo
2020 [Olympics using robots](https://yellrobot.com/robots-exoskeletons-
tokyo-2020-olympic-panasonic-toyota/)",Artificial Intelligence,1,Artificial Intelligence Teaching Students How to Drive,standard
39,t3_blqqqs,conversations_reddit,16.265099,,,"No petitions, surveys, or crowdfunding",No tags,,Are algorithms and artificial intelligence inherently prejudiced?,standard
0,stackanswer-stackoverflow-56283560,conversations_stackoverflow-answers,10.26615,[],,"<p>Preciso de ajuda com minhas regras de seguran_a do Firestore, pois n£o est£o permitindo updates ou deletes como eu queria que fizessem.</p>

<p>Tenho 2 cole_µes: Ofertas e Usurios;
Cada usurio tem seu idUsurio e um papel(leitor, administrador, editor)
Cada oferta tem seu IdOferta e o IdUsuario(do usurio que a criou).</p>

<p>Quero permitir que apenas quem criou a oferta possa fazer updates ou deletes nela.
Isso funciona bem na func£o Proprietario();
Quero ainda que os usurios cujo campo Papel seja: administrador ou editor possam fazer updates ou deletes nas ofertas que n£o foram criadas por eles.</p>

<p>Essa © a parte em que n£o funcionam as regras</p>

<p>Algu©m pode me ajudar? Eu li 2 vezes tudo que achei no firebase sobre as regras, mas n£o consigo criar uma que funcione.
Eu entendi que eu precisaria de um get(/databases</p>

<pre><code>service cloud.firestore {
match /databases/{database}/documents {

match /ofertas/{oferta}{

allow read: if logado();
allow create: if logado();
allow update: if proprietario();
allow delete: if proprietario() || isAdmin();

}
match /usuarios/{usuario}{
function isAdmin(){
return resource.data.papel == ""administrador"";
}
allow read: if logado();
allow create: if logado();
allow update: if request.auth.uid == usuario;


}

function logado(){
return request.auth!=null;
}

function proprietario(){
return request.auth.uid == resource.data.idUsuario;
}

function temAcesso(){
return resource.data.tipo 
in get(/databases/$(database)/documents/usuarios/$(tipo)).data.tipo;
}

}


}
</code></pre>",Cloud,0.935,Cloud Firestore Security Rules permission,standard
1,stackanswer-stackoverflow-56424526,conversations_stackoverflow-answers,10.26615,[],cloud,"<p>Mainly Virtualization means, running multiple operating systems on a single machine but sharing all the hardware resources. And it helps us to provide the pool of IT resources so that we can share these IT resources in order get benefits in the business.</p>

<p>For the maintenance of resources in cloud computing environment, virtualization is a necessity as it makes it easier. Virtualization in Cloud Computing increases security as it protects both the integrity of guest virtual machines and cloud components. Cloud Component virtualized machines can also be scaled up or down on demand or can provide reliability. Resource Sharing, high utilization of pooled resources, rapid provisioning are also some of the factors Managed Service Provider VA provides.</p>

<p><a href=""https://www.esds.co.in/enlight-cloud-hosting"" rel=""nofollow noreferrer"">https://www.esds.co.in/enlight-cloud-hosting</a></p>",Cloud,1,Virtual machine and cloud computing,standard
2,stackcomment-stackoverflow-96338493,conversations_stackoverflow-answers,10.2607975,,cloud,Hii. i stored a file in firebase cloud storage and i want to read or download that file. I tried what you said and deployed that cloud function. But i didn&#39;t get any data from that file and i didn&#39;t see any directory what i created in cloud functions folder . where it is created and located?,Cloud,1,Hii. i stored a file in firebase cloud storage and i want to read or download that file. I tried wha,standard
3,stackcomment-stackoverflow-98670055,conversations_stackoverflow-answers,10.2607975,,cloud,"If you think there is a bug in Cloud Functions, you should <a href=""https://support.google.com/firebase/contact/support?page=bug_or_feature"" rel=""nofollow noreferrer"">file a bug report</a> for that. But I can assure you that the times on Cloud Functions are not off by four hours. That would be critically bad. What you are seeing is likely just a difference in timezone between your machine and Cloud Functions.",Cloud,0.92,"If you think there is a bug in Cloud Functions, you should <a href=""https://support.google.com/fireb",standard
4,stackanswer-stackoverflow-56304821,conversations_stackoverflow-answers,10.2607975,[],cloud,"<p>See <a href=""https://firebase.google.com/docs/hosting/functions"" rel=""nofollow noreferrer"">https://firebase.google.com/docs/hosting/functions</a> .</p>

<blockquote>
<p>Cloud Functions for Firebase lets you automatically run backend code in response to HTTPS requests. Your code is stored in Google's cloud and runs in a managed environment. There's no need to manage and scale your own servers.</p>

<p>For example use cases and samples for Cloud Functions integrated with Firebase Hosting, visit our serverless overview.</p>
</blockquote>",Cloud,1,What exactly is &quot;source&quot; in the context of Firebase rewrites?,standard
5,stackanswer-stackoverflow-55048298,conversations_stackoverflow-answers,10.258867,[],cloud,"<p>Yes, just open a Terminal in Cloud 9 and start your app.</p>

<p>Then click on ""Preview"" button in Cloud 9 toolbar.</p>

<p>Detailed step by step instructions, incl a few limitations are detailed here 
<a href=""https://docs.aws.amazon.com/cloud9/latest/user-guide/app-preview.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/cloud9/latest/user-guide/app-preview.html</a></p>",Cloud,1,Quickly run express app in AWS cloud9 from app generated from cloudstar?,standard
6,stackanswer-stackoverflow-54986134,conversations_stackoverflow-answers,10.258068,[],cloud,"<p>Yes, it's the same datastore. Also called/soon-to-be <code>Cloud Firestore in Datastore mode</code> (which all older apps will be converted to at some point).</p>

<p>Yes, you can access it from anywhere, even from outside Google Cloud. From <a href=""https://cloud.google.com/appengine/docs/flexible/java/migrating#datastore"" rel=""nofollow noreferrer"">Cloud Datastore</a> (emphasis mine):</p>

<blockquote>
<p>You can access <a href=""https://cloud.google.com/datastore/docs"" rel=""nofollow noreferrer"">Cloud Datastore</a> from anywhere using the Cloud
Datastore API. Use the <a href=""https://cloud.google.com/sdk/cloud-client-libraries"" rel=""nofollow noreferrer"">Google Cloud client libraries</a> to store and
retrieve data from Cloud Datastore.</p>

<p><strong>The same Cloud Datastore data is available regardless of if you use the App Engine libraries, the Google Cloud client libraries, or call
the API directly.</strong></p>
</blockquote>

<p>The major steps to access the datastore from a Cloud Function:</p>

<ul>
<li>you can't use the GAE-specific client libraries like the one you likely used in your old app, you'll have to use one of the generic <a href=""https://cloud.google.com/datastore/docs/reference/libraries"" rel=""nofollow noreferrer"">client libraries</a> (or the <a href=""https://cloud.google.com/datastore/docs/reference/data/rest/"" rel=""nofollow noreferrer"">REST</a> or <a href=""https://cloud.google.com/datastore/docs/reference/data/rpc/"" rel=""nofollow noreferrer"">RPC</a> APIs)</li>
<li>you'll have to give your <a href=""https://cloud.google.com/functions/docs/securing/function-identity"" rel=""nofollow noreferrer"">CF's Identity/service account</a> the proper access permissions, see <a href=""https://cloud.google.com/datastore/docs/reference/libraries#setting_up_authentication"" rel=""nofollow noreferrer"">Setting up authentication</a> and <a href=""https://cloud.google.com/datastore/docs/activate#other-platforms"" rel=""nofollow noreferrer"">Accessing your database from another platform</a>.</li>
</ul>",Cloud,1,Can Google Cloud functions share a datastore with Appengine?,standard
7,stackcomment-stackoverflow-96585316,conversations_stackoverflow-answers,10.247631,,cloud,Could you share the code of your Cloud Function pls?,Cloud,1,Could you share the code of your Cloud Function pls?,standard
8,stackcomment-stackoverflow-97264745,conversations_stackoverflow-answers,10.247631,,cloud,no i am not on cloud so i use metalLB,Cloud,1,no i am not on cloud so i use metalLB,standard
9,stackanswer-stackoverflow-55389975,conversations_stackoverflow-answers,10.247631,[],cloud,"<p>I think it is now achievable through cloud functions
<a href=""https://firebase.google.com/docs/reference/functions/functions.auth.UserBuilder"" rel=""nofollow noreferrer"">https://firebase.google.com/docs/reference/functions/functions.auth.UserBuilder</a></p>",Cloud,0.981,prevent firebase user from deleting himself,standard
10,stackcomment-stackoverflow-98690262,conversations_stackoverflow-answers,10.247631,,cloud,"Possible duplicate of <a href=""https://stackoverflow.com/questions/49252427/point-cloud-library-with-visual-studio-2017"">Point Cloud Library with Visual Studio 2017</a>",Cloud,0.81,"Possible duplicate of <a href=""https://stackoverflow.com/questions/49252427/point-cloud-library-with",standard
11,stackcomment-stackoverflow-98895789,conversations_stackoverflow-answers,10.247631,,cloud,"@DevAS you can use <a href=""https://documentation.onesignal.com/reference"" rel=""nofollow noreferrer"">Onesignal API</a> or <a href=""https://firebase.google.com/docs/cloud-messaging"" rel=""nofollow noreferrer"">Firebase Cloud Messaging</a>",Cloud,0.833,"@DevAS you can use <a href=""https://documentation.onesignal.com/reference"" rel=""nofollow noreferrer""",standard
12,stackanswer-stackoverflow-56011926,conversations_stackoverflow-answers,10.244222,[],cloud,"<p>The two best ways to accomplish this goal would be by either using <a href=""https://cloud.google.com/functions/"" rel=""nofollow noreferrer"">Cloud Functions</a> or by using <a href=""https://cloud.google.com/dataflow"" rel=""nofollow noreferrer"">Cloud Dataflow</a>. For Cloud Functions, you would set up a trigger on the Pub/Sub topic and then in your code write to BigQuery. It would look similar to the <a href=""https://cloud.google.com/solutions/streaming-data-from-cloud-storage-into-bigquery-using-cloud-functions"" rel=""nofollow noreferrer"">tutorial on streaming from Cloud Storage to BigQuery</a>, except the input would be Pub/Sub messages. For Dataflow, you could use one of the <a href=""https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming#cloudpubsubsubscriptiontobigquery"" rel=""nofollow noreferrer"">Google-provided, open-source templates to write Pub/Sub messages to BigQuery</a>.</p>

<p>Cloud Dataflow would probably be better suited if your throughput is high (thousands of messages per second) and consistent. If you have low or infrequent throughput, Cloud Functions would likely be a better fit. Either of these solutions would run constantly and write the messages to BigQuery when available.</p>",Cloud,1,GCP: Where to schedule PubSub subscriber which writes to BigQuery,standard
13,stackoverflow-55072291,conversations_stackoverflow,10.236056,['ocr'],cloud,"<p>I'm looking for a cloud based solution to read the Machine Readable Zone from IDs or Passports to implement in our backend.</p>

<p>I tried some generic OCR solutions such as: </p>

<ol>
<li><strong>Amazon Rekognition</strong></li>
<li><strong>Google Vision</strong></li>
<li><strong>Microsoft Computer Vision</strong></li>
<li><strong>Teserract</strong> 3.0 / 4.0 (experimental)</li>
</ol>

<p>None of these provide accurate (sometimes not at all MRZ recognition)</p>

<p>I also tried some other tools specialized in MRZ OCR:</p>

<ol>
<li><strong>BlinkID</strong> from MicroBlink (which is very good but doesn't have a cloud solution)</li>
<li><strong>Accurascan</strong> (provides cloud solution but less accurate than BlinkID)</li>
<li><strong>Abbyy</strong> (too slow, 10~ seconds per request)</li>
</ol>

<p>Can you recommend me a good cloud solution for MRZ OCR of documents?</p>",Cloud,0.652,Reliable MRZ (Machine Readable) cloud API,standard
14,stackanswer-stackoverflow-54995658,conversations_stackoverflow-answers,10.23395,[],cloud,"<blockquote>
<p>Any framework can support this kind of requirements?</p>
</blockquote>

<p>Express (the older Koa) is more widely supported </p>

<ul>
<li><a href=""https://github.com/awslabs/aws-serverless-express"" rel=""nofollow noreferrer"">https://github.com/awslabs/aws-serverless-express</a></li>
<li><a href=""https://github.com/yvele/azure-function-express"" rel=""nofollow noreferrer"">https://github.com/yvele/azure-function-express</a></li>
</ul>

<h1>More</h1>

<p>Cloud vendors have various associated services (e.g. hosted databases) that differ significantly. You are going to struggle to get complete cloud redundancy. You will be best served using the internal redundancy options in the cloud provider you choose.</p>",Cloud,1,How to deploy a Koa based TypeScript project into both AWS Lambda and Azure Cloud Function?,standard
15,stackoverflow-55000865,conversations_stackoverflow,10.230841,"['google-cloud-platform', 'bigdata', 'data-lineage']",cloud,"<p>When we realize the data lake with GCP Cloud storage, and data processing with Cloud services such as Dataproc, Dataflow How can we generated data lineage report in GCP. Thanks.</p>",Cloud,0.819,How can I perform data lineage in GCP?,standard
16,stackanswer-stackoverflow-56052645,conversations_stackoverflow-answers,10.227014,[],cloud,"<p>Google Cloud Run fits into your Serverless layer but as a container. The container infrastructure is managed for you. </p>

<p>Cloud Functions are limited in respect to the libraries, languages, and runtimes supported.</p>

<p>Cloud Run removes those limitations. You can use any language, combination of libraries and runtime that supports running within a container. </p>

<p>One limitation is that there is only one internal port <code>$PORT</code> which defaults to 8080 today. Externally both HTTP and HTTPS are supported. Both HTTP and HTTPS map to <code>$PORT</code>.</p>

<p>One big plus is that Cloud Run supports custom DNS names and custom SSL certificates. You can host your website on Cloud Run. As an experiment, I set up WordPress and Cloud SQL on Cloud Run and assigned it a DNS domain name with an SSL certificate.</p>",Cloud,1,Would I benefit using Cloud run instead of Cloud Functions? Where does it fit in GCP?,standard
17,stackcomment-stackoverflow-96610628,conversations_stackoverflow-answers,10.21331,,cloud,Is the RGB image registered with the point cloud ?,No tags,,Is the RGB image registered with the point cloud ?,standard
18,stackcomment-stackoverflow-96799601,conversations_stackoverflow-answers,10.21331,,cloud,can&#39;t you use a cloud image for your requirement ?,Cloud,0.877,can&#39;t you use a cloud image for your requirement ?,standard
19,stackcomment-stackoverflow-96449605,conversations_stackoverflow-answers,10.21331,,cloud,"See: <a href=""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html"" rel=""nofollow noreferrer"">Amazon EBS Volume Types - Amazon Elastic Compute Cloud</a>",Cloud,0.94,"See: <a href=""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html"" rel=""nofollow",standard
20,stackanswer-stackoverflow-55968136,conversations_stackoverflow-answers,10.208327,[],cloud,"<p>You can control the pace at which cloud functions are triggered by controlling the triggers themselves. For example, if you have set ""new file creation in a bucket"" as trigger for your cloud function, then by controlling how many new files are created in that bucket you can manage concurrent execution.
Such solutions are not perfect though because sometimes the cloud functions fails and get restart automatically (if you've configure your cloud function that way) without you having any control over it. In effect, the number of active instances of cloud functions will be sometimes more than you plan.
What AWS is offering is a neat feature though. </p>",Cloud,0.852,How to handle backpressure using google cloud functions,standard
21,stackanswer-stackoverflow-55181268,conversations_stackoverflow-answers,10.208325,[],,"<p>Try by changing gradle version it worked me before, I too faced same issue few days back</p>

<pre><code>classpath 'com.android.tools.build:gradle:3.2.1'
</code></pre>",Cloud,0.811,Firebase cloud messaging gradle settings,standard
22,stackanswer-stackoverflow-55269119,conversations_stackoverflow-answers,10.208325,[],,"<p><code>firebase-functions</code> version 16.3.0, <a href=""https://firebase.google.com/support/release-notes/android"" rel=""nofollow noreferrer"">released 15 Mar 2019</a>, adds the ability to <a href=""https://firebase.google.com/docs/reference/android/com/google/firebase/functions/HttpsCallableReference"" rel=""nofollow noreferrer"">configure the timeout</a>.</p>",Cloud,0.763,Firebase Cloud Functions Change Timeout,standard
23,stackanswer-stackoverflow-55939033,conversations_stackoverflow-answers,10.208325,[],cloud,"<p>when you are creating your postgres instance you have to allow access to the ip address from the postgres' client is running.</p>

<p>1.-Create your postgresql instance
2.-In the Create a PostgreSQL instance window give the instance id and password to you postgres user in the Default user password section.
3.-clic on Show configuration options and locate Set connectivity, there You have to give access to Your pc ip address in the Authorized networks under Public IP section click on Add network introduce the ip into the Network box and click done, You can check the client ip address in the link[1] .
4.-If you are done with the configurations click create.</p>

<p>Now to verify the connectivity from the client to the GCS i recommend you to do it the first time with the command line console.</p>

<p>1.-In you pc lunch the command line console, 
2.-execute : psql -h [postgres instance ip address] -u postgres.
You can follow the official documentation for Connecting psql Client Using Public IP in the link[2].</p>

<p>[1]myIPaddress.com
[2]<a href=""https://cloud.google.com/sql/docs/postgres/connect-admin-ip"" rel=""nofollow noreferrer"">https://cloud.google.com/sql/docs/postgres/connect-admin-ip</a></p>",Cloud,1,Connect pgAdmin4 to cloud SQL,standard
24,stackanswer-stackoverflow-55015193,conversations_stackoverflow-answers,10.208325,[],cloud,"<p><a href=""https://cloud.google.com/nodejs/docs/reference/firestore/0.20.x/Firestore#runTransaction"" rel=""nofollow noreferrer""><code>runTransaction</code></a> returns a promise. You need to <code>await</code> it.</p>

<pre><code> await admin.firestore().runTransaction(...);
</code></pre>",Cloud,0.663,Firebase cloud transaction triggers error,standard
25,stackanswer-stackoverflow-56478275,conversations_stackoverflow-answers,10.208325,[],,<p>You can inject and use <code>SpanCustomizer</code> interface to customize the current span (add tags / logs etc.) or inject and use <code>Tracer</code> to retrieve the current span ad manipulate it.</p>,Cloud:Artificial Intelligence,0.68:0.992,Spring cloud slueth SpanAccessor interface,standard
26,stackanswer-stackoverflow-55070500,conversations_stackoverflow-answers,10.207169,[],cloud,"<p>If you do not have a name set for some-service, and it's a 3rd party service, I think the better approach would be to call it via RestTemplate or something. </p>

<p>Feign client needs to have the service name configured and known, for it to call that particular service in the network using service discovery. </p>",Cloud,0.819,Spring Cloud Kubernetes FeignClient Error,standard
27,stackanswer-stackoverflow-55955908,conversations_stackoverflow-answers,10.207169,[],cloud,"<p>Check the Google Cloud Status Dashboard if there are service interruptions for the day that your system encountered the issue.</p>

<p><a href=""https://status.cloud.google.com/"" rel=""nofollow noreferrer"">https://status.cloud.google.com/</a></p>",Cloud,1,Firebase Cloud Functions deploy error,standard
28,stackanswer-stackoverflow-55829960,conversations_stackoverflow-answers,10.207169,[],cloud,"<p>From <a href=""https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service</a>:</p>

<blockquote>
<p>When using a Service with spec.type: LoadBalancer, you can specify the
IP ranges that are allowed to access the load balancer by using
spec.loadBalancerSourceRanges. This field takes a list of IP CIDR
ranges, which Kubernetes will use to configure firewall exceptions.
This feature is currently supported on Google Compute Engine, Google
Kubernetes Engine, AWS Elastic Kubernetes Service, Azure Kubernetes
Service, and IBM Cloud Kubernetes Service. This field will be ignored
if the cloud provider does not support the feature.</p>
</blockquote>

<p>May be your cloud simply does not support it.</p>

<p>You can use other things that allow blocking by source IP, like nginx or ingress-nginx. In ingress-nginx you just specify list of allowed IPs in annotation <code>ingress.kubernetes.io/whitelist-source-range</code>. </p>

<p>If you want to go Nginx or other proxy route - don't forget to change Load Balancer Service <code>externalTrafficPolicy</code> to <code>Local</code>. Otherwise you will not see real client IPs.</p>",Cloud,1,spec.loadBalancerSourceRanges for Linode Cloud provider,standard
29,stackanswer-stackoverflow-55846997,conversations_stackoverflow-answers,10.207169,[],,"<p>There is a <a href=""https://github.com/dmacvicar/terraform-provider-libvirt"" rel=""nofollow noreferrer""><code>libvirt</code> provider</a> that is able to manage resources in KVM and is listed on the <a href=""https://www.terraform.io/docs/providers/type/community-index.html"" rel=""nofollow noreferrer"">community providers page</a>.</p>",Cloud,0.802,Using terraform in private cloud,standard
30,stackanswer-stackoverflow-56144304,conversations_stackoverflow-answers,10.207169,[],,"<p>If you want to transform your array elements into a new array, you could also use <a href=""https://developer.mozilla.org/de/docs/Web/JavaScript/Reference/Global_Objects/Array/map"" rel=""nofollow noreferrer""><code>Array.map</code></a>.</p>

<pre><code>allUsers = users.map(user =&gt; user.data());
</code></pre>",Artificial Intelligence,0.809,Typescript Cloud function not compiling,standard
31,stackanswer-stackoverflow-55180992,conversations_stackoverflow-answers,10.203379,[],,"<p>Take a look at the <a href=""https://firebase.google.com/support/release-notes/android"" rel=""nofollow noreferrer"">Firebase Android Release Notes</a> for the latests versions available for the different cores of <em>Firebase</em> functionalities. </p>

<pre><code>implementation 'com.google.firebase:firebase-messaging:17.4.0' 
</code></pre>

<p>Try updating it to the latest version available. </p>",No tags,,Firebase cloud messaging gradle settings,standard
32,stackanswer-stackoverflow-55350592,conversations_stackoverflow-answers,10.203379,[],,"<p>The problem was in puppeteer. I downgraded from the version 1.13.0 to 1.11.0 and now everything works fine. See the discussion <a href=""https://github.com/GoogleChrome/puppeteer/issues/3944"" rel=""nofollow noreferrer"">here</a></p>",Cloud,0.747,Cloud functions timeout on page.goto(),standard
33,stackanswer-stackoverflow-55862329,conversations_stackoverflow-answers,10.203379,[],cloud,"<p>I got the same kind of error.<br>
In my case, changing Node version to 8 fixed this error.</p>

<p><a href=""https://medium.com/google-cloud/migrating-firebase-cloud-functions-to-node-8-aebdb0d3d9a9"" rel=""nofollow noreferrer"">https://medium.com/google-cloud/migrating-firebase-cloud-functions-to-node-8-aebdb0d3d9a9</a></p>

<pre><code>Function failed on loading user code. Error message: Code in file index.js can't be loaded.
Is there a syntax error in your code?
Detailed stack trace: /user_code/node_modules/@google-cloud/logging/node_modules/gaxios/build/src/index.js:28
async function request(opts) {
^^^^^^^^

SyntaxError: Unexpected token function
at createScript (vm.js:56:10)
at Object.runInThisContext (vm.js:97:10)
at Module._compile (module.js:549:28)
at Object.Module._extensions..js (module.js:586:10)
at Module.load (module.js:494:32)
at tryModuleLoad (module.js:453:12)
at Function.Module._load (module.js:445:3)
at Module.require (module.js:504:17)
at require (internal/module.js:20:19)
at Object.&lt;anonymous&gt; (/user_code/node_modules/@google-cloud/logging/node_modules/gtoken/build/src/index.js:18:18)
</code></pre>",Cloud,0.883,Firebase Cloud functions deployment error,standard
34,stackanswer-stackoverflow-56071817,conversations_stackoverflow-answers,10.203379,[],,"<p>Do you tried like this ?</p>

<pre><code> @JvmField
@PropertyName(""championship-name"")
var championshipName: String = """"
@PropertyName(""championship-name"")
get() = field
@PropertyName(""championship-name"")
set(value) { field = value }
</code></pre>",Artificial Intelligence,0.843,Using PropertyName in Cloud Firestore,standard
35,stackoverflow-55948083,conversations_stackoverflow,10.193657,"['google-cloud-platform', 'google-cloud-sql']",cloud,"<p>I'd like to call Cloud SQL API described below from Cloud Functions.</p>

<ul>
<li><a href=""https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export?hl=en"" rel=""nofollow noreferrer"">https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export?hl=en</a></li>
</ul>

<p>And I found libraries to call GCP APIs.</p>

<ul>
<li><a href=""https://github.com/googleapis/google-cloud-node"" rel=""nofollow noreferrer"">https://github.com/googleapis/google-cloud-node</a></li>
<li><a href=""https://github.com/googleapis/google-cloud-go"" rel=""nofollow noreferrer"">https://github.com/googleapis/google-cloud-go</a></li>
</ul>

<p>However, there does not seem to be any modules for Cloud SQL.</p>

<p>I'm wondering why it's not implemented. is the reason that the APIs are relatively new? or that I misunderstand the purpose of the libraries and actually it shouldn't be implemented in the libraries?</p>",Cloud,0.966,Why aren&#39;t there any SDKs to call Cloud SQL API?,standard
36,stackoverflow-55999325,conversations_stackoverflow,10.193644,"['google-cloud-functions', 'serverless-framework']",cloud,"<p>I use serverless framework to manage my cloud functions. Some of them are of HTTP type. Recently, all the HTTP functions started to fail with 403 error. No matter if you enter a URL in a browser or trigger it with the cloud scheduler. The only place where it works is the <em>testing</em> tab of the function in the cloud console, when you click the ""<em>Test the function</em>"" button.</p>",Cloud,1,Google HTTP Cloud Function returns 403,standard
37,stackcomment-stackoverflow-96575509,conversations_stackoverflow-answers,10.1908245,,cloud,I meant creating w/ the use of Cloud Deployment Manager. I can create via Google Cloud Console but what I want is via Cloud Deployment Manager. I can not find anything in their documentation regarding this,Cloud,1,I meant creating w/ the use of Cloud Deployment Manager. I can create via Google Cloud Console but w,standard
38,stackcomment-stackoverflow-97612111,conversations_stackoverflow-answers,10.1908245,,cloud,This is my entire code on cloud function to convert the uploaded audio file from cloud storage bucket to text using speech api.... the code throws error saying that invalid arguments on calling speech api....,Cloud,0.92,This is my entire code on cloud function to convert the uploaded audio file from cloud storage bucke,standard
39,stackcomment-stackoverflow-96602387,conversations_stackoverflow-answers,10.178435,,cloud,c4f4t0r: will approach differ for cloud or premises or hybrid environment?,Cloud,0.888,c4f4t0r: will approach differ for cloud or premises or hybrid environment?,standard
40,stackanswer-stackoverflow-55031080,conversations_stackoverflow-answers,10.178435,[],cloud,<p>Model export feature is currently not supported in Cloud AutoML Vision.</p>,Cloud,1,Exporting a model to be implemented in mobile app,standard
41,stackanswer-stackoverflow-55015300,conversations_stackoverflow-answers,10.165311,[],cloud,"<p>The <code>runTransaction</code> method returns a <code>Promise</code>.
And as the <a href=""https://firebase.googleblog.com/2017/06/keep-your-promises-when-using-cloud.html"" rel=""nofollow noreferrer"">this blog post</a> says: You have to return that <code>Promise</code>.</p>

<p>And these is important:</p>

<blockquote>
<p>...if you want a function to stay alive during async work, you can do this by returning a promise from the function (except for HTTP/S triggers, which require a response sent to the client).</p>
</blockquote>

<p>Or in other words: If you don't return that <code>Promise</code>, your function could finish without completing the <code>transaction</code>.</p>

<pre><code>import * as functions from 'firebase-functions';
import * as admin from 'firebase-admin';
admin.initializeApp();

exports.addShard = functions.firestore
.document(`likes/{docID}`)
.onCreate(async (snap, context) =&gt; {
const postID: string = snap.data().postID;
const randNum: number = (Math.floor(Math.random()*3+1)); 
const postRef = admin.firestore().doc(`post/${postID}/count_shards/${randNum}`);

return admin.firestore().runTransaction(async transaction =&gt; {
const postShard = (await transaction.get(postRef)).data();
postShard.count += 1;
return transaction.update(postRef, postShard);
});

});
</code></pre>",Cloud,0.812,Firebase cloud transaction triggers error,standard
42,stackanswer-stackoverflow-55047103,conversations_stackoverflow-answers,10.165311,[],cloud,"<p>It is a good practice to externalise any kind of sensitive information.</p>

<p>If I were you, I would use Environment Variables. This <a href=""https://docs.aws.amazon.com/lambda/latest/dg/eventsources.html#eventsources-sqs"" rel=""nofollow noreferrer"">answer</a> explains how to fetch Env Variables in Java.</p>

<p>If you are running (or plan to run) on the Cloud, you can take a look into your provider's way to store parameters. AWS, for example, uses <a href=""https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html"" rel=""nofollow noreferrer"">Systems Manager Parameter Store</a></p>

<p>Other options would be to read a file during runtime, look up in a database, etc. You get the idea.</p>",Cloud,0.944,Optimize properties variables Spring Cloud,standard
43,stackanswer-stackoverflow-54881290,conversations_stackoverflow-answers,10.165311,[],cloud,"<p>You cannot change the lifetime from Google side, as the doc you post said, Google side (Cloud VPN) just negotiates with the lifetime with the on-premise, being the max 36,000 seconds (10 hours) for Phase1.</p>

<p>In any case, you will need to change this at your on-premise side. </p>",Cloud,0.775,Adjusting GCP Cloud VPN Lifetime,standard
44,stackanswer-stackoverflow-55477194,conversations_stackoverflow-answers,10.165311,[],,"<ol>
<li>Comment or cut your function</li>
<li>Deploy</li>
<li>Uncomment or paste back the function</li>
<li>Rename the function</li>
<li>Deploy</li>
<li>Rename the function back</li>
<li>Deploy</li>
</ol>",Artificial Intelligence,0.626,Firebase cloud function deploy error,standard
45,stackanswer-stackoverflow-55959852,conversations_stackoverflow-answers,10.165311,[],cloud,<p>You donÈt save image into firestore but image url. After you save image into storage you have to get the url of that image and then save the url to firestore. Just google these steps or see documentation for more info</p>,Cloud:Artificial Intelligence,0.965:0.684,Saving image to Cloud firestore,standard
46,stackanswer-stackoverflow-55839927,conversations_stackoverflow-answers,10.165311,[],cloud,"<p>There is no such thing as ""Firebase functions"". What you're referring to is Cloud Functions with Firebase tools layered on top of it.</p>

<p>You can connect Cloud Functions (with Firebase or not) to an external database as long as you're on the Blaze payment plan, which allows you to make outgoing connections to some third party service.</p>",Cloud,1,Firebase functions with cloud sql,standard
47,stackanswer-stackoverflow-56274380,conversations_stackoverflow-answers,10.165311,[],cloud,"<p>Node 8 is available for cloud functions now. Try upgrading your environment.</p>

<p>You probably just need to:</p>

<ul>
<li>Add ""engines"": { ""node"": ""8"" } to your /functions/package.json. <a href=""https://github.com/firebase/functions-samples/blob/Node-8/stripe/functions/package.json"" rel=""nofollow noreferrer"">Example</a>. </li>
</ul>

<p>In case it still doesn't work: </p>

<ul>
<li>Upgrade your firebase-functions to the latest version</li>
<li>Upgrade firebase-tools to the latest version</li>
</ul>",Cloud,0.851,Object.values() in Firebase Cloud Functions,standard
48,stackoverflow-55838902,conversations_stackoverflow,10.16206,['google-cloud-platform'],cloud,"<p>I checked out ""Google Cloud Platform Marketplace"", most solutions are built to ""launch on compute engine"".</p>

<p>Are there any ""Google Cloud Platform Marketplace Solutions"" built to ""launch on app engine""?</p>

<p>A good percentage of my projects are built and processed on app engine. If I can find these app engine solutions from ""Google Cloud Platform Marketplace"", that will save me a lot of development time.</p>",Cloud,0.99,Google Cloud Platform Marketplace launch on compute engine. How about Marketplace solutions launch on app engine?,standard
49,stackoverflow-55513746,conversations_stackoverflow,10.15982,"['text-files', 'google-cloud-pubsub']",cloud,"<p>i am trying to publish data to Cloud Pub Sub .Data is in JSON format and is being kept in my local folder. I am not using Cloud Storage and trying to read the pubsub message directly through cloud function. Tested the flow with manually passing messages and the data is getting inserted into Bigquery tables also. Only place i got stuck is, how will i pass a .txt file JSON dataset to Cloud PubSub</p>

<p>Sample data
{""ID"":6,""NAME"":""Komal"",""AGE"":22,""ADDRESS"":""Assam"",""SALARY"":20000}</p>

<p>Can any one give me a hint!!</p>

<p>I could see various options using cloud storage and all, here i am reading the changed data from DB table,insert those records into 1 dummy table and converting the data from that table to JSON format and writing to a .txt file. From here if i could publish the data to pubsub , entire flow will get completed</p>

<p>If i manually pass like below , the data will get inserted</p>

<p>gcloud pubsub topics publish pubsubtopic1 --message {""ID"":6,""NAME"":""Komal"",""AGE"":22,""ADDRESS"":""Assam"",""SALARY"":20000}</p>

<p>Thanks In Advance</p>",Cloud,1,Read a txt file JSON data to publish the messages in Cloud Pub Sub,standard
0,https://news.ycombinator.com/item?id=19394898,conversations_hackernewsnew,16.17212,[],AI,"Threelly uses state of the art A.I. to analyze videos for key insights:
topics, scenes, people, sentiments, and much more.



Threelly uses state of the art Artificial Intelligence algorithms to automatically analyze videos to locate and pull the precise location of key points of interest like - topics, scenes, people, sentiments, brands, expressions, labels and much more. Allowing you to rapidly gain intelligent insights from any video.


How does it work?
-----------------
1. Install
2. Go to YouTube.com
3. Watch your favorite videos in YouTube as usual - magic will happen :)


AI Powered Video Insights. 
Gain deep insights with time-based tags that are created automatically. 
ThreellyÈs unparalleled AI recognition recognizes a huge variety of visual concepts and objects; recognize faces, logos or known graphics; Visual tags, Celebrity recognition*, Person recognition*, Speech-to-text, Visual text (OCR), Known graphics & logos, Locations & landmarks and much more. All powered by state of the art Artificial Intelligence (AI) algorithms. 

Radically Simple. 
Threelly is built to be innovative and radically simple. 
It installs right away with a single click and works directly in the Chrome browser. No need to download files or install complicated software. Use the clean, simple and intuitive interface to personalize YouTube insights to your liking. Create your own list of time-based tags to reveal insights into the videos you care about. 

Take The Quantum Leap Forward With Threelly. 
YouTubers, Students, Educators, Broadcasters, studios, gamers, or anyone consuming video on YouTube will benefit greatly from Threelly. 
Threelly built to remove friction from interacting with video; bringing AI-DRIVEN INSIGHTS to your fingertips. Our commitment is to give you insights QUICKLY and save you TIME.

This extension works on Chrome Browsers, whether it's Windows, Mac OS X or Linux.



== Feedback and bug reports ==
Threelly is still in beta, and we're constantly making updates, fixing bugs and adding new features. 
If you're having issues or found a bug, please don't post your bug report here, contact us directly so we can fix it: yourfriends@threelly.com


== Enjoying Threelly SmartView? Please rate! 
== FIVE STAR REVIEWS REQUESTED
If you like THREELLY SMARTVIEW, please help spread the word by giving it a 5 star rating here ;)
If you're not fully satisfied, please contact us yourfriends@threelly.com and we'll make sure to help.

Stay in touch:
For new feature announcements or just to say hello, please follow @Threelly123 on Twitter or instagram http://twitter.com/threelly123
Like us on Facebook: http://facebook.com/threelly123

v.1.25 Release Notes:
+ Minor improvements and optimizations
 Resolved issue with YouTube player pausing at 60 secs.
 Resolved issue with slice bar not refreshing upon change of video.
 User can copy to clipboard a direct link to a ""slice"" for sharing.",Artificial Intelligence,0.976,Unlocking Insights from Videos with Artificial Intelligence,standard
1,https://news.ycombinator.com/item?id=19712347,conversations_hackernewsnew,16.17212,[],AI,"# Ai Hashtags

#### Generate Hashtags using Artificial Intelligence

_The iOS app has been built, but I can't afford to pay $ 99/year to submit a
free app,_

[More details](https://smakosh.com/solving-hashtags-problems)",Artificial Intelligence,0.546,Show HN: Generate Hashtags Using Artificial Intelligence,standard
2,https://news.ycombinator.com/item?id=19798999,conversations_hackernewsnew,16.17212,[],AI,"# Artificial Intelligence will Enhance and Hack Humanity

The truth is, itÈs complicated and will become even more complicated. AI is
already being used to hack us in multiple ways, from us gifting our data and
private info to technology firms to how our attention on our mobile devices is
funneled.

The internet has created new pillars that monetizes the future where AI isnÈt
just not regulated, it hasnÈt even hit its stride in how ubiquitous it will
become.

* Attention economy
* Surveillance capitalism
* AI in driving global GDP
* AI in cybersecurity
* AIÈs role in technological loneliness (divide and conquer in the smart home)

If AI has become the new arms race between the likes of the U.S and China,
we stand at the dawn of a new era where [AI will both
enhance](https://www.wired.com/story/wired25-kai-fu-lee-fei-fei-li-artificial-
intelligence/) and hack us in ways we cannot yet imagine.

After reading [Jun Wu](https://medium.com/@junwu_46652)Ès piece on [Empathy in
Artificial Intelligence](https://towardsdatascience.com/empathy-in-artificial-
intelligence-eb167f62af99), it got me thinking. Male bias and the
militarization of AI is very dangerous for humanity. ItÈs probably an
existential threat to our survival as a species. I donÈt just mean this in the
Elon Musk terms of AGI, but in how we fail to regulate it.

#### China will Lead Ethics in AI in the 21st Century

As China rises to dominance both technologically and economically that will
become more pronounced in the 2030s, their approach to ethics in AI will begin
to dominate the world. We can already tell that they will be the leaders in
how facial recognition informs universal systems of surveillance, the
manifestation of social credit systems and the monetization of data in Asia.

* Facial recognition and its ethical implications.
* AI in the rise of Universal Surveillance Architecture Systems (USAS)
* Emergence of Social Credit Systems
* Monetization of data in Asia

[China is best
positioned](https://www.ft.com/content/f92abc38-6bb8-11e9-80c7-60ee53e6681d)
in the future to influence and impact policy regarding the regulation of AI.
They have started to think seriously about the [ethics of
AI.](https://www.scmp.com/topics/artificial-intelligence) Their thinking is
not yet mature, but if China can be a leader globally in any signal way that
is most important to the future of humanity, itÈs on the [regulation & ethics
of AI](https://www.scmp.com/business/commodities/article/2157700/ethics-and-
pursuit-artificial-intelligence).

Before that happens they will likely make a lot of mistakes and serious
breaches of AI ethics, and its impact on things like human rights.

#### The Age of Biotechnology & AI is an Ethical Minefield

Wired recently interviewed Fei-Fei Li, you can read the interview
[here](https://www.wired.com/story/will-artificial-intelligence-enhance-hack-
humanity/). Here are some bullet points from that event:

* The era of Biotechnology will allow people to hack their humanity in ways that were never possible before.
* AI will be deeply implicated in how we hack other humans and alter even our DNA.
* The era of AI and biotech enhancements is coming, so the question is, who decides what is a good enhancement and what is a bad enhancement?
* YNH: _The easiest people to manipulate are the people who believe in free will, because they think they cannot be manipulated._

An awesome debate. Yuval Noah Harari & Fei-Fei Li

### The 4th Industrial Revolution

* In the 4th industrial revolution is an era of great convenience and major ethical questions that could lead to irreparable damage in how we evolve as a species (it could lead to our extinction).
* What are the good qualities we need to enhance? What happens when our military is automated and robotic? Is enhancing ourselves with AI dangerous?
* The technological pressure of innovation for monetization also means powerful corporations could easily become too powerful where they place corporate profits ahead of ethical considerations. In 2019, we already have a long list of such occurrences.
* There is already a crisis between engineers and their managers playing itself out at companies such as Google (and many other $1 Trillion dollar firms). The employees of BigTech are speaking out, with mixed results regarding the ethics of the work they are doing. AI is nearly always implicated in this.

#### Enhancing Means Hacking Humanity

As companies like Amazon and Google invade the smart home, our private data
and health data will become a major issue in the ethics of AI. This is because
simultaneously these companies will become giants in the AI of the future of
healthcare.

* Google itself launched and[ dissolved its own AI ethics board](https://www.theverge.com/2019/4/4/18296113/google-ai-ethics-board-ends-controversy-kay-coles-james-heritage-foundation) due to major controversy surrounding it.
* In 2019, the debate about ethics in AI also centers on if putting _Advertising_ at the center of the internet is healthy for the world. Facebook & Google among others are implicated in this on-going debate.

Apple and Facebook are pivoting into privacy architectures and walled gardens
based on subscription revenue (Apple) and the monetization of encrypted Chat
(Facebook).

The advent of artificial intelligence forces humanity, both governments and
the corporate sector to organize rules and guidelines on artificial
intelligence, bio-technologies and robots that protects the fate of the
species. Realistically this will take decades to find a global consensus on.

### The 2020s are a Black Mirror decade for Ethics in AI

Before that takes place thereÈs a period where hacking (rather than enhancing)
human becomes the wild-wild west of cybersecurity invasion. You can think of
smartphone addiction and mobile app engineering as part of this stage.

Fines against companies like Google & Facebook for monopolistic and privacy
data infractions are slow and relatively minor compared to the scale,
influence and power of these firms and the utilities they provide.

#### Artificial General Intelligence

The possibility of AGI manifesting in the 21st century is low, but still an
existential threat to humanity. More important that how humanity deals with
other life forms in our galaxy, guidelines for how to deal with AGI should it
ever manifest needs also to be constructed. As for artificial intelligence in
the current era, itÈs impossible to regulate.

We need better AI to moderate and regulate AI. ItÈs exponential growth in how
machine intelligence and algorithms are impacting us is a very difficult topic
considering the lack of checks and balances in capitalism. ItÈs likely that
the 2020s are a very messy decade in terms of how humanity is hacked by
corporations. It could realistically lead to a surveillance architecture that
our parents might easily consider a dystopia.",Artificial Intelligence,0.964,Artificial Intelligence Will Enhance and Hack Humanity,standard
4,https://news.ycombinator.com/item?id=20055498,conversations_hackernewsnew,16.17212,[],AI,"Microsoft unveiled a [curriculum](https://docs.microsoft.com/en-
us/learn/paths/ai-business-school-government/) in its Artificial Intelligence
Business School this week that is specifically tailored for government
decision-makers.

The fact is that government workers across the boardand especially decision-
makersdonÈt necessarily have that familiarity or depth on AI, Anthony
Salcito, MicrosoftÈs vice president for government, said in a
[statement](https://blogs.microsoft.com/ai-for-business/2019/05/27/government-
ai-school/?utm_source=ai-blog&utm_campaign=1735). This new learning path is a
way to get them introduced to the concept and to understand why itÈs important
in the context of government work.

The tech giant launched its AI Business School in March to help executives and
other business leaders better understand how to implement the technology
through a free online master class. Now that more than 140,000 people have
gained practical guidance from the AI course material to date, the company is
offering a new path that is designed especially for government agencies.

Through various course modules, government insiders can learn about the
components that comprise a strong AI strategy, principles to guide responsible
AI adoption, lessons on fostering an AI-ready culture and other insights
around using the tech to better serve their constituents.

The course content also includes a case study demonstrating how a city in
Finland has integrated AI to more efficiently serve citizens and a demo that
showcases how the government can utilize intelligent bots to help constituents
access needed resources, among other materials and a video lecture.

Microsoft is also expressly gearing the curriculum to governments of all sizes
and Salcito said the new learning path is motivated by MicrosoftÈs key
priority, which is to help the government serve its constituents through
cloud services.

We believe this course is valuable for government decision-makers at all
levels  from small municipalities to large cities, Salcito said. The beauty
of artificial intelligence technologies is their scalability.",Artificial Intelligence,1,Microsoft Unveils Artificial Intelligence Course for Government,standard
5,stackoverflow-55373454,conversations_stackoverflow,16.111567,AI,"<p>I am new on artificial intelligence and I am using TensorFlow object detection API to detect a product on images, so It already detecting object but I wanna to get coordinates Xmax,Xmin Ymax and Ymin for each object on the images.</p>

<p>That is the images with object detected, so in this case was detected 2 object on the image.</p>

<p>Link:</p>

<p><a href=""https://i.ibb.co/CVd1xLR/download.png"" rel=""nofollow noreferrer"">https://i.ibb.co/CVd1xLR/download.png</a></p>

<p>We can see that I got the coordinates of objects but its no clearly, there more than 3 coordinates in the output and I just want to get the amount of coordinates as the number of objects that are in the image. </p>

<p>This the code which provide the output </p>

<pre><code>with detection_graph.as_default():
with tf.Session(graph=detection_graph) as sess:
image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')
detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')
num_detections = detection_graph.get_tensor_by_name('num_detections:0')

print(detection_graph.get_tensor_by_name('detection_boxes:0'))

for image_path in TEST_IMAGE_PATHS:
boxes = detect_objects(image_path)
print(boxes)

</code></pre>

<p>Output </p>

<pre><code>Tensor(""detection_boxes:0"", dtype=float32)
[[[0.16593058 0.06630109 0.8009524 0.5019088 ]
[0.15757088 0.5376015 0.8869156 0.9394863 ]
[0.5966009 0.88420665 0.6564093 0.9339011 ]
...
[0. 0. 0. 0. ]
[0. 0. 0. 0. ]
[0. 0. 0. 0. ]]]

</code></pre>

<p>I want to get something like that. only the coordinates of the Bounding Box. We assuming that they are the coordinates of the objects.</p>

<pre><code>[0.16593058 0.06630109 0.8009524 0.5019088 ]
[0.15757088 0.5376015 0.8869156 0.9394863 ]

</code></pre>",Artificial Intelligence,1,"how to get bounding box [Xmax,Xmin,Ymax,Ymin] from tensorflow object detection",standard,
14,t3_b651cx,conversations_reddit,15.941394,,,"No petitions, surveys, or crowdfunding",No tags,,Three Pioneers in Artificial Intelligence Win Turing Award,standard
15,https://news.ycombinator.com/item?id=19362775,conversations_hackernewsnew,15.875434,[],AI,"### Export Results as a new summarized PDF

You've made your search in thousands of documents, and you've found pages
about your search in dozens of them. You need to share the results with your
colleagues. Do you have to share all documents containing hundreds of pages to
share just dozens of related pages? Not anymore.

PDF Search allows you to export the most relevant pages in search results as a
new PDF document. So you can share a summary report with your friends with a
single document.",Cloud,0.81,Use of Artificial Intelligence to search within documents,standard
16,https://news.ycombinator.com/item?id=19510796,conversations_hackernewsnew,15.875434,[],AI,"Russian banks are stepping up the use of [artificial
intelligence](https://www.computerweekly.com/ehandbook/A-Computer-Weekly-
buyers-guide-to-automation-and-AI-in-systems-management) (AI) as the
technologyÈs unprecedented evolution looks set to see it boost their
competitiveness, but shortages of people with the right skills, as well as
infrastructural issues, are hampering the technologyÈs wider applications.

AI is undergoing a period of unprecedented evolution. Over the next few
years, the technology will progress so far that AI will be employed in
financial institutions just as often as humans, said [Sergey
Putyatinsky](https://mkb.ru/en/about/corporate-governance/management-
board/putyatinskiy-sergey-evgenevich), deputy chairman of Credit Bank of
Moscow (CBoM)[](https://mkb.ru/en/about/corporate-governance/management-
board/putyatinskiy-sergey-evgenevich). Active use of AI technology will be a
decisive factor in banksÈ competition in mass segments.

According to a study conducted by the [local rating agency Expert
RA](https://www.raexpert.com/), in cooperation with the Centre for Financial
Technologies, Russian banks most often use AI in credit analysis.

Other areas where AI adoption has been increasing, according to the study, are
debt collection and marketing, including creation of individual [offers for
customers](https://www.computerweekly.com/news/252441507/One-fifth-of-global-
banks-think-AI-will-boost-customer-experience).

Meanwhile, the study revealed that Russian banks mostly put their hopes on AI
in such areas as uncovering fraudulent transactions, debt collection and
credit scoring, while automating call centres by [introducing chat
bots](https://searchcrm.techtarget.com/essentialguide/Guide-to-AI-in-customer-
service-using-chatbots-and-NLP), using AI in algorithmic trading, [human
resources (HR)
management](https://searchhrsoftware.techtarget.com/podcast/Testing-the-
intelligence-of-AI-in-HR-applications) and remote customer identification are
generally considered less promising.

According to the studyÈs authors, however, the latter areas may not
necessarily be dismissed by lenders as unsuitable for AI adoption, but it is
difficult to come up with the returns on investment (ROI) from applying the
technology to those areas. Meanwhile, Russian banks often prefer to adopt the
technology by small steps.

We are pragmatic about the adoption of hypedÈ technologies, said
Putyatinsky. We normally start with smaller-scale pilot projects that allow
us to evaluate the potential usefulness of the technology and build up in-
house competences.

Wherever possible, we use open-source software. We make calculations for
every project to determine if it is financially viable and, based on that, we
make decisions on whether to greenlight it.

According to Putyatinsky, CBoMÈs priority areas for AI technology are
processing full-text documents, making loan decisions, dealing with over-due
debts and financial monitoring.

Another major Russian lender, Rosbank, uses AI for processes involving [risk
evaluation](https://searchenterpriseai.techtarget.com/feature/AI-in-insurance-
forces-big-changes-to-traditional-industry), loan issuing, optimisation of the
branch network, uncovering fraud, communications and interaction with
customers.

We believe that over the next one to two years, AI will also be adopted for
the bankÈs other processes that are not directly linked to interaction with
customers, said [Dmitry Smirnov, head of RosbankÈs data
lab](https://www.linkedin.com/in/smirdm/?locale=de_DE).

Accumulating large amounts of data and the arrival of new data sources will
facilitate that. We are actively exploring areas where AI could be potentially
adopted. These are processes aimed at improving the organisationÈs efficiency
and, from the customerÈs viewpoint, processes that simplify their interaction
with the bank.

Meanwhile, PromsvyazbankÈs main area for AIÈs application includes credit
decision-making, uncovering fraud and forming offers for customers.

Currently, we are working on broadening the scope of AI application, said
Daniil Tkach, head of the customer relations department at
[Promsvyazbank](https://en.wikipedia.org/wiki/Promsvyazbank).

In the short term, automated systems will tell us which products would be the
best offer for a customer, what channels will be the most efficient and what
communication style will be most amenable to the customer.

According to Tkach, the main conditions for wider spread of AI include a
sufficient degree of automation and manageability, reliable systems for data
collection and a sufficient number of reiterations of processes for learning
purposes. He said this is applicable for just about any banking processes,
such as sales, communications, anti-fraud and operations.

We could also single out intellectual management systems, in which AI
substantially helps superiors to understand the quality of work by their
employees and provides tips to all employees for possibly improving their
work, Tkach said.

Still, Russian banks often see AI as a technology that could help automate new
areas rather than replace already existing automation solutions.

We are not trying to revamp existing solutions, CBoMÈs Putyatinsky said.
Instead, we look at areas that have not yet been automated and start
automating them from scratch with the use of new technology.

### __Obstacles to AI adoption

Meanwhile, the process of [adopting AI in the banking
sector](https://www.computerweekly.com/news/252447328/Barclays-appointment-
will-step-up-use-of-AI-in-investment-bank) is not always smooth. There are
[obstacles in the
way](https://www.computerweekly.com/news/252452506/OpenStack-Foundation-will-
tackle-infrastructure-barriers-to-enterprise-AI-adoption) of the technologyÈs
wider spread across the industry.

According to the Expert RA study, those obstacles include discrepancies with
data in information systems, but once the issue of data consistency is
resolved, finding qualified personnel to process data is set to be a major
challenge.

Industry insiders have already been complaining about difficulties in finding
qualified personnel to operate AI-based solutions.

The main factors that are impeding the adoption and development of AI are
shortages of qualified professionals and problems with the infrastructure of
information systems, said Smirnov.

Putyatinsky agreed, saying: The acutest issue is training of qualified
personnel.

To help resolve this challenge, CBoM has been running an internship programme
called [IB Universe](https://www.globalbankingandfinance.com/artificial-
intelligence-in-banking-industry-conversion-to-genuine-benefits/) for the past
12 months. This allows students and recent graduates to acquire practical
experience in various areas of investment business, added Putyatinsky.

According to Putyatinsky, educational programmes of that kind will eventually
allow banks to train personnel in the working environment, producing a new
wave of employees who will already be prepared to deal with new technologies,
such as AI and machine learning.

Another issue with application of AI is complexity of the technologyÈs
algorithms, PromsvyazbankÈs Tkach said. Contemporary [machine learning
algorithms](https://searchcio.techtarget.com/answer/How-do-machine-learning-
algorithms-differ-from-traditional-algorithms) are so complex that humans have
problems understanding decisions made by AI, he added.

Over the next few years, progress with adopting AI systems in RussiaÈs banking
industry is set to largely depend on investments in regional networks,
personnel training and banksÈ ability to attract and retain customers,
according to the Expert RA study.

The good news is that at this point, a bank doesnÈt need to make enormous
investment to become one of the [Russian banking industryÈs] AI leaders, said
the studyÈs authors. But the bad news is that to achieve that, you have to
act right now.",Artificial Intelligence,1,Artificial intelligence making major inroads into Russian banking,standard
17,https://news.ycombinator.com/item?id=19517785,conversations_hackernewsnew,15.875434,[],AI,"Computers which are capable of teaching themselves to predict premature death
could greatly improve preventative healthcare in the future, suggests a new
study by experts at the University of Nottingham.

The team of healthcare data scientists and doctors have developed and tested a
system of computer-based 'machine learning' algorithms to predict the risk of
early death due to chronic disease in a large middle-aged population.

They found this AI system was very accurate in its predictions and performed
better than the current standard approach to prediction developed by human
experts. The study is published by _PLOS ONE_ in a special collections edition
of ""Machine Learning in Health and Biomedicine"".

The team used health data from just over half a million people aged between 40
and 69 recruited to the UK Biobank between 2006 and 2010 and followed up until
2016.

Leading the work, Assistant Professor of Epidemiology and Data Science, Dr
Stephen Weng, said: ""Preventative healthcare is a growing priority in the
fight against serious diseases so we have been working for a number of years
to improve the accuracy of computerised health risk assessment in the general
population. Most applications focus on a single disease area but predicting
death due to several different disease outcomes is highly complex, especially
given environmental and individual factors that may affect them.

""We have taken a major step forward in this field by developing a unique and
holistic approach to predicting a person's risk of premature death by machine-
learning. This uses computers to build new risk prediction models that take
into account a wide range of demographic, biometric, clinical and lifestyle
factors for each individual assessed, even their dietary consumption of fruit,
vegetables and meat per day.

""We mapped the resulting predictions to mortality data from the cohort, using
Office of National Statistics death records, the UK cancer registry and
'hospital episodes' statistics. We found machine learned algorithms were
significantly more accurate in predicting death than the standard prediction
models developed by a human expert.""

The AI machine learning models used in the new study are known as 'random
forest' and 'deep learning'. These were pitched against the traditionally-used
'Cox regression' prediction model based on age and gender - found to be the
least accurate at predicting mortality - and also a multivariate Cox model
which worked better but tended to over-predict risk.

Professor Joe Kai, one of the clinical academics working on the project, said:
""There is currently intense interest in the potential to use 'AI' or 'machine-
learning' to better predict health outcomes. In some situations we may find it
helps, in others it may not. In this particular case, we have shown that with
careful tuning, these algorithms can usefully improve prediction.

""These techniques can be new to many in health research, and difficult to
follow. We believe that by clearly reporting these methods in a transparent
way, this could help with scientific verification and future development of
this exciting field for health care.""

This new study builds on previous work by the Nottingham team which showed
that four different AI algorithms, 'random forest', 'logistic regression',
'gradient boosting' and 'neural networks', were significantly better at
predicting cardiovascular disease than an established algorithm used in
current cardiology guidelines. This earlier study is available here.

The Nottingham researchers predict that AI will play a vital part in the
development of future tools capable of delivering personalised medicine,
tailoring risk management to individual patients. Further research requires
verifying and validating these AI algorithms in other population groups and
exploring ways to implement these systems into routine healthcare.

###

**Disclaimer:** AAAS and EurekAlert! are not responsible for the accuracy of
news releases posted to EurekAlert! by contributing institutions or for the
use of any information through the EurekAlert system.",Artificial Intelligence,1,"Artificial intelligence can predict premature death, study finds",standard
18,https://news.ycombinator.com/item?id=19930331,conversations_hackernewsnew,15.875434,[],AI,"This video is the product of Dessa Engineers, Hashiam Kadhim, Joseph Palermo,
and Rayhane Mama. 

The Engineers used artificial intelligence to recreate Joe RoganÈs voice,
generating the most human-like voice synthesis to date. The audio you are
listening to is 100% generated from the artificial intelligence model. The
model even learned to generate breaths and mouthing sounds where it sees fit
in order to make the speech sound most natural. Find out more about this
project in this blog post (linked below), or check out www.fakejoerogan.com to
see if you can beat our AI model! 

If you have any other questions please reach out to real.talk@dessa.com 

Blog: [https://medium.com/@dessa_/real-
talk-...](/redirect?redir_token=1wN8IgXCJCvxXsdIj51vF6VvIth8MTU1ODExMDQ4NUAxNTU4MDI0MDg1&q=https%3A%2F%2Fmedium.com%2F%40dessa_%2Freal-
talk-speech-synthesis-5dd0897eef7f&v=DWK_iYBl8cA&event=video_description) 

Learn more about Dessa here:
[https://dessa.com/](/redirect?redir_token=1wN8IgXCJCvxXsdIj51vF6VvIth8MTU1ODExMDQ4NUAxNTU4MDI0MDg1&q=https%3A%2F%2Fdessa.com%2F&v=DWK_iYBl8cA&event=video_description) 

Please note that this project does not suggest that we endorse the views and
opinions of Joe Rogan. Joe was selected as a demonstrative model for the
purposes of displaying the capability of this technology.",Artificial Intelligence,1,We Recreated Joe Rogan's Voice Using Artificial Intelligence,standard
19,t3_b0xde1,conversations_reddit,15.850653,,,"No petitions, surveys, or crowdfunding",No tags,,How tech giants are investing in artificial intelligence,standard
20,t3_b62lq6,conversations_reddit,15.850653,,,"No petitions, surveys, or crowdfunding",No tags,,Three Pioneers in Artificial Intelligence Win Turing Award,standard
21,t3_b8lrlg,conversations_reddit,15.718902,,AI,"We did research about how AI can be taught to joke. For our project we take
meme dataset from iFunny and try to create a funny caption generator. There
were several different approaches:

1. Searching nearest caption to theme of image by cluster

2. Searching nearest caption to theme of image by visual similarity

3. Transferring the image descriptor into the vector space of text descriptors

4. Generating captions using Markov Chains

In more details you can read in our blog post <https://heartbeat.fritz.ai/can-
artificial-intelligence-be-taught-how-to-joke-7c7d53a3492a>. We are happy to
answer any questions about our work and discuss other approaches.",Artificial Intelligence,1,[P] Can artificial intelligence be taught how to joke?,standard
22,t3_bv7mlc,conversations_reddit,15.718902,,,For news and announcements from and about Google,Cloud,0.809,Google and Microsoft Using Artificial Intelligence to Fight Hackers,standard
23,https://news.ycombinator.com/item?id=19322342,conversations_hackernewsnew,15.684645,[],AI,"1. 1.

Turing, A. M. Computing machinery and intelligence. _Mind_ **49** , 433460
(1950).

2. 2.

Jordan, M. I. & Mitchell, T. M. Machine learning: trends, perspectives, and
prospects. _Science_ **349** , 255260 (2015).

3. 3.

Mitchell, T. M. _Machine Learning_ (McGraw-Hill Science/Engineering/Math,
Boston, Mass, USA, 1997).

4. 4.

Peek, N., Combi, C., Marin, R. & Bellazzi, R. Thirty years of artificial
intelligence in medicine (AIME) conferences: a review of research themes.
_Artif. Intell. Med._ **65** , 6173 (2015).

5. 5.

Yu, K. H., Beam, A. L. & Kohane, I. S. Artificial intelligence in healthcare.
_Nat. Biomed. Eng._ **2** , 719731 (2018).

6. 6.

Lynch, C. J. & Liston, C. New machine-learning technologies for computer-aided
diagnosis. _Nat. Med._ **24** , 13041305 (2018).

7. 7.

Wong, D. & Yip, S. Machine learning classifies cancer. _Nature_ **555** ,
446447 (2018).

8. 8.

Zhang, W., Chien, J., Yong, J. & Kuang, R. Network-based machine learning and
graph theory algorithms for precision oncology. _npj Precis. Oncol._ **1** ,
25 (2017).

9. 9.

Ching, T. et al. Opportunities and obstacles for deep learning in biology and
medicine. _J. R. Soc. Interface_ **15** , 20170387 (2018).

10. 10.

Richter, A. N. & Khoshgoftaar, T. M. A review of statistical and machine
learning methods for modeling cancer risk using structured clinical data.
_Artif. Intell. Med._ **90** , 114 (2018).

11. 11.

Esteva, A. et al. Dermatologist-level classification of skin cancer with deep
neural networks. _Nature_ **542** , 115118 (2017).

12. 12.

LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. _Nature_ **521** , 436444
(2015).

13. 13.

Goodfellow, I., Bengio, Y. & Courville, A. _Deep Learning_ (MIT Press,
Cambridge, Mass, USA, 2016).

14. 14.

Coudray, N. et al. Classification and mutation prediction from non-small cell
lung cancer histopathology images using deep learning. _Nat. Med._ **24** ,
15591567 (2018).

15. 15.

Ehteshami Bejnordi, B. et al. Diagnostic assessment of deep learning
algorithms for detection of lymph node metastases in women with breast cancer.
_JAMA_ **318** , 21992210 (2017).

16. 16.

Rawat, W. & Wang, Z. Deep convolutional neural networks for image
classification: a comprehensive review. _Neural Comput._ **29** , 23522449
(2017).

17. 17.

Bailey, M. H. et al. Comprehensive characterization of cancer driver genes and
mutations. _Cell_ **173** , 371385 (2018).

18. 18.

Ghahramani, Z. Probabilistic machine learning and artificial intelligence.
_Nature_ **521** , 452459 (2015).

19. 19.

Touw, W. G. et al. Data mining in the Life Sciences with Random Forest: a walk
in the park or lost in the jungle? _Brief. Bioinform._ **14** , 315326
(2013).

20. 20.

Azuaje, F. Computational models for predicting drug responses in cancer
research. _Brief. Bioinform._ **18** , 820829 (2017).

21. 21.

Zhao, L., Lee, V. H. F., Ng, M. K., Yan, H. & Bijlsma, M. F. Molecular
subtyping of cancer: current status and moving toward clinical applications.
_Brief. Bioinform._ <https://doi.org/10.1093/bib/bby026> (2018).

22. 22.

Karczewski, K. J. & Snyder, M. P. Integrative omics for health and disease.
_Nat. Rev. Genet._ **19** , 229310 (2018).

23. 23.

Li, Y., Wu, F. X. & Ngom, A. A review on machine learning principles for
multi-view biological data integration. _Brief. Bioinform._ **19** , 325340
(2018).

24. 24.

Ramazzotti, D., Lal, A., Wang, B., Batzoglou, S. & Sidow, A. Multi-omic tumor
data reveal diversity of molecular mechanisms that correlate with survival.
Preprint at <https://www.biorxiv.org/content/early/2018/10/14/267245> (2018).

25. 25.

Kim, D. et al. Knowledge boosting: a graph-based integration approach with
multi-omics data and genomic knowledge for cancer clinical outcome prediction.
_J. Am. Med. Inform. Assoc._ **22** , 109120 (2015).

26. 26.

Klughammer, J. et al. The DNA methylation landscape of glioblastoma disease
progression shows extensive heterogeneity in time and space. _Nat. Med._
**24** , 16111624 (2018).

27. 27.

Yu, K. H. et al. Association of omics features with histopathology patterns in
lung adenocarcinoma. _Cell Syst._ **5** , 620627 (2017).

28. 28.

Gevaert, O. et al. Glioblastoma multiforme: exploratory radiogenomic analysis
by using quantitative image features. _Radiology_ **273** , 168174 (2014).

29. 29.

Disselhorst, J. A. et al. Linking imaging to omics utilizing image-guided
tissue extraction. _Proc. Natl. Acad. Sci. U.S.A._ **115** , E2980E2987
(2018).

30. 30.

Pan, S. J. & Yang, Q. A survey on transfer learning. _IEEE Trans. Knowl. Data
Eng._ **22** , 13451359 (2010).

31. 31.

Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J. & Wojna, Z. Rethinking the
inception architecture for computer vision. Preprint at
<https://arxiv.org/abs/1512.00567> (2015).

32. 32.

Sevakula, R. K., Singh, V., Verma, N. K., Kumar, C. & Cui, Y. Transfer
learning for molecular cancer classification using deep neural networks.
_IEEE/ACM Trans. Comput. Biol. Bioinform._
<https://doi.org/10.1109/TCBB.2018.2822803> (2018).

33. 33.

Turki, T. W., Wei, Z. & Wang, J. T. L. Transfer learning approaches to improve
drug sensitivity prediction in multiple myeloma patients. _IEEE Access_ **5**
, 73817393 (2017).

34. 34.

Tan, M. Prediction of anti-cancer drug response by kernelized multi-task
learning. _Artif. Intell. Med._ **73** , 7077 (2016).

35. 35.

Shaikhina, T. & Khovanova, N. A. Handling limited datasets with neural
networks in medical applications: a small-data approach. _Artif. Intell. Med._
**75** , 5163 (2017).

36. 36.

Choi, C. et al. RETAIN: an interpretable predictive model for healthcare using
reverse time attention mechanism. Preprint at
<https://arxiv.org/abs/1608.05745> (2016).

37. 37.

Lahav, O., Mastronarde, N. & van der Schaar, M. What is interpretable? Using
machine learning to design interpretable decision-support systems. Preprint at
<https://arxiv.org/abs/1811.10799> (2018).

38. 38.

Alaa, A. M. & van der Schaar, M. Forecasting individualized disease
trajectories using interpretable deep learning. Preprint at
<https://arxiv.org/abs/1810.10489> (2018).

39. 39.

Castelvecchi, D. Can we open the black box of AI? _Nature_ **538** , 2023
(2016).

40. 40.

Lundberg, S. M. et al. Explainable machine-learning predictions for the
prevention of hypoxaemia during surgery. _Nat. Biomed. Eng._ **2** , 749760
(2018).

41. 41.

Li, O., Liu, H., Chen, C. & Rudin, C. Deep learning for case-based reasoning
through prototypes: a neural network that explains its predictions. Preprint
at <https://arxiv.org/abs/1710.04806> (2017).

42. 42.

Chen, C., Li, O., Barnett, A., Su, J. & Rudin, C. This looks like that: deep
learning for interpretable image recognition. Preprint at
<https://arxiv.org/abs/1806.10574> (2018).

43. 43.

Ancona, M., Ceolini, E., _ztireli, C. & Gross, M. Towards better understanding
of gradient-based attribution methods for deep neural networks. Preprint at
<https://arxiv.org/abs/1711.06104> (2018).

44. 44.

Fabris, F., Doherty, A., Palmer, D., de Magalhaes, J. P. & Freitas, A. A. A
new approach for interpreting Random Forest models and its application to the
biology of ageing. _Bioinformatics_ **34** , 24492456 (2018).

45. 45.

Basu, S., Kumbier, K., Brown, J. B. & Yu, B. Iterative random forests to
discover predictive and stable high-order interactions. _Proc. Natl. Acad.
Sci. U.S.A._ **115** , 19431948 (2018).

46. 46.

Yu, M. K. et al. Visible machine learning for biomedicine. _Cell_ **173** ,
15621565 (2018).

47. 47.

Yauney, G. & Shah, P. Reinforcement learning with action-derived rewards for
chemotherapy and clinical trial dosing regimen selection. _Proc. Mach. Learn.
Res._ **85** , 161226 (2018).

48. 48.

Ali, I. et al. Lung nodule detection via deep reinforcement learning. _Front.
Oncol._ **8** , 108 (2018).

49. 49.

Padmanabhan, R., Meskin, N. & Haddad, W. M. Reinforcement learning-based
control of drug dosing for cancer chemotherapy treatment. _Math. Biosci._
**293** , 1120 (2017).

50. 50.

Tseng, H. H. et al. Deep reinforcement learning for automated radiation
adaptation in lung cancer. _Med. Phys._ **44** , 66906705 (2017).

51. 51.

Mahmud, M., Kaiser, M. S., Hussain, A. & Vassanelli, S. Applications of deep
learning and reinforcement learning to biological data. _IEEE Trans. Neural
Netw. Learn. Syst._ **29** , 20632079 (2018).

52. 52.

Girardi, D. et al. Interactive knowledge discovery with the doctor-in-the-
loop: a practical example of cerebral aneurysms research. _Brain Inform._
**3** , 133143 (2016).

53. 53.

Pearl, J. _Causality: Models, Reasoning and Inference_ (Cambridge University
Press, Cambridge, England, 2000).

54. 54.

Yoon, J., Jordon, J. & Van der Schaar, M. GANITE: estimation of individualized
treatment effects using generative adversarial nets. In _International
Conference on Learning Representations._
<https://openreview.net/forum?id=ByKWUeWA> (2018).

55. 55.

Alaa, A. M. & Van der Schaar, M. AutoPrognosis: automated clinical prognostic
modeling via Bayesian optimization with structured Kernel learning. Preprint
at <https://arxiv.org/abs/1802.07207> (2018).",Artificial Intelligence,0.889,Artificial intelligence for precision oncology: beyond patient stratification,standard
24,https://news.ycombinator.com/item?id=19704661,conversations_hackernewsnew,15.684645,[],AI,"# Must-read books to learn Artificial Intelligence in 2019

We have reviewed the top 5 best Artificial Intelligence books available on the
Internet. And to be honest, these books were _really_ hard to find. Between
the A.I conspiracy books and the how to make money off A.I books, there
was really wasnÈt much left to choose from. These resources are weighted based
off trusted community reviews and the quality of the content itself. Because
why waste your time on bad content? You wonÈt ever truly understand the field
of Artificial Intelligence, nor will you be able to even apply it very well.
These books will cover topics like Neural Networks, Mathematical
Optimizations, Logic, Probability, and Economics  which are all _extremely_
useful in todayÈs modern world.

### 1\. Artificial Intelligence: A Modern Approach

[Artificial Intelligence: A Modern
Approach](https://www.amazon.com/gp/product/9332543518/ref=as_li_tl?ie=UTF8&tag=zeroequalsfal-20&camp=1789&creative=9325&linkCode=as2&creativeASIN=9332543518&linkId=d01c6c70480b5bb97712ea8d4f488ded)
provides AI algorithm techniques in-detail, from pathfinding to intelligent AI
Agent design. If you are looking for one of the best books on A.I, then this
is surely a top pick. There is detailed information on building Agents, graph
algorithms incl. A* Search, and how to navigate in areas of uncertainty. Great
book with lots of content and examples.

### 2\. Deep Learning

[Deep
Learning](https://www.amazon.com/gp/product/0262035618/ref=as_li_qf_asin_il_tl?ie=UTF8&tag=zeroequalsfal-20&creative=9325&linkCode=as2&creativeASIN=0262035618&linkId=84568d05237b805c578061aed460c18f)
is written by a famous ex-Googler, providing a rich and detailed guide into
one of A.IÈs most exciting sub-fields, Machine Learning. In this book you
will learn about Neural Networks and how to construct them for various use-
cases. ItÈs been backed by our industry thought-leaders such as Elon Musk who
has commented on how comphresive this book truly is.

### 3\. Pattern Recognition and Machine Learning (Information Science and
Statistics)

[Pattern Recognition and Machine Learning (Information Science and
Statistics)](https://www.amazon.com/gp/product/0387310738/ref=as_li_qf_asin_il_tl?ie=UTF8&tag=zeroequalsfal-20&creative=9325&linkCode=as2&creativeASIN=0387310738&linkId=af136812be38f404cda557c135deaabc)
is a speciality book on the field of pattern recognition. This is a no bs*
book that covers scientific topics such as Bayesian methods to build A.I
agents. It is a truly an outstanding book for itÈs time, and first published
back in 2006.

### 4\. Deep Learning with Python

[Deep Learning with
Python](https://www.amazon.com/gp/product/1617294438/ref=as_li_qf_asin_il_tl?ie=UTF8&tag=zeroequalsfal-20&creative=9325&linkCode=as2&creativeASIN=1617294438&linkId=e875897693499f3ed3137e2cb2c10493)
combines Deep Learning techniques together with the Python programming
language. Python is generally the preferred language for building AI models 
as it is highly recognised by many large companies and it supports some
exceptional A.I libraries such as Tensorflow to construct A.I agents. This
book will get you up to speed with building A.I using Deep Learning. Prior
knowledge of Python may be advised.

### 5\. The Elements of Statistical Learning: Data Mining, Inference, and
Prediction, Second Edition (Springer Series in Statistics)

[The Elements of Statistical Learning: Data Mining, Inference, and Prediction,
Second Edition (Springer Series in
Statistics)](https://www.amazon.com/gp/product/0387848576/ref=as_li_qf_asin_il_tl?ie=UTF8&tag=zeroequalsfal-20&creative=9325&linkCode=as2&creativeASIN=0387848576&linkId=514d719391cc3e1ddb4c8e1ebefeb8c0)
might be one of the best books to gain a solid foundation of statistics, which
really is the backbone of many A.I based applications. Stats helps to drive
the decision-making process of AI such that smart decisions are made. This
book is comphresive and covers Data Mining, Inference, and Prediction  all
relevant and highly applicable today.

Thanks for reading!",Artificial Intelligence,1,Best Books to Learn Artificial Intelligence in 2019,standard
