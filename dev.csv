__label__AI	[![](https://www.microsoft.com/en-us/research/uploads/prod/2019/04/Visceral-Machines-2Site_04_2019_1400x788-1024x576.png)](https://www.microsoft.com/en-us/research/uploads/prod/2019/04/Visceral-Machines-2Site_04_2019_1400x788.png)Recent successes in machine intelligence hinge on core computation ability toefficiently search through billions of possibilities in order to makedecisions. Sequences of decisions, if successful, often suggest that perhapscomputation is catching up toor even surpassinghuman intelligence. Humanintelligence, on the other hand, is highly generalizable, adaptive, robust andexhibits characteristics that the current state-of-the-art machineintelligence systems simply are not yet capable of producing. For example,humans are able to plan significantly far in advance based on the anticipatedoutcomes, even in the presence of many unknown variables. Human intelligenceshines in scenarios in which other humans and living beings are involved andconsistently demonstrates reasoning and meta-reasoning abilities. Humanintelligence is also sympathetic, empathetic, kind, nurturingandimportantlyable to relinquish and redefine the goals of a mission for thebenefit of a greater good. While almost all the work in machine intelligencefocuses on how, the hallmark of human-intelligence is the ability to askwhat and why.Our hypothesis is that emotional intelligence is key to unlocking emergence ofmachines that are not only more general, robust and efficient, but that alsoare aligned with the values of humanity. The affective mechanisms in humansallow us to accomplish tasks that are far too difficult to program or teachcurrent machines. For example, our sympathetic and parasympathetic responsesallow us to stay safe and to be aware of danger. Our ability to recognizeaffect in others and imagine ourselves in their situations makes us far moreeffective in taking appropriate decisions and navigating in the complex world.Drives and affect such as hunger, curiosity, surprise, and joy enable us toregulate our own behavior and also determine the sets of goals that we wish toachieve. And finally, our ability to express our own internal state is anexcellent way to signal to others and possibly influence their decisionmaking.Consequently, [it has beenhypothesized](https://mitpress.mit.edu/books/affective-computing) thatbuilding such an emotional intelligence into a computational framework atminimum would require the following capabilities:* Recognizing othersÈ emotions* Responding to othersÈ emotions* Expressing emotions* Regulating and utilizing emotions in decision makingHistorically, the research in building emotionally intelligent machines hasprimarily taken the human-machine collaboration point of view and mostlyfocused on the first three capabilities. For example, [the earliestwork](https://mitpress.mit.edu/books/affective-computing) on affectrecognition started almost three decades ago, where physiological sensors,cameras, microphones, and so on were used to detect a host of affectiveresponses. While there is much debate about how consistently and universallypeople express emotions on their faces and other physiological signals, andwhether these really reflect how they feel inside, [researchers havesuccessfully built algorithms to identify useful signals in the noisy world ofhuman expressions as well as demonstrated that these signals are consistentwith socio-culturalnorms](http://alumni.media.mit.edu/~djmcduff/assets/publications/McDuff_2017_SAS_Abstract.pdf).Ability to take appropriate actions based on the internal cognitive state of ahuman is imperative for an emotionally intelligent agent.[Applications](https://ieeexplore.ieee.org/document/1532370) such as[automatic tutoring systems](https://www.microsoft.com/en-us/research/uploads/prod/2016/12/ACM2005.pdf), mental and physical healthsupport, and applications for improving productivity lie at the forefront ofwhat is being pursued. The recent line of work on sequential decision making,such as contextual bandits, is slowly making gains in this rich area. [Our ownwork](https://www.microsoft.com/en-us/research/uploads/prod/2016/10/foodandmood_final.pdf), for example, showshow a system sensitive to affective aspects of managing a diet could helpsubjects make good decisions.Expression of affect has been at the forefront of computing for many decadesnow. Even simple signals (for example, light, color, sound) have the abilityto convey and provoke rich emotion. In [Neural TTS Stylization withAdversarial and Collaborative Games](https://www.microsoft.com/en-us/research/publication/neural-tts-stylization-with-adversarial-and-collaborative-games/), (co-authored with Shuang Ma and [YaleSong](https://www.microsoft.com/en-us/research/people/yalesong/)) to bepresented at the Seventh International Conference on LearningRepresentations[ICLR 2019](https://iclr.cc/), we propose a new machinelearning approach to synthesizing realistic human sounding speech that isexpressive. This architecture challenges the model to generate realisticsounding speech that is faithful to the textual content while maintaining aneasily controllable dial for changing the emotion expressed in an independentfashion. Our model achieves start-of-the-art results across multiple tasks,including style transfer (content and style swapping), emotion modeling, andidentity transfer (fitting a new speakerÈs voice). An open-sourceimplementation is available with the paper.[![Figure 1-Our neural architecture uses a combination of adversarial andcollaborative approaches. The algorithm received two audio samples during eachtraining step and has to produce two samples one of which is a reconstructionof the first audio sample \(i.e., has both the content and style of sample 1\)and the second which has the content of sample 1 and the style of sample 2. Indoing so it creates an internal representation of both content and style whichare disambiguated. ](https://www.microsoft.com/en-us/research/uploads/prod/2019/04/Neural_TTS-1024x552.jpg)](https://researchdemopage.wixsite.com/tts-gan)Figure 1-Our neural architecture uses a combination of adversarial andcollaborative approaches. The algorithm received two audio samples during eachtraining step and has to produce two samples one of which is a reconstructionof the first audio sample (i.e., has both the content and style of sample 1)and the second which has the content of sample 1 and the style of sample 2. Indoing so it creates an internal representation of both content and style whichare disambiguated.While the recognition, expression and intervention aspects of artificiallyemotionally intelligent systems have been studied in-depth over the past 20years, there is a still more compelling form of intelligencea system thatutilizes the affective mechanisms effectively in order to learn better andmake choices efficiently. In the most recent line of work, we hope to explorequestions of how to build such affective mechanisms that help ourcomputational processes achieve more than what they accomplish currently.Our recent work, also appearing at ICLR 2019, explores the idea of affect-based intrinsic motivations that can aid in learning decision-makingmechanisms. Much of the recent success in artificial intelligence in solvinggames such as Go, Pac-Man, and text-based RPGs rely on reinforcement learning,where good actions are rewarded and bad actions are penalized. However, itrequires a large number of trials in such an action-reward framework for acomputational agent to learn a reasonable policy. The intuition behind ourproposal is to get inspiration from how humans and other living beingsleverage affective mechanisms to learn much more efficiently.As a human learns to navigate the world, the bodyÈs (nervous systemÈs)responses provide constant intrinsic feedback about the potential consequenceof action choices, for example, becoming nervous when close to a cliffÈs edgeor when driving fast around a bend. Physiological changes are correlated withthese biological preparations to protect one-self from danger. Theanticipatory response in humans to a threatening situation is for the heartrate to increase, heart rate variability to decrease, and for blood to bediverted from the extremities and for the sweat glands to dilate. This is thebodyÈs fight or flight response. Humans have evolved over millions of yearsto build up these complex systems. What if machines had similar feedbacksystems?[![Visceral Machines are a novel approach to reinforcement learning thatleverages neural networks trained on physiological signals to mimic autonomicnervous system responses. Such signals then are used as intrinsic rewardmechanisms to train agents that can learn to accomplish varioustasks.](https://www.microsoft.com/en-us/research/uploads/prod/2019/04/Figure-2a-1024x728.png)](https://www.microsoft.com/en-us/research/uploads/prod/2019/04/Figure-2a.png)Figure 2-Visceral Machines are a novel approach to reinforcement learning thatleverages neural networks trained on physiological signals to mimic autonomicnervous system responses. Such signals then are used as intrinsic rewardmechanisms to train agents that can learn to accomplish various tasks.In [Visceral Machines: Risk-Aversion in Reinforcement Learning with IntrinsicPhysiological Rewards](https://www.microsoft.com/en-us/research/publication/visceral-machines-risk-aversion-in-reinforcement-learning-with-intrinsic-physiological-rewards/), we propose a novel approachto reinforcement learning that leverages an intrinsic reward function trainedon human fight or flight behavior.Our hypothesis is that such reward functions can circumvent the challengesassociated with sparse and skewed rewards in reinforcement learning settingsand can help improve sample efficiency. In our case, extrinsic rewards fromevents are not necessary for the agent to learn. We test this in a simulateddriving environment and show that it can increase the speed of learning andreduce the number of collisions during the learning stage. We are excitedabout the potential of training autonomous systems that mimic the ability tofeel and respond to stimuli in an emotional way.[![An example of the physiological response \(blood volume pulse\) recordedfrom a human during a driving task. A zoomed in section of the pulse wave withframes from the view of the driver are shown. Note how the pulse wave pinchesbetween seconds 285 and 300, during this period the driver collided with awall while turning sharply to avoid another obstacle. The pinching beginsbefore the collision occurs as the driverÈs anticipatory response isactivated. The intrinsic reward component aims to recreate statisticalproperties of the blood volume pulse wave during driving in the simulatedenvironment](https://www.microsoft.com/en-us/research/uploads/prod/2019/04/Figure-2b-1024x601.png)](https://www.microsoft.com/en-us/research/uploads/prod/2019/04/Figure-2b.png)Figure 3-An example of the physiological response (blood volume pulse)recorded from a human during a driving task. A zoomed in section of the pulsewave with frames from the view of the driver are shown. Note how the pulsewave pinches between seconds 285 and 300, during this period the drivercollided with a wall while turning sharply to avoid another obstacle. Thepinching begins before the collision occurs as the driverÈs anticipatoryresponse is activated. The intrinsic reward component aims to recreatestatistical properties of the blood volume pulse wave during driving in thesimulated environmentA lot of computer scientists and roboticists have aspired to build agents thatresemble memorable characters in popular science fiction such as KITT andR2D2. However, rich opportunities exist for building holistic affectivecomputing mechanisms that go a step beyond and to help us build robust,efficient and non-myopic artificial intelligence. We hope that this workinspires a fresh look at how emotions can be used in artificial intelligence.We hope to see you at ICLR in New Orleans in May and look forward to sharingideas and advancing the conversation on the possibilities in the excitingresearch realm of emotionally intelligent agents.
__label__nan	%PDF-1.5 %´è_´è_´è_´è_ 366 0 obj <> endobj 384 0 obj<>/Filter/FlateDecode/ID[<20FF5D460D546D4B863BC23C3FC01C80>]/Index[36635]/Info 365 0 R/Length 89/Prev 206688/Root 367 0 R/Size 401/Type/XRef/W[1 21]>>stream h´è_bbd``b`´è_ ´è_´è_S ´è_`´è_ ´è_*´è_´è_´è_-´è_bë_&´è_ $V$X~ .´è_,´è_2´è_´è_2´è_:´è_X ´è_`d´è_2´è_´è_´è_r´è_?C´è_'´è_´è_´è_< endstream endobj startxref 0 %%EOF 400 0 obj <>stream h´è_b```f``´è_´è_´è_´è_´è_´è_,´è_ ´è_´è_@1V ´è_$´è_$´è_´è_´è_era´è_´è_´è_´è_X´è_´è_ = mkKK´è_d´è_Nv´è_t´è_´è_q´è_´è_´è_´è_X__q#êm&J´è_n\´è_I \´è_´è_´è_´è_´è_´è_´è_6´è_&´è_00´è_´è_v´è_0´è_Q´è_´è_|´è_)v´è_.g´è_5´è_´è_´è_´è_´è_ÑÙm´è_k´è_´è_(ã´è_ ´è_:´è_9´è_6v ´è_´è_´è_Õé ´è_´è_´è_´è_´è_4´è_ ´è_´è_´è_´è_´è_´è_´è_´è_ ´è_ ´è_9´è_endstream endobj 367 0 obj <
__label__DevOps	Rust's [NonNull has been stabilized](https://doc.rust-lang.org/std/ptr/struct.NonNull.html) for a while now. Double check for each usage that the covariance rule makes sense, however.
__label__cloud	"<blockquote><p>Any framework can support this kind of requirements?</p></blockquote><p>Express (the older Koa) is more widely supported </p><ul><li><a href=""https://github.com/awslabs/aws-serverless-express"" rel=""nofollow noreferrer"">https://github.com/awslabs/aws-serverless-express</a></li><li><a href=""https://github.com/yvele/azure-function-express"" rel=""nofollow noreferrer"">https://github.com/yvele/azure-function-express</a></li></ul><h1>More</h1><p>Cloud vendors have various associated services (e.g. hosted databases) that differ significantly. You are going to struggle to get complete cloud redundancy. You will be best served using the internal redundancy options in the cloud provider you choose.</p>"
__label__nan	"<p>There is a <a href=""https://github.com/dmacvicar/terraform-provider-libvirt"" rel=""nofollow noreferrer""><code>libvirt</code> provider</a> that is able to manage resources in KVM and is listed on the <a href=""https://www.terraform.io/docs/providers/type/community-index.html"" rel=""nofollow noreferrer"">community providers page</a>.</p>"
__label__cloud	"See: <a href=""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html"" rel=""nofollow noreferrer"">Amazon EBS Volume Types - Amazon Elastic Compute Cloud</a>"
__label__nan	There must be a new contact created on HubSpot.
__label__DevOps	We need an easy way to test particula-based apps in granular way (i.e. testing routes separately since testing the whole app is already possible)
__label__Customer Experience	It seems that Dash did a hard fork which introduces a new TX format. The old TX format still works, but there might be some trouble while spending the new format because Dash doesn't use BIP-143 and needs to stream prev-txs.
__label__cloud	"<p>when you are creating your postgres instance you have to allow access to the ip address from the postgres' client is running.</p><p>1.-Create your postgresql instance2.-In the Create a PostgreSQL instance window give the instance id and password to you postgres user in the Default user password section.3.-clic on Show configuration options and locate Set connectivity, there You have to give access to Your pc ip address in the Authorized networks under Public IP section click on Add network introduce the ip into the Network box and click done, You can check the client ip address in the link[1] .4.-If you are done with the configurations click create.</p><p>Now to verify the connectivity from the client to the GCS i recommend you to do it the first time with the command line console.</p><p>1.-In you pc lunch the command line console, 2.-execute : psql -h [postgres instance ip address] -u postgres.You can follow the official documentation for Connecting psql Client Using Public IP in the link[2].</p><p>[1]myIPaddress.com[2]<a href=""https://cloud.google.com/sql/docs/postgres/connect-admin-ip"" rel=""nofollow noreferrer"">https://cloud.google.com/sql/docs/postgres/connect-admin-ip</a></p>"
__label__Frontend tools	"Move **Morphy Tsai** from Community to Design category. New title ""Designer"""
__label__cloud	"@DevAS you can use <a href=""https://documentation.onesignal.com/reference"" rel=""nofollow noreferrer"">Onesignal API</a> or <a href=""https://firebase.google.com/docs/cloud-messaging"" rel=""nofollow noreferrer"">Firebase Cloud Messaging</a>"
__label__DevOps, Customer Experience	Feedback from Peter Durham:In the multiple test example, HTMLPage is used as the container, with a tests property not in the schema. Will there be a way to include tests of different pages in one structure?
__label__Customer Experience	The menu on IE is not displayed very good.
__label__AI	The approach is related to traditional simulation, but with criticaldifferences. A simulation is essentially assumption-driven, Schawinski said.The approach is to say, I think I know what the underlying physical laws arethat give rise to everything that I see in the system.È So I have a recipe forstar formation, I have a recipe for how dark matter behaves, and so on. I putall of my hypotheses in there, and I let the simulation run. And then I ask:Does that look like reality? What heÈs done with generative modeling, hesaid, is in some sense, exactly the opposite of a simulation. We donÈt knowanything; we donÈt want to assume anything. We want the data itself to tell uswhat might be going on.The apparent success of generative modeling in a study like this obviouslydoesnÈt mean that astronomers and graduate students have been made redundant but it appears to represent a shift in the degree to which learning aboutastrophysical objects and processes can be achieved by an artificial systemthat has little more at its electronic fingertips than a vast pool of data.ItÈs not fully automated science  but it demonstrates that weÈre capable ofat least in part building the tools that make the process of scienceautomatic, Schawinski said.Generative modeling is clearly powerful, but whether it truly represents a newapproach to science is open to debate. For [DavidHogg](https://cosmo.nyu.edu/hogg/), a cosmologist at New York University andthe Flatiron Institute (which, like _Quanta_ , is funded by the SimonsFoundation), the technique is impressive but ultimately just a verysophisticated way of extracting patterns from data  which is what astronomershave been doing for centuries. In other words, itÈs an advanced form ofobservation plus analysis. HoggÈs own work, like SchawinskiÈs, leans heavilyon AI; heÈs been using neural networks to [classifystars](https://arxiv.org/pdf/1711.08793.pdf) according to their spectra and to[infer other physical attributes](https://arxiv.org/pdf/1603.03040.pdf) ofstars using data-driven models. But he sees his work, as well as SchawinskiÈs,as tried-and-true science. I donÈt think itÈs a third way, he said recently.I just think we as a community are becoming far more sophisticated about howwe use the data. In particular, we are getting much better at comparing datato data. But in my view, my work is still squarely in the observational mode.## Hardworking AssistantsWhether theyÈre conceptually novel or not, itÈs clear that AI and neuralnetworks have come to play a critical role in contemporary astronomy andphysics research. At the Heidelberg Institute for Theoretical Studies, thephysicist [KaiPolsterer](https://www.iau.org/administration/membership/individual/16830/)heads the astroinformatics group  a team of researchers focused on new, data-centered methods of doing astrophysics. Recently, theyÈve been using amachine-learning algorithm to [extract redshift information from galaxy datasets](https://www.aanda.org/articles/aa/pdf/2018/01/aa31326-17.pdf), apreviously arduous task.Polsterer sees these new AI-based systems as hardworking assistants that cancomb through data for hours on end without getting bored or complaining aboutthe working conditions. These systems can do all the tedious grunt work, hesaid, leaving you to do the cool, interesting science on your own.But theyÈre not perfect. In particular, Polsterer cautions, the algorithms canonly do what theyÈve been trained to do. The system is agnostic regardingthe input. Give it a galaxy, and the software can estimate its redshift andits age  but feed that same system a selfie, or a picture of a rotting fish,and it will output a (very wrong) age for that, too. In the end, oversight bya human scientist remains essential, he said. It comes back to you, theresearcher. YouÈre the one in charge of doing the interpretation.For his part, Nord, at Fermilab, cautions that itÈs crucial that neuralnetworks deliver not only results, but also error bars to go along with them,as every undergraduate is trained to do. In science, if you make a measurementand donÈt report an estimate of the associated error, no one will take theresults seriously, he said.Like many AI researchers, Nord is also concerned about the impenetrability ofresults produced by neural networks; often, a system delivers an answerwithout offering a clear picture of how that result was obtained.Yet not everyone feels that a lack of transparency is necessarily a problem.[Lenka Zdeborov](http://artax.karlin.mff.cuni.cz/~zdebl9am/), a researcher atthe Institute of Theoretical Physics at CEA Saclay in France, points out thathuman intuitions are often equally impenetrable. You look at a photograph andinstantly recognize a cat  but you donÈt know how you know, she said. Yourown brain is in some sense a black box.ItÈs not only astrophysicists and cosmologists who are migrating toward AI-fueled, data-driven science. Quantum physicists like [RogerMelko](https://uwaterloo.ca/physics-astronomy/people-profiles/roger-melko) ofthe Perimeter Institute for Theoretical Physics and the University of Waterlooin Ontario have used neural networks to solve some of the toughest and mostimportant problems in that field, such as [how to represent the mathematicalwave function](https://arxiv.org/pdf/1812.09329.pdf) describing a many-particle system. AI is essential because of what Melko calls the exponentialcurse of dimensionality. That is, the possibilities for the form of a wavefunction grow exponentially with the number of particles in the system itdescribes. The difficulty is similar to trying to work out the best move in agame like chess or Go: You try to peer ahead to the next move, imagining whatyour opponent will play, and then choose the best response, but with eachmove, the number of possibilities proliferates.Of course, AI systems have mastered both of these games  chess, decades ago,and Go in 2016, when an AI system called[AlphaGo](https://www.theguardian.com/technology/2016/mar/15/googles-alphago-seals-4-1-victory-over-grandmaster-lee-sedol) defeated a top human player.They are similarly suited to problems in quantum physics, Melko says.## The Mind of the MachineWhether Schawinski is right in claiming that heÈs found a third way of doingscience, or whether, as Hogg says, itÈs merely traditional observation anddata analysis on steroids, itÈs clear AI is changing the flavor ofscientific discovery, and itÈs certainly accelerating it. How far will the AIrevolution go in science?Occasionally, grand claims are made regarding the achievements of a robo-scientist. A decade ago, an AI robot chemist named Adam investigated thegenome of bakerÈs yeast and worked out which genes are responsible for makingcertain amino acids. (Adam did this by observing strains of yeast that hadcertain genes missing, and comparing the results to the behavior of strainsthat had the genes.) _Wired_ Ès headline read, [Robot Makes ScientificDiscovery All by Itself](https://www.wired.com/2009/04/robotscientist/).More recently, Lee Cronin, a chemist at the University of Glasgow, has beenusing a robot [to randomly mixchemicals](https://www.wired.co.uk/article/robot-chemist-life-on-earth), tosee what sorts of new compounds are formed. Monitoring the reactions in real-time with a mass spectrometer, a nuclear magnetic resonance machine, and aninfrared spectrometer, the system eventually learned to predict whichcombinations would be the most reactive. Even if it doesnÈt lead to furtherdiscoveries, Cronin has said, the robotic system could allow chemists to speedup their research by about 90 percent.Last year, another team of scientists at ETH Zurich used neural networks to[deduce physical laws](https://arxiv.org/abs/1807.10300) from sets of data.Their system, a sort of robo-Kepler, rediscovered the heliocentric model ofthe solar system from records of the position of the sun and Mars in the sky,as seen from Earth, and figured out the law of conservation of momentum byobserving colliding balls. Since physical laws can often be expressed in morethan one way, the researchers wonder if the system might offer new ways perhaps simpler ways  of thinking about known laws.These are all examples of AI kick-starting the process of scientificdiscovery, though in every case, we can debate just how revolutionary the newapproach is. Perhaps most controversial is the question of how muchinformation can be gleaned from data alone  a pressing question in the age ofstupendously large (and growing) piles of it. In _The Book of Why_ (2018), thecomputer scientist Judea Pearl and the science writer Dana Mackenzie assertthat data are profoundly dumb. Questions about causality can never beanswered from data alone, they write. Anytime you see a paper or a studythat analyzes the data in a model-free way, you can be certain that the outputof the study will merely summarize, and perhaps transform, but not interpretthe data. Schawinski sympathizes with PearlÈs position, but he described theidea of working with data alone as a bit of a straw man. HeÈs neverclaimed to deduce cause and effect that way, he said. IÈm merely saying wecan do more with data than we often conventionally do.Another oft-heard argument is that science requires creativity, and that  atleast so far  we have no idea how to program that into a machine. (Simplytrying everything, like CroninÈs robo-chemist, doesnÈt seem especiallycreative.) Coming up with a theory, with reasoning, I think demandscreativity, Polsterer said. Every time you need creativity, you will need ahuman. And where does creativity come from? Polsterer suspects it is relatedto boredom  something that, he says, a machine cannot experience. To becreative, you have to dislike being bored. And I donÈt think a computer willever feel bored. On the other hand, words like creative and inspired haveoften been used to describe programs like Deep Blue and AlphaGo. And thestruggle to describe what goes on inside the mind of a machine is mirroredby the difficulty we have in probing our own thought processes.Schawinski recently left academia for the private sector; he now runs astartup called Modulos which employs a number of ETH scientists and, accordingto its website, works in the eye of the storm of developments in AI andmachine learning. Whatever obstacles may lie between current AI technologyand full-fledged artificial minds, he and other experts feel that machines arepoised to do more and more of the work of human scientists. Whether there is alimit remains to be seen.Will it be possible, in the foreseeable future, to build a machine that candiscover physics or mathematics that the brightest humans alive are not ableto do on their own, using biological hardware? Schawinski wonders. Will thefuture of science eventually necessarily be driven by machines that operate ona level that we can never reach? I donÈt know. ItÈs a good question.
__label__AI	We did research about how AI can be taught to joke. For our project we takememe dataset from iFunny and try to create a funny caption generator. Therewere several different approaches:1. Searching nearest caption to theme of image by cluster2. Searching nearest caption to theme of image by visual similarity3. Transferring the image descriptor into the vector space of text descriptors4. Generating captions using Markov ChainsIn more details you can read in our blog post <https://heartbeat.fritz.ai/can-artificial-intelligence-be-taught-how-to-joke-7c7d53a3492a>. We are happy toanswer any questions about our work and discuss other approaches.
__label__cloud	no i am not on cloud so i use metalLB
__label__nan	
__label__nan	
__label__Customer Experience	I would love to see variable fonts support. It's in freetype and harfbuzz, and all major browsers.
__label__AI	"<table> <tr><td> <a href=""https://www.reddit.com/r/MachineLearning/comments/bc108p/d_4_recommended_books_on_ai_ethics_and_philosophy/""> <img src=""https://b.thumbs.redditmedia.com/zo9dARSkvlvNVnq10JEpHnPFpOh-n8X5Db8FmiQ-e5c.jpg"" alt=""[D] 4 Recommended Books on AI Ethics and Philosophy"" title=""[D] 4 Recommended Books on AI Ethics and Philosophy"" /> </a> </td><td> <!-- SC_OFF --><div class=""md""><p>One should not only know the technology and the methods. The more artificial intelligence enters our lives, the more important ethics and philosophy become. Everyone who develops ML models bears a special challenge.</p> <p>&#x200B;</p> <p>link: <a href=""https://www.aisoma.de/4-recommended-books-on-ai-ethics-and-ai-philosophy/"">https://www.aisoma.de/4-recommended-books-on-ai-ethics-and-ai-philosophy/</a> </p> <p>&#x200B;</p> <p><a href=""https://i.redd.it/vgamjtmvhnr21.jpg"">https://i.redd.it/vgamjtmvhnr21.jpg</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=""https://www.reddit.com/user/seemingly_omniscient""> /u/seemingly_omniscient </a> <br/> <span><a href=""https://www.reddit.com/r/MachineLearning/comments/bc108p/d_4_recommended_books_on_ai_ethics_and_philosophy/"">[link]</a></span> &#32; <span><a href=""https://www.reddit.com/r/MachineLearning/comments/bc108p/d_4_recommended_books_on_ai_ethics_and_philosophy/"">[comments]</a></span> </td></tr></table>"
__label__nan	There must be a new contact created on HubSpot.
__label__nan	no comments yetBe the first to share what you think!
__label__cloud	"<p>I'd like to call Cloud SQL API described below from Cloud Functions.</p><ul><li><a href=""https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export?hl=en"" rel=""nofollow noreferrer"">https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export?hl=en</a></li></ul><p>And I found libraries to call GCP APIs.</p><ul><li><a href=""https://github.com/googleapis/google-cloud-node"" rel=""nofollow noreferrer"">https://github.com/googleapis/google-cloud-node</a></li><li><a href=""https://github.com/googleapis/google-cloud-go"" rel=""nofollow noreferrer"">https://github.com/googleapis/google-cloud-go</a></li></ul><p>However, there does not seem to be any modules for Cloud SQL.</p><p>I'm wondering why it's not implemented. is the reason that the APIs are relatively new? or that I misunderstand the purpose of the libraries and actually it shouldn't be implemented in the libraries?</p>"
__label__DevOps	This fails to generate the correct url:```rst.. code-include:: {filename}/src/my_file.py```This generates `contents/pages/{filename}/src/my_file.py`.
